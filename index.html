<!DOCTYPE html>
<html lang="en">
<head>
  <title>Portable Network Graphics (PNG) Specification (Third Edition)</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">

  <style type="text/css">
    span.chunk { color: #622;}
  </style>
  <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
  <script class="remove">
    var respecConfig = {
      group: "png",
      specStatus: "CRD",
      crEnd: "2024-09-18",
      implementationReportURI: "https://w3c.github.io/png/Implementation_Report_3e/",
      shortName: "png-3",
      publishDate: "2024-07-18",
      copyrightStart: "1996",
      previousPublishDate: "2023-07-20",
      previousMaturity: "CR",
      edDraftURI: "https://w3c.github.io/png/",
      github: {
        repoURL : "https://github.com/w3c/png",
        branch : "main"
      },
      extraCSS: ["https://dev.w3.org/2009/dap/ReSpec.js/css/respec.css"],
      editors: [
        { name: "Chris Blume", url: "https://www.programmax.net", company: "W3C Invited Experts", w3cid: 127631 },
        { name: "Pierre-Anthony Lemieux", company: "MovieLabs", companyURL: "https://movielabs.com/", url: "mailto:pal@palemieux.com", w3cid: 57073 },
        { name: "Chris Lilley", url: "https://svgees.us", company: "W3C", companyURL: "https://www.w3.org", w3cid: 1438 },
        { name: "Leonard Rosenthol", company: "Adobe Inc.", companyURL: "https://www.adobe.com", w3cid: 42485 },
        { name: "Chris Arley Seeger", company: "NBCUniversal, LLC a subsidiary of Comcast Corporation", companyURL: "https://www.xfinity.com", w3cid: 125844 }
      ],
      formerEditors: [
        { name: "Thomas Boutell" },
        { name: "Adam M. Costello" },
        { name: "David Duce" },
        { name: "Tom Lane" },
        { name: "Glenn Randers-Pehrson" },
      ],
      authors: [
        { name: "Mark Adler", url: "https://en.wikipedia.org/wiki/Mark_Adler" },
        { name: "Thomas Boutell", url: "https://boutell.dev/" },
        { name: "Christian Brunschen" },
        { name: "Adam M. Costello", url: "http://www.nicemice.net/amc/" },
        { name: "Lee Daniel Crocker" },
        { name: "Andreas Dilger", url: "http://www-mddsp.enel.ucalgary.ca/People/adilger/" },
        { name: "Oliver Fromme", url: "https://www.fromme.com/" },
        { name: "Jean-loup Gailly", url: "http://gailly.net/" },
        { name: "Chris Herborth" },
        { name: "Alex Jakulin" },
        { name: "Neal Kettler" },
        { name: "Tom Lane" },
        { name: "Alexander Lehmann" },
        { name: "Chris Lilley", url: "https://svgees.us", company: "W3C", companyURL: "https://www.w3.org" },
        { name: "Dave Martindale" },
        { name: "Owen Mortensen" },
        { name: "Chris Needham", url: "https://chrisneedham.com/about" },
        { name: "Stuart Parmenter"},
        { name: "Keith S. Pickens" },
        { name: "Robert P. Poole" },
        { name: "Glenn Randers-Pehrson" },
        { name: "Greg Roelofs", url: "http://www.gregroelofs.com/" },
        { name: "Willem van Schaik", url: "http://www.schaik.com/" },
        { name: "Guy Schalnat" },
        { name: "Paul Schmidt" },
        { name: "Andrew Smith" },
        { name: "Michael Stokes" },
        { name: "Simon Thompson", company: "British Broadcasting Corporation", companyURL: "https://www.bbc.co.uk" },
        { name: "Vladimir Vukicevic" },
        { name: "Tim Wegner" },
        { name: "Jeremy Wohl" }
      ],
      wg: "Portable Network Graphics (PNG) Working Group",
      wgURI: "https://www.w3.org/groups/wg/png",
      wgPublicList: "public-png",
      wgPatentURI: "https://www.w3.org/groups/wg/png/ipr",
      lint: { "informative-dfn": false },
      xref: ["i18n-glossary"],
      localBiblio: {
        "CIPA-DC-008": {
          title: "Exchangeable image file format for digital still cameras: Exif Version 2.32",
          href: "https://www.cipa.jp/std/documents/download_e.html?DC-008-Translation-2019-E",
          date: "2019-05-17",
          publisher: "Camera & Imaging Products Association"
        },
        "COLOR-FAQ": {
          title: "Color FAQ",
          authors: ["Poynton, C."],
          href: "https://poynton.ca/ColorFAQ.html",
          date: "2009-10-19"
        },
        "CTA-861.3-A": {
          title: "HDR Static Metadata Extensions (CTA-861.3-A)",
          publisher: "Consumer Technology Association",
          date: "2015-01",
          href: "https://shop.cta.tech/products/hdr-static-metadata-extensions"
        },
        "Display-P3": {
          title: "Display P3",
          authors: ["Apple, Inc"],
          date: "2022-02",
          publisher: "ICC",
          href: "https://www.color.org/chardata/rgb/DisplayP3.xalter"
        },
        "ICC-2": {
          title: "Specification ICC.2:2019 (Profile version 5.0.0 - iccMAX)",
          date: "2019",
          href: "https://www.color.org/specification/ICC.2-2019.pdf",
          publisher: "International Color Consortium"
        },
        "GAMMA-FAQ": {
          title: "Gamma FAQ",
          authors: ["Poynton, C."],
          href: "https://poynton.ca/GammaFAQ.html",
          date: "1998-08-04"
        },
        "HDR10": {
          title: "HDR10 Media Profile",
          href: "https://en.wikipedia.org/wiki/HDR10"
        },
        "HDR-Static-Meta": {
          title: "On the Calculation and Usage of HDR Static Content Metadata",
          authors: ["Smith, Michael D.", "Zink, Michael"],
          publisher: "Society of Motion Picture and Television Engineers",
          date: "2021-08-05",
          href: "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508136"
        },
        "Hill": {
          title: "Comparative analysis of the quantization of color spaces on the basis of the CIELAB color-difference formula",
          authors: ["Hill, B.", "Roger, Th.", "Vorhagen, F.W."],
          journal: "ACM Transactions on Graphics, Volume 16, Issue 2, pp. 109–154",
          date: "1997-04",
          href: "https://dl.acm.org/doi/10.1145/248210.248212"
        },
        "ISO-3309": {
          title: "ISO/IEC 3309:1993, Information Technology — Telecommunications and information exchange between systems — High-level data link control (HDLC) procedures — Frame structure.",
          date: "1993",
          publisher: "ISO"
        },
        "ISO_8859-1": {
          title: "ISO/IEC 8859-1:1998, Information technology — 8-bit single-byte coded graphic character sets — Part 1: Latin alphabet No. 1.",
          date: "1998",
          publisher: "ISO"
        },
        "ISO_9899": {
          title: "ISO/IEC 9899:2018 Information technology — Programming languages — C",
          href: "https://www.iso.org/standard/74528.html",
          date: "2018-6",
          publisher: "ISO"
        },
        "ISO_15076-1": {
          title: "ISO 15076-1:2010 Image technology colour management — Architecture, profile format and data structure — Part 1: Based on ICC.1:2010",
          href: "https://www.iso.org/standard/54754.html",
          date: "2010-12",
          publisher: "ISO"
        },
        "ISO_20677-1": {
          title: "ISO 20677:2019 Image technology colour management — Extensions to architecture, profile format and data structure",
          href: "https://www.iso.org/standard/68806.html",
          date: "2019-02",
          publisher: "ISO"
        },
        "ITU-R-BT.709": {
          title: "ITU-R BT.709, SERIES BT: BROADCASTING SERVICE (TELEVISION). Parameter values for the HDTV standards for production and international programme exchange",
          publisher: "ITU",
          date: "2015-06",
          href: "https://www.itu.int/rec/R-REC-BT.709"
        },
        "ITU-R-BT.2020": {
          title: "Parameter values for ultra-high definition television systems for production and international programme exchange",
          publisher: "ITU",
          href: "https://www.itu.int/rec/R-REC-BT.2020"
        },
        "ITU-R-BT.2100": {
          title: "ITU-R BT.2100, SERIES BT: BROADCASTING SERVICE (TELEVISION). Image parameter values for high dynamic range television for use in production and international programme exchange",
          publisher: "ITU",
          date: "2018-07",
          href: "https://www.itu.int/rec/R-REC-BT.2100"
        },
          "ITU-R-BT.2390": {
          title: "High dynamic range television for production and international programme exchange",
          publisher: "ITU",
          href: "https://www.itu.int/dms_pub/itu-r/opb/rep/R-REP-BT.2390-11-2023-PDF-E.pdf"
        },
        "ITU-T-H.273": {
          title: "ITU-T H.273, SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS Infrastructure of audiovisual services – Coding of moving video. Coding-independent code points for video signal type identification",
          publisher: "ITU",
          date: "2021-07",
          href: "https://www.itu.int/rec/T-REC-H.273"
        },
        "ITU-T-V.42": {
          title: "ITU-T V.42, SERIES V: DATA COMMUNICATION OVER THE TELEPHONE NETWORK. Error-correcting procedures for DCEs using asynchronous-to-synchronous conversion",
          href: "https://www.itu.int/rec/T-REC-V.42-200203-I/en",
          date: "2002-03-29",
          publisher: "ITU"
        },
        "Kasson": {
          title: "An Analysis of Selected Computer Interchange Color Spaces",
          authors: ["Kasson, J.", "W. Plouffe"],
          journal: "ACM Transactions on Graphics, vol. 11, no. 4, pp. 373-405",
          date: "1992",
          href: "https://dl.acm.org/doi/abs/10.1145/146443.146479"
        },
        "Luminance-Chromaticity": {
          title: "Luminance and Chromaticity",
          href: "https://colorusage.arc.nasa.gov/lum_and_chrom.php",
          publisher: "Color Usage Research Lab, NASA Ames Research Center"
        },
        "Paeth": {
          authors: ["Paeth, A.W"],
          title: "Image File Compression Made Easy, in Graphics Gems II, pp. 93-100",
          publisher: "Academic Press",
          date: "1991",
          isbn: "0-12-064481-9",
          href: "https://www.sciencedirect.com/science/article/pii/B9780080507545500293"
        },
        "PNG-EXTENSIONS": {
          title: "Extensions to the PNG Third Edition Specification, Version 1.6.0",
          publisher: "W3C",
          date: "2021",
          href: "https://w3c.github.io/png/extensions/Overview.html"
        },
        "PostScript": {
          title: "PostScript Language Reference Manual",
          authors: ["Adobe Systems Incorporated"],
          publisher: "Addison-Wesley",
          date: "1990",
          edition: "2",
          isbn: "0-201-18127-4"
        },
        "ROELOFS": {
          title: "PNG: The Definitive Guide",
          authors: ["Roelofs, G."],
          publisher: "O'Reilly &amp; Associates Inc",
          isbn: "1-56592-542-4",
          href: "http://www.libpng.org/pub/png/pngbook.html",
          date: "1999-06-11"
        },
        "SMPTE-170M": {
          title: "Television — Composite Analog Video Signal — NTSC for Studio Applications",
          publisher: "Society of Motion Picture and Television Engineers",
          date: "2004-11-30",
          href: "https://standards.globalspec.com/std/892300/SMPTE%20ST%20170M"
        },
        "SMPTE-RP-177": {
          title: "Derivation of Basic Television Color Equations",
          publisher: "Society of Motion Picture and Television Engineers",
          date: "1 November 1993",
          href: "https://standards.globalspec.com/std/1284890/smpte-rp-177"
        },
        "SMPTE-ST-2067-21": {
          title: "Interoperable Master Format — Application #2E",
          publisher: "Society of Motion Picture and Television Engineers",
          date: "2023-02-20",
          href: "https://doi.org/10.5594/SMPTE.ST2067-21.2023"
        },
        "SMPTE-RP-2077": {
          title: "Full-Range Image Mapping",
          publisher: "Society of Motion Picture and Television Engineers",
          date: "2013-01-01",
          href: "https://doi.org/10.5594/SMPTE.RP2077.2013"
        },
        "SMPTE-ST-2086": {
          title: "Mastering Display Color Volume Metadata Supporting High Luminance and Wide Color Gamut Images",
          publisher: "Society of Motion Picture and Television Engineers",
          date: "27 April 2018",
          href: "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353899"
        },
        "TIFF-6.0": {
          href: "https://www.loc.gov/preservation/digital/formats/fdd/fdd000022.shtml",
          title: "TIFF Revision 6.0",
          date: "3 June 1992"
        },
        "Ziv-Lempel": {
          authors: ["J. Ziv", "A. Lempel"],
          title: "A Universal Algorithm for Sequential Data Compression, IEEE Transactions on Information Theory, vol. IT-23, no. 3, pp. 337 - 343",
          date: "1977-05",
          publisher: "IEEE",
          href: "https://ieeexplore.ieee.org/document/1055714",
        },
        "EBU-R-103": {
          title: "Video Signal Tolerance in Digital Television Systems",
          publisher: "EBU",
          date: "2020-05",
          href: "https://tech.ebu.ch/docs/r/r103.pdf"
        },
        "ITU-T-Series-H-Supplement-19": {
          title: "Series H: Audio Visual and Multimedia Systems - Usage of video signal type code points",
          publisher: "ITU",
          date: "2021-04",
          href: "https://www.itu.int/ITU-T/recommendations/rec.aspx?rec=14652"
        },  
        "ITU-R BT.2408": {
          title: "Guidance for operational practices in HDR television production",
          publisher: "ITU",
          date: "09/2023",
          href: "https://www.itu.int/pub/R-REP-BT.2408"
        },  
        "ISO/TS 22028-5": {
          title: "Part 5: High dynamic range and wide colour gamut encoding for still images (HDR/WCG)",
          publisher: "ISO",
          date: "06/2023",
          href: "https://www.iso.org/standard/81863.html"

    }
  </script>
</head>
<body>
  <section id="abstract">
    <p>This document describes PNG (Portable Network Graphics), an extensible file format for the <a>lossless</a>, portable,
    well-compressed storage of static and animated raster images. PNG provides a patent-free replacement for GIF and can also
    replace many common uses of TIFF. <a>Indexed-color</a>, <a>greyscale</a>, and <a>truecolor</a> images are supported, plus an optional alpha
    channel. Sample depths range from 1 to 16 bits.</p>

    <p>PNG is designed to work well in online viewing applications, such as the World Wide Web, so it is fully streamable with a
    progressive display option. PNG is robust, providing both full file integrity checking and simple detection of common
    transmission errors. Also, PNG can store color space data for improved color matching on heterogeneous platforms.</p>

    <p>This specification defines two Internet Media Types, image/png and image/apng.</p>
    <!--
needs update, comment out for now

<p>The PNG specification enjoys a good level of <a href="http://www.libpng.org/pub/png/pngstatus.html">implementation</a>  with good interoperability. At the time of this publication more than 180 <a href="http://www.libpng.org/pub/png/pngapvw.html">image viewers</a> could display PNG images and over 100 <a href="http://www.libpng.org/pub/png/pngaped.html">image editors</a> could read and write valid PNG files. Full support of PNG is  required  for conforming <a href="/Graphics/SVG">SVG</a> viewers; at the time of publication all eighteen <a href="/Graphics/SVG/SVG-Implementations.htm8#viewer">SVG viewers</a> had PNG support. HTML has no required image formats, but over 60 <a href="http://www.libpng.org/pub/png/pngapbr.html">HTML browsers</a> had at least basic support of PNG images.</p> -->
  </section>

  <section id="sotd">
    <p>This specification is intended to become an International Standard, but is not yet one. It is inappropriate to refer to this
    specification as an International Standard.</p>

  </section>
  <!-- *********************************************************************

FROM HERE ON THIS FILE IS IDENTICAL TO THE ISO VERSION
with these exceptions:

- id added to any headings that did not have one, to comply with pubrules and allow indexing into the document
- URL for this document updated in Annex E and the words " [to be completed when published]" removed

**************************************************************************  -->

  <h2 id="Introduction">Introduction</h2>

  <p>The design goals for this specification were:</p>

  <ol>
    <li>Portability: encoding, decoding, and transmission should be software and hardware platform independent.</li>

    <li>Completeness: it should be possible to represent <a>truecolor</a>, <a>indexed-color</a>, and <a>greyscale</a> images, in each case with
    the option of transparency, color space information, and ancillary information such as textual comments.
    </li>

    <li>Serial encode and decode: it should be possible for datastreams to be generated serially and read serially, allowing the
    datastream format to be used for on-the-fly generation and display of images across a serial communication channel.</li>

    <li>Progressive presentation: it should be possible to transmit datastreams so that an approximation of the whole image can be
    presented initially, and progressively enhanced as the datastream is received.</li>

    <li>Robustness to transmission errors: it should be possible to detect datastream transmission errors reliably.</li>

    <li>Losslessness: filtering and compression should preserve all information.</li>

    <li>Performance: any filtering, compression, and progressive image presentation should be aimed at efficient decoding and
    presentation. Fast encoding is a less important goal than fast decoding. Decoding speed may be achieved at the expense of
    encoding speed.</li>

    <li>Compression: images should be compressed effectively, consistent with the other design goals.</li>

    <li>Simplicity: developers should be able to implement the standard easily.</li>

    <li>Interchangeability: any standard-conforming PNG decoder shall be capable of reading all conforming PNG datastreams.</li>

    <li>Flexibility: future extensions and private additions should be allowed for without compromising the interchangeability of
    standard PNG datastreams.</li>

    <li>Freedom from legal restrictions: no algorithms should be used that are not freely available.</li>
  </ol>

  <section>
    <!-- Maintain a fragment named "1Scope" to preserve incoming links to it -->

    <h2 id="1Scope">Scope</h2>

    <p>This specification specifies a datastream and an associated file format, Portable Network Graphics (PNG, pronounced "ping"),
    for a <a>lossless</a>, portable, compressed individual computer graphics image or frame-based animation, transmitted across the
    Internet.
  </section>

  <section>
    <!-- Maintain a fragment named "3Defsandabbrevs" to preserve incoming links to it -->

    <h2 id="3Defsandabbrevs">Terms, definitions, and abbreviated terms</h2>

    <p>For the purposes of this specification the following definitions apply.</p>

    <dl>

      <!-- Maintain a fragment named "3byte" to preserve incoming links to it -->

      <dt id="3byte"><dfn>byte</dfn>
      </dt>
      <dt>octet</dt>

      <dd>8-bit binary integer in the range [0, 255] where the most significant bit is bit 7 and the least significant
      bit is bit 0.</dd>
      <!-- Maintain a fragment named "3byteOrder" to preserve incoming links to it -->

      <dt id="3byteOrder"><dfn>byte order</dfn>
      </dt>

      <dd>
        ordering of <a>bytes</a> for multi-byte data values.
      </dd>

      <!-- Maintain a fragment named "3chromaticity" to preserve incoming links to it -->

      <dt id="3chromaticity"><dfn>chromaticity</dfn>
      </dt>

      <dd>pair of <i>x</i> and <i>y</i> values in the <i>xyY</i> space specified at [[COLORIMETRY]].

      <p class="note">Chromaticity is a measure of the quality of a color regardless of its luminance.</p></dd>

      <!-- Maintain a fragment named "3composite" to preserve incoming links to it -->

      <dt id="3composite"><dfn data-lt="composited|composite">composite (verb)</dfn>
      </dt>

      <dd>form an image by merging a foreground image and a background image, using transparency information to determine
      where and to what extent the background should be visible.
      <p class="note">The foreground image is said to be <a>composited</a> against the background.</p>
      </dd>

      <!-- Maintain a fragment named "3datastream" to preserve incoming links to it -->

      <dt id="3datastream"><dfn>datastream</dfn>
      </dt>

      <dd>
        sequence of <a>bytes</a>.
      </dd>
      <!-- Maintain a fragment named "3deflate" to preserve incoming links to it -->

      <dt id="3deflate"><dfn>deflate</dfn>
      </dt>

      <dd>
        member of the <a>LZ77</a> family of compression methods.

        <p>SOURCE: [[RFC1951]]</p>
      </dd>
      
      

      <dt><dfn>frame</dfn></dt>

      <dd>For static PNG, the <a>static image</a>
        is considered to be the first (and only) frame.
        For animated PNG, each image that forms part
        of the <a href="#apng-frame-based-animation">frame-based animation</a> sequence
        is a frame.
        Thus, for animated PNG, when the static image is not the first frame,
        the static image is not considered to be a frame.
      </dd>


      <!-- Maintain a fragment named "3frameBuffer" to preserve incoming links to it -->

      <dt id="3frameBuffer"><dfn>frame buffer</dfn>
      </dt>

      <dd>
        the final digital storage area for the image shown by most types of computer display.

        <p class="note">Software causes an image to appear on screen by loading the image into the <a>frame buffer</a>.</p>
      </dd>

      <dt><dfn>fully transparent black</dfn>
      </dt>

      <dd>pixel where the red, green, blue and alpha components are all equal to zero.</dd>

      <dt><dfn>gamma value</dfn>
      </dt>

      <dd>
        value of the exponent of a <a>gamma</a> <a>transfer function</a>.
      </dd>
      <!-- Maintain a fragment named "3gamma" to preserve incoming links to it -->

      <dt id="3gamma"><dfn>gamma</dfn>
      </dt>

      <dd>
        power-law <a>transfer function</a>.
      </dd>

      <dt>high dynamic range (<dfn>HDR</dfn>)
      </dt>

      <dd>
        an image format capable of storing images with a relatively high dynamic range similar to or in excess of the human visual system's instantaneous dynamic range (~12-14 <a>stops</a>). PNG allows the use of two <a>HDR</a> formats, <a>HLG</a> and <a>PQ</a> [[ITU-R-BT.2100]].
      </dd>

      <dt>hybrid log-gamma (<dfn>HLG</dfn>)
      </dt>

      <dd>
        <a>transfer function</a> defined in [[ITU-R-BT.2100]] Table 5. (A relative scene-referred system.)
      </dd>

      <dt><dfn>full-range image</dfn>
      </dt>

      <dd>image where reference black and white correspond, respectively, to sample values <code>0</code> and <code>2<sup>bit depth</sup> -
      1</code>.</dd>

      <!-- Maintain a fragment named "3imageData" to preserve incoming links to it -->

      <dt id="3imageData"><dfn>image data</dfn>
      </dt>

      <dd>
        1-dimensional array of <a>scanlines</a> within an image.
      </dd>

      <!-- Maintain a fragment named "3interlacedPNGimage" to preserve incoming links to it -->

      <dt id="3interlacedPNGimage"><dfn>interlaced PNG image</dfn>
      </dt>

      <dd>
        sequence of <a>reduced images</a> generated from the <a>PNG image</a> by <a>pass extraction</a>.
      </dd>
      <!-- Maintain a fragment named "3losslessCompression" to preserve incoming links to it -->

      <dt id="3losslessCompression"><dfn>lossless</dfn>
      </dt>

      <dd>method of data compression that permits reconstruction of the original data exactly, bit-for-bit.</dd>
      <!-- Maintain a fragment named "3luminance" to preserve incoming links to it -->

      <dt id="3luminance"><dfn>luminance</dfn>
      </dt>

      <dd>
        an objective measurement of the visible light intensity, taking into account the sensitivity of the human eye to different wavelengths.

        <p class="note">Luminance and <a>chromaticity</a> together fully define a measured color.  See <a href="https://colorusage.arc.nasa.gov/lum_and_chrom.php">Luminance and Chromaticity</a>
        or, for a formal definition [[COLORIMETRY]].</p>

      </dd>
      <!-- Maintain a fragment named "3LZ77" to preserve incoming links to it -->

      <dt><dfn id="3LZ77">LZ77</dfn>
      </dt>

      <dd>data compression algorithm described in [[Ziv-Lempel]].</dd>

      <dt><dfn>narrow-range image</dfn>
      </dt>

      <dd>Image where reference black and white do not correspond, respectively, to sample values <code>0</code> and
      <code>2<sup>bit depth</sup> - 1</code>.</dd>
      <!-- Maintain a fragment named "3networkByteOrder" to preserve incoming links to it -->

      <dt id="3networkByteOrder"><dfn>network byte order</dfn>
      </dt>

      <dd>
        <a>byte order</a> in which the most significant byte comes first, then the less significant bytes in descending order of
        significance (MSB LSB for two-byte integers, MSB B2 B1 LSB for four-byte integers).
      </dd>

      <dt>perceptual quantizer (<dfn>PQ</dfn>)
      </dt>

      <dd>
        <a>transfer function</a> defined in [[ITU-R-BT.2100]] Table 4. (An absolute display-referred system.)
        <p class="note">
          Only RGB may be used in PNG, ICtCp is NOT supported.
        </p>
      </dd>

      <!-- Maintain a fragment named "3PNGdecoder" to preserve incoming links to it -->

      <dt id="3PNGdecoder">PNG decoder</dt>

      <dd>
        process or device that reconstructs the <a>reference image</a> from a <a>PNG datastream</a> and generates a
        corresponding <a>delivered image</a>.
      </dd>
      <!-- Maintain a fragment named "3PNGeditor" to preserve incoming links to it -->

      <dt id="3PNGeditor"><dfn>PNG editor</dfn>
      </dt>

      <dd>
        process or device that creates a modification of an existing <a>PNG datastream</a>, preserving unmodified ancillary
        information wherever possible, and obeying the <a>chunk</a> ordering rules, even for unknown chunk types.
      </dd>
      <!-- Maintain a fragment named "3PNGencoder" to preserve incoming links to it -->

      <dt id="3PNGencoder">PNG encoder
      </dt>

      <dd>
        process or device which constructs a <a>reference image</a> from a <a>source image</a>, and generates a <a>PNG
        datastream</a> representing the reference image.
      </dd>
      <!-- Maintain a fragment named "3PNGfile" to preserve incoming links to it -->

      <dt id="3PNGfile">PNG file
      </dt>

      <dd>
        <a>PNG datastream</a> stored as a file.
      </dd>
      <!-- Maintain a fragment named "3PNGfourByteUnSignedInteger" to preserve incoming links to it -->

      <dt id="3PNGfourByteUnSignedInteger"><dfn>PNG four-byte unsigned integer</dfn>
      </dt>

      <dd>
        <p>a four-byte unsigned integer limited to the range 0 to 2<sup>31</sup>-1.</p>

        <p class="note">The restriction is imposed in order to accommodate languages that have difficulty with unsigned four-byte
        values.</p>
      </dd>

      <dt id="3PNGtwoByteUnSignedInteger"><dfn>PNG two-byte unsigned integer</dfn>
      </dt>

      <dd>
        <p>a two-byte unsigned integer in network byte order.</p>
      </dd>

      <!-- Maintain a fragment named "3sample" to preserve incoming links to it -->

      <dt id="3sample"><dfn>sample</dfn>
      </dt>

      <dd>
        intersection of a <a>channel</a> and a <a>pixel</a> in an image.
      </dd>
      <!-- Maintain a fragment named "3sampleDepth" to preserve incoming links to it -->

      <dt id="3sampleDepth">sample depth</dt>

      <dd>
        number of bits used to represent a <a>sample</a> value.
      </dd>
      <!-- Maintain a fragment named "3scanline" to preserve incoming links to it -->

      <dt id="3scanline"><dfn>scanline</dfn>
      </dt>

      <dd>
        row of <a>pixels</a> within an image or <a>interlaced PNG image</a>.
      </dd>

      <dt>standard dynamic range (<dfn>SDR</dfn>)
      </dt>

      <dd>
        an image format capable of storing images with a relatively low dynamic range of 5-8 <a>stops</a>. Examples include [[SRGB]], [[Display-P3]], [[ITU-R-BT.709]].
      <p class="note">Standard dynamic range is independent of the primaries and hence, gamut. Wide color gamut <a>SDR</a> formats are supported by PNG.</p></dd>

      <dt><dfn>stop</dfn>
      </dt>

      <dd>
        a change in scene light luminance of a factor of 2.
      </dd>

      <dt><dfn>transfer function</dfn>
      </dt>

      <dd>function relating image luminance with image samples.</dd>
      <!-- Maintain a fragment named "3whitePoint" to preserve incoming links to it -->

      <dt id="3whitePoint"><dfn>white point</dfn>
      </dt>

      <dd>
        <a>chromaticity</a> of a computer display's nominal white value.
      </dd>
      <!-- Maintain a fragment named "3zlib" to preserve incoming links to it -->

      <dt id="3zlib"><dfn>zlib</dfn>
      </dt>

      <dd>
        <p><a>deflate</a>-style compression method.</p>

        <p>SOURCE: [[rfc1950]]</p>

        <p class="note">Also refers to the name of a library containing a sample implementation of this method.</p>
      </dd>

      <!-- Maintain a fragment named "3CRC" to preserve incoming links to it -->
      <dt id="3CRC">Cyclic Redundancy Code</dt>
      <dt><abbr title="Cyclic Redundancy Code">CRC</abbr></dt>
      <dd>
        <p>type of check value designed to detect most transmission errors.</p>

        <p class="note">A decoder calculates the CRC for the received data and checks by comparing it to the CRC calculated by
        the encoder and appended to the data. A mismatch indicates that the data or the CRC were corrupted in transit.</p>
      </dd>

      <!-- Maintain a fragment named "3CRT" to preserve incoming links to it -->
      <dt id="3CRT">Cathode Ray Tube</dt>
      <dt><abbr title="Cathode Ray Tube">CRT</abbr></dt>

      <dd>vacuum tube containing one or more electron guns, which emit electron beams that are manipulated to display images on a
      phosphorescent screen.</dd>

      <dt>Electro-Optical Transfer Function</dt>
      <dt>
        <abbr title="Electro-Optical Transfer Function"><dfn>EOTF</dfn></abbr>
      </dt>
      <dd>The <a>transfer function</a> between the electrical or digital domain and light energy. It defines the amount of light emitted by a display for a given input signal.</dd>

      <!-- Maintain a fragment named "3LSB" to preserve incoming links to it -->
      <dt id="3LSB">Least Significant Byte</dt>
      <dt><abbr title="Least Significant Byte">LSB</abbr></dt>
      <dd>
        Least significant byte of a multi-<a>byte</a> value.
      </dd>
      <!-- Maintain a fragment named "3MSB" to preserve incoming links to it -->
      <dt id="3MSB">Most Significant Byte</dt>
      <dt><abbr title="Most Significant Byte">MSB</abbr></dt>

      <dd>
        Most significant byte of a multi-<a>byte</a> value.
      </dd>

      <dt>Opto-Electrical Transfer Function</dt>
      <dt>
        <abbr title="Opto-Electrical Transfer Function"><dfn>OETF</dfn></abbr>
      </dt>
      <dd>The <a>transfer function</a> between light energy and the electrical or digital domain. It defines the amount of light in a scene required to produce a given output signal.</dd>
    </dl>
  </section>
  
  

  <section>
    <!-- Maintain a fragment named "4Concepts" to preserve incoming links to it -->

    <h2 id="4Concepts">Concepts</h2>

    <section>
      <h2>Static and Animated images</h2>

      <p>All PNG images contain a single <dfn>static image</dfn>.</p>

      <p>Some PNG images — called <dfn class="lint-ignore">Animated PNG</dfn> (<abbr title="Animated PNG">APNG</abbr>) — also
      contain a frame-based animation sequence, the <dfn>animated image</dfn>. The first frame of this may be — but need not be —
      the <a>static image</a>. Non-animation-capable displays (such as printers) will display the <a>static image</a> rather than
      the animation sequence.</p>

      <p>The <a>static image</a>, and each individual frame of an <a>animated image</a>, corresponds to a <em>reference image</em>
      and is stored as a <em>PNG image</em>.</p>

    </section>

    <section>
      <!-- Maintain a fragment named "4Concepts.Sourceimage" to preserve incoming links to it -->

      <h2 id="4Concepts.Sourceimage">Images</h2>

      <p>This specification specifies the PNG datastream, and places some requirements on PNG encoders, which generate PNG
      datastreams, PNG decoders, which interpret PNG datastreams, and <a>PNG editors</a>, which transform one PNG datastream into
      another. It does not specify the interface between an application and either a PNG encoder, decoder, or editor. The precise
      form in which an image is presented to an encoder or delivered by a decoder is not specified. Four kinds of image are
      distinguished.</p>

      <dl>
        <!-- Maintain a fragment named "3sourceImage" to preserve incoming links to it -->
        <dt><dfn id="3sourceImage">Source image</dfn></dt>
        <dd>The <i>source image</i> is the image presented to a PNG encoder.</dd>

        <!-- Maintain a fragment named "3referenceImage" to preserve incoming links to it -->
        <!-- Maintain a fragment named "3pixel" to preserve incoming links to it -->
        <dt><dfn id="3referenceImage">Reference image</dfn></dt>
        <dd>The <a>reference image</a>, which only exists conceptually, is a rectangular array of rectangular <dfn id="3pixel">pixels</dfn>, all having
        the same width and height, and all containing the same number of unsigned integer samples, either three (red, green, blue)
        or four (red, green, blue, alpha). The array of all samples of a particular kind (red, green, blue, or alpha) is called a
        <!-- Maintain a fragment named "3channel" to preserve incoming links to it -->
        <dfn id="3channel">channel</dfn>. Each channel has a sample depth in the range 1 to 16, which is the number of bits used by every sample in the
        channel. Different channels may have different sample depths. The red, green, and blue samples determine the intensities of
        the red, green, and blue components of the pixel's color; if they are all zero, the pixel is black, and if they all have
        <!-- Maintain a fragment named "3alpha" to preserve incoming links to it -->
        their maximum values (2<sup>sampledepth</sup>-1), the pixel is white. The <dfn id="3alpha">alpha</dfn> sample determines a pixel's degree of
        opacity, where zero means fully transparent and the maximum value means fully opaque. In a three-channel reference image
        all pixels are fully opaque. (It is also possible for a four-channel reference image to have all pixels fully opaque; the
        difference is that the latter has a specific alpha sample depth, whereas the former does not.) Each horizontal row of
        pixels is called a scanline. Pixels are ordered from left to right within each scanline, and scanlines are ordered from top
        to bottom. Every reference image can be represented exactly by a <a>PNG datastream</a> and every <a>PNG datastream</a> can be converted into a reference image. A PNG encoder may transform the source image directly into a PNG image, but conceptually it first transforms the
        source image into a reference image, then transforms the reference image into a PNG image. Depending on the type of source
        image, the transformation from the source image to a reference image may require the loss of information. That
        transformation is beyond the scope of this International Standard. The reference image, however, can always be recovered
        exactly from a PNG datastream.</dd>

        <!-- Maintain a fragment named "3PNGimage" to preserve incoming links to it -->
        <dt><dfn id="3PNGimage">PNG image</dfn></dt>
        <dd>The <i>PNG image</i> is obtained from the reference image by a series of transformations: <a>alpha separation</a>,
        <a>indexing</a>, <a>RGB merging</a>, <a>alpha compaction</a>, and <a>sample depth scaling</a>. Five types of PNG image are defined
        (see <a href="#6Colour-values"></a>). (If the PNG encoder actually transforms the source image directly into the PNG image,
        and the source image format is already similar to the PNG image format, the encoder may be able to avoid doing some of
        these transformations.) Although not all sample depths in the range 1 to 16 bits are explicitly supported in the PNG image,
        the number of significant bits in each channel of the reference image may be recorded. All channels in the PNG image have
        the same sample depth. A PNG encoder generates a PNG datastream from the PNG image. A PNG decoder takes the PNG datastream
        and recreates the PNG image.
        </dd>

        <!-- Maintain a fragment named "3deliveredImage" to preserve incoming links to it -->
        <dt><dfn id="3deliveredImage">Delivered image</dfn></dt>
        <dd>The <a>delivered image</a> is constructed from the PNG image obtained by decoding a PNG datastream. No specific format
        is specified for the <a>delivered image</a>. A viewer presents an image to the user as close to the appearance of the
        original source image as it can achieve.
        </dd>
      </dl>

      <p>The relationships between the four kinds of image are illustrated in <a href="#image-relationship"></a>.</p>

      <figure id="image-relationship">
        <!-- Maintain a fragment named "figure41" to preserve incoming links to it -->
         <object id="figure41" data="figures/image-relationships.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Relationships between source, reference, PNG, and display images
        </figcaption>
      </figure>
      
      

      <p>The relationships between samples, channels, pixels, and sample depth are illustrated in <a href=
      "#sample-pixel-channel-relationship"></a>.</p>

      <figure id="sample-pixel-channel-relationship">
        <!-- Maintain a fragment named "figure42" to preserve incoming links to it -->
         <object id="figure42" data="figures/sample-pixel-channel-relationship.svg" type="image/svg+xml" width="640" height="290">
        </object>
        <figcaption>
          Relationships between sample, sample depth, pixel, and channel
        </figcaption>
      </figure>
    </section>
    <!-- Maintain a fragment named "4Concepts.ColourSpaces" to preserve incoming links to it -->

    <section id="4Concepts.ColourSpaces">
      <h2>Color spaces</h2>

      <p>The RGB color space in which color samples are situated may be specified in one of four ways:</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>by CICP image format signaling metadata;</li>

        <li>by an ICC profile;</li>

        <li>by specifying explicitly that the color space is sRGB when the samples conform to this color space;</li>

        <li>by specifying a <a>gamma value</a> and the 1931 CIE <i>x,y</i> chromaticities of the red, green, and blue primaries
        used in the image and the reference <a>white point</a>.
        </li>
      </ol>

      <p>For high-end applications the first two methods provides the most flexibility and control. The third method enables one
      particular, but extremely common, color space to be indicated. The fourth method, which was standardized before ICC profiles
      were widely adopted, enables the exact chromaticities of the RGB data to be specified, along with the <a>gamma</a> correction
      to be applied (see <a href="#C-GammaAppendix"></a>). However, color-aware applications will prefer one of the first three
      methods, while color-unaware applications will typically ignore all four methods.</p>

      <p><a href="#color-chunk-precendence"></a> is a list of chunk types that provide color space information,
      each with an associated Priority number. If a single image contains more than one of these chunk types,
      the chunk with the lowest Priority number should take precedence and any higher-numbered chunk types should be ignored.</p>

      <table id="color-chunk-precendence" class="numbered simple">
        <caption>
          Color Chunk Priority
        </caption>

        <tr>
          <th>Chunk Type</th>
          <th>Priority</th>
        </tr>

        <tr>
          <td><a href="#cICP-chunk" class="chunk">cICP</a></td>
          <td>1</td>
        </tr>

        <tr>
          <td><a class="chunk" href="#11iCCP">iCCP</a></td>
          <td>2</td>
        </tr>

        <tr>
          <td><a class="chunk" href="#11sRGB">sRGB</a></td>
          <td>3</td>
        </tr>

        <tr>
          <td><a class="chunk" href="#11cHRM">cHRM</a> and <a class="chunk" href="#11gAMA">gAMA</a></td>
          <td>4</td>
        </tr>
      </table>

      <p><a>Gamma</a> correction is not applied to the alpha channel, if present. Alpha samples are always full-range and represent 
      a linear fraction of full opacity.</p>

      <p>Mastering metadata may also be provided.</p>
    </section>
    <!-- Maintain a fragment named "4Concepts.PNGImageTransformation" to preserve incoming links to it -->

    <section id="4Concepts.PNGImageTransformation">
      <h2>Reference image to PNG image transformation</h2>
      <!-- Maintain a fragment named "4Concepts.Introduction" to preserve incoming links to it -->

      <section class="introductory" id="4Concepts.Introduction">
        <h3>Introduction</h3>

        <p>A number of transformations are applied to the reference image to create the PNG image to be encoded (see <a href=
        "#reference-to-png-transformation"></a>). The transformations are applied in the following sequence, where square brackets
        mean the transformation is optional:</p>

        <pre>
        [alpha separation]
        indexing or ( [RGB merging] [alpha compaction] )
        sample depth scaling
</pre>
        <p>When every pixel is either fully transparent or fully opaque, the <a>alpha separation</a>, <a>alpha compaction</a>, and
        <a>indexing</a> transformations can cause the recovered reference image to have an alpha sample depth different from the
        original reference image, or to have no alpha channel. This has no effect on the degree of opacity of any pixel. The two
        reference images are considered equivalent, and the transformations are considered lossless. Encoders that nevertheless
        wish to preserve the alpha sample depth may elect not to perform transformations that would alter the alpha sample
        depth.</p>
        
        

        <figure id="reference-to-png-transformation">
          <!-- Maintain a fragment named "figure43" to preserve incoming links to it -->
           <object id="figure43" data="figures/reference-to-png-transformation.svg" type="image/svg+xml" height="525" width="370">
          </object>
          <figcaption>
            Reference image to PNG image transformation
          </figcaption>
        </figure>
      </section>
      <!-- Maintain a fragment named "4Concepts.Implied-alpha" to preserve incoming links to it -->
      <section id="4Concepts.Implied-alpha">
        <!-- Maintain a fragment named "3alphaSeparation" to preserve incoming links to it -->
        <h2><dfn id="3alphaSeparation">Alpha separation</dfn></h2>

        <p>If all alpha samples in a reference image have the maximum value, then the alpha channel may be omitted, resulting in an
        equivalent image that can be encoded more compactly.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.Indexing" to preserve incoming links to it -->

      <section id="4Concepts.Indexing">
        <h2>Indexing</h2>

        <p>If the number of distinct pixel values is 256 or less, and the RGB sample depths are not greater than 8, and the alpha
        channel is absent or exactly 8 bits deep or every pixel is either fully transparent or fully opaque, then the alternative
        <a>indexed-color</a> representation, achieved through an <dfn id="3indexing">indexing</dfn> transformation, may be more efficient for encoding.
        <!-- Maintain a fragment named "3indexing" to preserve incoming links to it -->
        <!-- Maintain a fragment named "3palette" to preserve incoming links to it -->
        <!-- Maintain a fragment named "3alphaTable" to preserve incoming links to it -->
        <!-- Maintain a fragment named "3indexedColour" to preserve incoming links to it -->
        In the <dfn id="3indexedColour">indexed-color</dfn> representation, each pixel is replaced by an index into a palette. The <dfn id="3palette">palette</dfn>
        is a list of entries each containing three 8-bit samples (red, green, blue). If an alpha channel is present, there is also
        a parallel table of 8-bit alpha samples, called the <dfn id="3alphaTable">alpha table</dfn>.</p>
        
        

        <figure id="indexed-colour-image">
          <!-- Maintain a fragment named "figure44" to preserve incoming links to it -->
           <object id="figure44" height="450" width="660" data="figures/indexed-colour-image.svg" type="image/svg+xml">
          </object>
          <figcaption>
            Indexed-color image
          </figcaption>
        </figure>

        <p>A suggested palette or palettes may be constructed even when the PNG image is not <a>indexed-color</a> in order to assist
        viewers that are capable of displaying only a limited number of colors.</p>

        <p>For <a>indexed-color</a> images, encoders can rearrange the palette so that the table entries with the maximum alpha value are
        grouped at the end. In this case the table can be encoded in a shortened form that does not include these entries.</p>

        <p>Encoders creating indexed-color PNG must not insert index values greater than the actual length of the palette table; to
        do so is an error, and decoders will vary in their handling of this error.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.RGBMerging" to preserve incoming links to it -->

      <section id="4Concepts.RGBMerging">
        <!-- Maintain a fragment named "3RGBmerging" to preserve incoming links to it -->

        <h2><dfn id="3RGBmerging">RGB merging</dfn>
        </h2>

        <p>If the red, green, and blue channels have the same sample depth, and, for each pixel, the values of the red, green, and
        blue samples are equal, then these three channels may be merged into a single greyscale channel.</p>
      </section>

      <!-- Maintain a fragment named "4Concepts.Alpha-indexing" to preserve incoming links to it -->
      <section id="4Concepts.Alpha-indexing">
        <!-- Maintain a fragment named "3alphaCompaction" to preserve incoming links to it -->
        <h2><dfn id="3alphaCompaction">Alpha compaction</dfn></h2>

        <p>For non-indexed images, if there exists an RGB (or greyscale) value such that all pixels with that value are fully
        transparent while all other pixels are fully opaque, then the alpha channel can be represented more compactly by merely
        identifying the RGB (or greyscale) value that is transparent.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.Scaling" to preserve incoming links to it -->

      <section id="4Concepts.Scaling">
        <!-- Maintain a fragment named "3sampleDepthScaling" to preserve incoming links to it -->

        <h2><dfn id="3sampleDepthScaling">Sample depth scaling</dfn>
        </h2>

        <p>In the PNG image, not all sample depths are supported (see <a href="#6Colour-values"></a>), and all channels shall have
        the same sample depth. All channels of the PNG image use the smallest allowable sample depth that is not less than any
        sample depth in the reference image, and the possible sample values in the reference image are linearly mapped into the
        next allowable range for the PNG image. <a href="#scaling-sample-values"></a> shows how samples of depth 3 might be mapped
        into samples of depth 4.</p>
        
        

        <figure id="scaling-sample-values">
          <!-- Maintain a fragment named "figure45" to preserve incoming links to it -->
           <object id="figure45" height="320" width="280" data="figures/scaling-sample-values.svg" type="image/svg+xml">
          </object>
          <figcaption>
            Scaling sample values
          </figcaption>
        </figure>

        <p>Allowing only a few sample depths reduces the number of cases that decoders have to cope with. <a>Sample depth
        scaling</a> is reversible with no loss of data, because the reference image sample depths can be recorded in the PNG
        datastream. In the absence of recorded sample depths, the reference image sample depth equals the PNG image sample depth.
        See <a href="#12Sample-depth-scaling"></a> and <a href="#13Sample-depth-rescaling"></a>.</p>

        <figure id="possible-pixel-types">
          <!-- Maintain a fragment named "figure46" to preserve incoming links to it -->
           <object id="figure46" data="figures/possible-pixel-types.svg" type="image/svg+xml">
          </object>
          <figcaption>
            Possible PNG image pixel types
          </figcaption>
        </figure>
      </section>
    </section>
    
    
    <!-- Maintain a fragment named "4Concepts.PNGImage" to preserve incoming links to it -->

    <section id="4Concepts.PNGImage">
      <h2>PNG image</h2>

      <p>The transformation of the reference image results in one of five types of PNG image (see <a href=
      "#possible-pixel-types"></a>) :</p>
      <!-- <ol start="1"> -->

      <dl>
        <dt><dfn>Truecolor with alpha</dfn></dt>
        <dd>Each <a>pixel</a> consists of four <a>samples</a>: red, green, blue and <a>alpha</a>.</dd>

        <dt><dfn>Greyscale with alpha</dfn></dt>
        <dd>Each <a>pixel</a> consists of two <a>samples</a>: a <a>grey sample</a> and an <a>alpha</a> sample.</dd>

        <!-- Maintain a fragment named "3truecolour" to preserve incoming links to it -->
        <dt id="truecolor"><dfn id="3truecolour">Truecolor</dfn></dt>
        <dd>Each <a>pixel</a> consists of a triplet of <a>samples</a>: red, green, blue. An optional alpha channel can be specified
        as a single triplet of red, green, blue <a>samples</a>: <a>pixels</a> of the image whose red, green, blue <a>samples</a>
        are identical to the red, green, blue <a>samples</a> of the alpha channel are fully transparent; others are fully opaque. If
        the alpha channel is not present, all <a>pixels</a> are fully opaque.</dd>

        <dt><dfn>Greyscale</dfn></dt>
        <!-- Maintain a fragment named "3greyscale" to preserve incoming links to it -->
        <dd>Each pixel consists of a single <dfn  id="3greyscale">grey sample</dfn>, which represents overall
        <a>luminance</a> (on a scale from black to white). An optional alpha channel can be specified as a single <a>grey
        sample</a>: <a>pixels</a> of the image whose <a>grey sample</a> is identical to the <a>grey sample</a> of the alpha channel
        are fully transparent; others are fully opaque. If the alpha channel is not present, all <a>pixels</a> are fully
        opaque.</dd>

        <dt><a>Indexed-color</a></dt>
        <dd>Each pixel consists of an index into a palette (and into an associated table of alpha values, if present).</dd>
      </dl>

      <p>The format of each pixel depends on the PNG image type and the bit depth. For PNG image types other than indexed-color,
      the bit depth specifies the number of bits per sample, not the total number of bits per pixel. For <a>indexed-color</a> images, the
      bit depth specifies the number of bits in each palette index, not the sample depth of the colors in the palette or alpha
      table. Within the pixel the samples appear in the following order, depending on the PNG image type.</p>
      <!-- <ol start="6"> -->

      <ol>
        <li><a>Truecolor with alpha</a>: red, green, blue, alpha.</li>

        <li><a>Greyscale with alpha</a>: grey, alpha.</li>

        <li><a>Truecolor</a>: red, green, blue.</li>

        <li><a>Greyscale</a>: grey.</li>

        <li><a>Indexed-color</a>: palette index.</li>
      </ol>
    </section>
    <!-- Maintain a fragment named "4Concepts.Encoding" to preserve incoming links to it -->

    <section id="4Concepts.Encoding">
      <h2>Encoding the PNG image</h2>
      <!-- Maintain a fragment named "4Concepts.EncodingIntro" to preserve incoming links to it -->

      <section class="introductory" id="4Concepts.EncodingIntro">
        <h3>Introduction</h3>

        <p>A conceptual model of the process of encoding a PNG image is given in <a href="#encoding-png-image"></a>. The steps
        refer to the operations on the array of pixels or indices in the PNG image. The <a>palette</a> and <a>alpha table</a> are not encoded in
        this way.</p>
        <!-- <ol start="1"> -->

        <ol>
          <li>Pass extraction: to allow for progressive display, the PNG image pixels can be rearranged to form several smaller
          images called reduced images or passes.</li>

          <li>Scanline serialization: the image is serialized a scanline at a time. Pixels are ordered left to right in a scanline
          and scanlines are ordered top to bottom.</li>

          <li>Filtering: each scanline is transformed into a filtered scanline using one of the defined filter types to prepare the
          scanline for image compression.</li>

          <li>Compression: occurs on all the filtered scanlines in the image.</li>

          <li>Chunking: the compressed image is divided into conveniently sized chunks. An error detection code is added to each
          chunk.</li>

          <li>Datastream construction: the chunks are inserted into the datastream.</li>
        </ol>
      </section>
      <!-- Maintain a fragment named "4Concepts.EncodingPassAbs" to preserve incoming links to it -->

      <section id="4Concepts.EncodingPassAbs">
        <h2>Pass extraction</h2>
        <!-- Maintain a fragment named "3reducedImage" to preserve incoming links to it -->
        <!-- Maintain a fragment named "3passExtraction" to preserve incoming links to it -->
        <p><dfn id="3passExtraction">Pass extraction</dfn> (see <a href="#encoding-png-image"></a>) splits a PNG image into a sequence of <dfn id="3reducedImage">reduced images</dfn> where the
        first image defines a coarse view and subsequent images enhance this coarse view until the last image completes the PNG
        image. The set of reduced images is also called an interlaced PNG image. Two interlace methods are defined in this
        specification. The first method is a null method; pixels are stored sequentially from left to right and scanlines from top
        to bottom. The second method makes multiple scans over the image to produce a sequence of seven reduced images. The seven
        passes for a sample image are illustrated in <a href="#encoding-png-image"></a>. See <a href="#8Interlace"></a>.</p>
        
        

        <figure id="encoding-png-image">
          <!-- Maintain a fragment named "figure47" to preserve incoming links to it -->
           <object id="figure47" data="figures/encoding-png-image.svg" type="image/svg+xml">
          </object>
          <figcaption>
            Encoding the PNG image
          </figcaption>
        </figure>

        <figure id="pass-extraction">
          <!-- Maintain a fragment named "figure48" to preserve incoming links to it -->
           <object id="figure48" data="figures/pass-extraction.svg" type="image/svg+xml">
          </object>
          <figcaption>
            Pass extraction
          </figcaption>
        </figure>
      </section>
      
      
      <!-- Maintain a fragment named "4Concepts.EncodingScanlineAbs" to preserve incoming links to it -->

      <section id="4Concepts.EncodingScanlineAbs">
        <h2>Scanline serialization</h2>

        <p>Each row of pixels, called a scanline, is represented as a sequence of bytes.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.EncodingFiltering" to preserve incoming links to it -->

      <section id="4Concepts.EncodingFiltering">
        <h2>Filtering</h2>

        <p>PNG allows <a>image data</a> to be filtered before it is compressed. Filtering can improve the compressibility of the
        data. The filter operation is deterministic, reversible, and lossless. This allows the decompressed data to be
        reverse-filtered in order to obtain the original data. See <a href="#7Filtering"></a>.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.EncodingCompression" to preserve incoming links to it -->

      <section id="4Concepts.EncodingCompression">
        <h2>Compression</h2>

        <p>The sequence of filtered scanlines in the pass or passes of the PNG image is compressed (see <a href=
        "#compression"></a>) by one of the defined compression methods. The concatenated filtered scanlines form the input to the
        compression stage. The output from the compression stage is a single compressed datastream. See <a href=
        "#10Compression"></a>.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.EncodingChunking" to preserve incoming links to it -->

      <section id="4Concepts.EncodingChunking">
        <h2>Chunking</h2>

        <p>Chunking provides a convenient breakdown of the compressed datastream into manageable chunks (see <a href=
        "#compression"></a>). Each chunk has its own redundancy check. See <a href="#11Chunks"></a>.</p>
        
        

        <figure id="compression">
          <!-- Maintain a fragment named "figure410" to preserve incoming links to it -->
           <object id="figure410" data="figures/compression.svg" type="image/svg+xml">
          </object>
          <figcaption>
            Compression and chunking
          </figcaption>
        </figure>
      </section>
    </section>
    <!-- Maintain a fragment named "4Concepts.AncillInfo" to preserve incoming links to it -->

    <section id="4Concepts.AncillInfo">
      <h2>Additional information</h2>

      <p>Ancillary information may be associated with an image. Decoders may ignore all or some of the ancillary information. The
      types of ancillary information provided are described in <a href="#table41"></a>.</p>
      <!-- Maintain a fragment named "table41" to preserve incoming links to it -->

      <table id="table41" class="simple numbered">
        <caption>
          Types of ancillary information
        </caption>

        <tr>
          <th>Type of information</th>
          <th>Description</th>
        </tr>

        <tr>
          <td>Animation information</td>
          <td>
            An animated image, defined as a series of frames with associated timing, position and handling information, to be
            displayed if the viewer is capable of doing so. For other cases such as printers, the <a>static image</a> will be
            displayed instead.
          </td>
        </tr>

        <tr>
          <td>Background color</td>
          <td>Solid background color to be used when presenting the image if no better option is available.</td>
        </tr>

        <tr>
          <td>Coding-independent code points</td>
          <td>
            Identifies the color space by enumerating metadata such as the <a>transfer function</a> and color primaries.

            Originally for <a>SDR</a> and <a>HDR</a> video, also used for still and animated images.
          </td>
        </tr>

        <tr>
          <td>Content Light Level Information</td>
          <td><a>Luminance</a> of the brightest pixel in the image (or image sequence) and the average luminance level of the brightest frame in the sequence.</td>
        </tr>

        <tr>
          <td>EXIF information</td>
          <td>Exchangeable image file format metadata such as shutter speed, aperture, and orientation</td>
        </tr>

        <tr>
          <td>Gamma and chromaticity</td>
          <td>
            <a>Gamma value</a> of the image with respect to the desired output intensity, and <a>chromaticity</a> characteristics
            of the RGB values used in the image.
          </td>
        </tr>

        <tr>
          <td>ICC profile</td>
          <td>Description of the color space (in the form of an International Color Consortium (ICC) profile) to which the samples
          in the image conform.</td>
        </tr>

        <tr>
          <td>Image histogram</td>
          <td>Estimates of how frequently the image uses each palette entry.</td>
        </tr>

        <tr>
          <td>Mastering Display Color Volume</td>
          <td>Describes the absolute three-dimensional color gamut volume of the display used to prepare the content, including the lightest and darkest colors the mastering display can reproduce. This helps to present the image on the display device.</td>
        </tr>

        <tr>
          <td>Physical pixel dimensions</td>
          <td>Intended pixel size and aspect ratio to be used in presenting the PNG image.</td>
        </tr>

        <tr>
          <td>Significant bits</td>
          <td>The number of bits that are significant in the samples.</td>
        </tr>

        <tr>
          <td>sRGB color space</td>
          <td>A rendering intent (as defined by the International Color Consortium) and an indication that the image samples
          conform to this color space.</td>
        </tr>

        <tr>
          <td>Suggested palette</td>
          <td>A reduced palette that may be used when the display device is not capable of displaying the full range of colors in
          the image.</td>
        </tr>

        <tr>
          <td>Textual data</td>
          <td>Textual information (which may be compressed) associated with the image.</td>
        </tr>

        <tr>
          <td>Time</td>
          <td>The time when the PNG image was last modified.</td>
        </tr>

        <tr>
          <td>Transparency</td>
          <td>Alpha information that allows the reference image to be reconstructed when the alpha channel is not retained in the
          PNG image.</td>
        </tr>
      </table>
    </section>
    <!-- Maintain a fragment named "4Concepts.Format" to preserve incoming links to it -->

    <section id="4Concepts.Format">
      <h2>PNG datastream</h2>
      <!-- Maintain a fragment named "4Concepts.FormatChunks" to preserve incoming links to it -->

      <section id="4Concepts.FormatChunks">
        <h2>Chunks</h2>

        <p>The PNG datastream consists of a PNG signature (see <a href="#5PNG-file-signature"></a>) followed by a sequence of
        chunks (see <a href="#11Chunks"></a>). Each chunk has a chunk type which specifies its function.</p>
      </section>
      <!-- Maintain a fragment named "4Concepts.FormatTypes" to preserve incoming links to it -->

      <section id="4Concepts.FormatTypes">
        <h2>Chunk types</h2>

        <p>Chunk types are four-byte sequences chosen so that they correspond to readable labels when interpreted in the ISO
        646.IRV:1991 [[ISO646]] character set. The first four are termed critical chunks, which shall be understood and correctly
        interpreted according to the provisions of this specification. These are:</p>
        <!-- <ol start="1"> -->

        <ol>
          <li>
            <a class="chunk" href="#11IHDR">IHDR</a>: image header, which is the first chunk in a PNG datastream.
          </li>

          <li>
            <a class="chunk" href="#11PLTE">PLTE</a>: palette table associated with indexed PNG images.
          </li>

          <li>
            <a class="chunk" href="#11IDAT">IDAT</a>: image data chunks.
          </li>

          <li>
            <a class="chunk" href="#11IEND">IEND</a>: image trailer, which is the last chunk in a PNG datastream.
          </li>
        </ol>

        <!-- Maintain a fragment named "3ancillaryChunk" to preserve incoming links to it -->
        <p>The remaining chunk types are termed <dfn class="lint-ignore" id="3ancillaryChunk">ancillary chunk</dfn> types, which encoders may generate and decoders may interpret.</p>
        <!-- <ol start="5"> -->

        <ol>
          <li>Transparency information: <a class="chunk" href="#11tRNS">tRNS</a> (see <a href="#11transinfo"></a>).
          </li>

          <li>Color space information: <a class="chunk" href="#11cHRM">cHRM</a>, <a class="chunk" href="#11gAMA">gAMA</a>,
          <a class="chunk" href="#11iCCP">iCCP</a>, <a class="chunk" href="#11sBIT">sBIT</a>, <a class="chunk" href=
          "#11sRGB">sRGB</a>, <a class="chunk" href="#cICP-chunk">cICP</a>, <a class="chunk" href="#mDCv-chunk">mDCv</a> (see
          <a href="#11addnlcolinfo"></a>).
          </li>

          <li>Textual information: <a class="chunk" href="#11iTXt">iTXt</a>, <a class="chunk" href="#11tEXt">tEXt</a>, <a class=
          "chunk" href="#11zTXt">zTXt</a> (see <a href="#11textinfo"></a>).
          </li>

          <li>Miscellaneous information: <a class="chunk" href="#11bKGD">bKGD</a>, <a class="chunk" href="#11hIST">hIST</a>,
          <a class="chunk" href="#11pHYs">pHYs</a>, <a class="chunk" href="#11sPLT">sPLT</a>, <a class="chunk" href=
          "#eXIf">eXIf</a> (see <a href="#11addnlsiinfo"></a>).
          </li>

          <li>Time information: <a class="chunk" href="#11tIME">tIME</a> (see <a href="#11timestampinfo"></a>).
          </li>

          <li>Animation information: <a class="chunk" href="#acTL-chunk">acTL</a>, <a class="chunk" href="#fcTL-chunk">fcTL</a>,
          <a class="chunk" href="#fdAT-chunk">fdAT</a> (see <a href="#animation-information"></a>).
          </li>
        </ol>
      </section>
    </section>

    <section>
      <h2>APNG: frame-based animation</h2>

      <section class="introductory">
        <h3>Introduction</h3>

        <p>Animated PNG (APNG) extends the original, static-only PNG format,
        adding support for <a>frame</a>-based animated images. It is intended to
        be a replacement for simple animated images that have traditionally used the GIF format [[GIF]], while adding support for
        24-bit images and 8-bit transparency, which GIF lacks.</p>

        <p>APNG is backwards-compatible with earlier versions of PNG; a non-animated PNG decoder will ignore the ancillary
        APNG-specific chunks and display the <a>static image</a>.</p>
      </section>

      <section>
        <h3>Structure</h3>

        <p>An APNG stream is a normal PNG stream as defined in previous versions of the PNG Specification, with three additional
        chunk types describing the animation and providing additional frame data.</p>

        <p>To be recognized as an APNG, an <a class="chunk" href="#acTL-chunk">acTL</a> chunk must appear in the stream before any
        <a class="chunk" href="#11IDAT">IDAT</a> chunks. The <a class="chunk" href="#acTL-chunk">acTL</a> structure is <a href=
        "#animation-information">described below</a>.</p>

        <p>Conceptually, at the beginning of each play the <a>output buffer</a> shall be completely initialized to a <a>fully
        transparent black</a> rectangle, with width and height dimensions from the <a class="chunk" href="#11IHDR">IHDR</a>
        chunk.</p>

        <p>The static image may be included as the first frame of the animation by the presence of a single <a class="chunk" href=
        "#fcTL-chunk">fcTL</a> chunk before <a class="chunk" href="#11IDAT">IDAT</a>. Otherwise, the static image is not part of
        the animation.</p>

        <p>Subsequent frames are encoded in <a class="chunk" href="#fdAT-chunk">fdAT</a> chunks, which have the same structure as
        <a class="chunk" href="#11IDAT">IDAT</a> chunks, except preceded by a <a href="#4Concepts.APNGSequence">sequence
        number</a>. Information for each frame about placement and rendering is stored in <a class="chunk" href=
        "#fcTL-chunk">fcTL</a> chunks. The full layout of <a class="chunk" href="#fdAT-chunk">fdAT</a> and <a class="chunk" href=
        "#fcTL-chunk">fcTL</a> chunks is <a href="#animation-information">described below</a>.</p>

        <p>The boundaries of the entire animation are specified by the width and height parameters of the <a class="chunk" href=
        "#11IHDR">IHDR</a> chunk, regardless of whether the default image is part of the animation. The default image should be
        appropriately padded with <a>fully transparent black</a> pixels if extra space will be needed for later frames.</p>

        <p>Each frame is identical for each play, therefore it is safe for applications to cache the frames.</p>
      </section>

      <section id="4Concepts.APNGSequence">
        <h3>Sequence numbers</h3>

        <p>The <a class="chunk" href="#fcTL-chunk">fcTL</a> and <a class="chunk" href="#fdAT-chunk">fdAT</a> chunks have a
        zero-based, 4 byte sequence number. Both chunk types share the sequence. The purpose of this number is to detect (and
        optionally correct) sequence errors in an Animated PNG, since this specification does not impose ordering restrictions
        on ancillary chunks.</p>

        <p>The first <a class="chunk" href="#fcTL-chunk">fcTL</a> chunk shall contain sequence number 0, and the sequence numbers
        in the remaining <a class="chunk" href="#fcTL-chunk">fcTL</a> and <a class="chunk" href="#fdAT-chunk">fdAT</a> chunks shall
        be in ascending order, with no gaps or duplicates.</p>

        <p>The tables below illustrate the use of sequence numbers for images with more than one frame, and more than one <a class=
        "chunk" href="#fdAT-chunk">fdAT</a> chunk for the second frame. (<a class="chunk" href="#11IHDR">IHDR</a> and <a class=
        "chunk" href="#11IEND">IEND</a> chunks omitted in these tables, for clarity).</p>

        <table class="numbered simple">
          <caption>
            If the static image is also the first frame
          </caption>

          <tr>
            <th>Sequence number</th>
            <th>Chunk</th>
          </tr>

          <tr>
            <td>(none)</td>
            <td>
              <a class="chunk" href="#acTL-chunk">acTL</a>
            </td>
          </tr>

          <tr>
            <td>0</td>
            <td>
              <a class="chunk" href="#fcTL-chunk">fcTL</a> first frame
            </td>
          </tr>

          <tr>
            <td>(none)</td>
            <td>
              <a class="chunk" href="#11IDAT">IDAT</a> first frame / static image
            </td>
          </tr>

          <tr>
            <td>1</td>
            <td>
              <a class="chunk" href="#fcTL-chunk">fcTL</a> second frame
            </td>
          </tr>

          <tr>
            <td>2</td>
            <td>
              first <a class="chunk" href="#fdAT-chunk">fdAT</a> for second frame
            </td>
          </tr>

          <tr>
            <td>3</td>
            <td>
              second <a class="chunk" href="#fdAT-chunk">fdAT</a> for second frame
            </td>
          </tr>
        </table>

        <table class="numbered simple">
          <caption>
            If the static image is not part of the animation
          </caption>

          <tr>
            <th>Sequence number</th>
            <th>Chunk</th>
          </tr>

          <tr>
            <td>(none)</td>
            <td>
              <a class="chunk" href="#acTL-chunk">acTL</a>
            </td>
          </tr>

          <tr>
            <td>(none)</td>
            <td>
              <a class="chunk" href="#11IDAT">IDAT</a> static image
            </td>
          </tr>

          <tr>
            <td>0</td>
            <td>
              <a class="chunk" href="#fcTL-chunk">fcTL</a> first frame
            </td>
          </tr>

          <tr>
            <td>1</td>
            <td>
              first <a class="chunk" href="#fdAT-chunk">fdAT</a> for first frame
            </td>
          </tr>

          <tr>
            <td>2</td>
            <td>
              second <a class="chunk" href="#fdAT-chunk">fdAT</a> for first frame
            </td>
          </tr>

          <tr>
            <td>3</td>
            <td>
              <a class="chunk" href="#fcTL-chunk">fcTL</a> second frame
            </td>
          </tr>

          <tr>
            <td>4</td>
            <td>
              first <a class="chunk" href="#fdAT-chunk">fdAT</a> for second frame
            </td>
          </tr>

          <tr>
            <td>5</td>
            <td>
              second <a class="chunk" href="#fdAT-chunk">fdAT</a> for second frame
            </td>
          </tr>
        </table>
      </section>

      <section id="apng-output-buffer">
        <h3>Output buffer</h3>

        <p>The <dfn>output buffer</dfn> is a pixel array with dimensions specified by the width and height parameters of the PNG <a
        class="chunk" href="#11IHDR">IHDR</a> chunk. Conceptually, each frame is constructed in the output buffer before being
        <a>composited</a> onto the <a>canvas</a>. The contents of the output buffer are available to the decoder. The corners of
        the output buffer are mapped to the corners of the <a>canvas</a>.</p>
      </section>

      <section id="apng-canvas">
        <h3>Canvas</h3>

        <p>The <dfn>canvas</dfn> is the area on the output device on which the frames are to be displayed. The contents of the
        canvas are not necessarily available to the decoder. If a <a class="chunk" href="#11bKGD">bKGD</a> chunk exists, it may be
        used to fill the canvas if there is no preferable background.</p>
      </section>

    </section>
    <!-- Maintain a fragment named "4Concepts.Errors" to preserve incoming links to it -->

    <section id="4Concepts.Errors">
      <h2>Error handling</h2>

      <p>Errors in a PNG datastream fall into two general classes:</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>transmission errors or damage to a computer file system, which tend to corrupt much or all of the datastream;</li>

        <li>syntax errors, which appear as invalid values in chunks, or as missing or misplaced chunks. Syntax errors can be caused
        not only by encoding mistakes, but also by the use of registered or private values, if those values are unknown to the
        decoder.</li>
      </ol>

      <p>PNG decoders should detect errors as early as possible, recover from errors whenever possible, and fail gracefully
      otherwise. The error handling philosophy is described in detail in <a href="#13Decoders.Errors"></a>.</p>
    </section>
    <!-- Maintain a fragment named "4Concepts.Registration" to preserve incoming links to it -->

    <section class="informative" id="4Concepts.Registration">
      <h2>Extensions</h2>

      <p>The PNG format exposes several extension points:</p>

      <ul>
        <li>
          <a href="#sec-defining-new-chunks">chunk type</a>;
        </li>

        <li>
          <a href="#11tEXt">text keyword</a>; and
        </li>

        <li>
          <a>private field values</a>.
        </li>
      </ul>

      <p>Some of these extension points are reserved by W3C, while others are available for private use.</p>
    </section>
  </section>
  <!-- Maintain a fragment named "5DataRep" to preserve incoming links to it -->

  <section id="5DataRep">
    <h2>Datastream structure</h2>
    <!-- Maintain a fragment named "5Introduction" to preserve incoming links to it -->

    <section id="5Introduction">
      <h2>PNG datastream</h2>

      <!-- Maintain a fragment named "3PNGdatastream" to preserve incoming links to it -->
      <p>The <dfn id="3PNGdatastream">PNG datastream</dfn> consists of a PNG signature followed by a sequence of chunks. It
      is the result of encoding a <a>PNG image</a>.</p>

      <p class="note">The term datastream is used rather than "file" to describe a byte sequence that may be only a portion of a
      file. It is also used to emphasize that the sequence of bytes might be generated and consumed "on the fly", never appearing in
      a stored file at all.</p>
    </section>
    <!-- Maintain a fragment named "5PNG-file-signature" to preserve incoming links to it -->

    <section id="5PNG-file-signature">
      <!-- Maintain a fragment named "3PNGsignature" to preserve incoming links to it -->
      <h2 id="3PNGsignature">PNG signature</h2>

      <p>The first eight bytes of a PNG datastream always contain the following hexadecimal values:</p>

      <pre>
  <!-- 137 80 78 71 13 10 26 10 -->
  89 50 4E 47 0D 0A 1A 0A
</pre>
      <p>This signature indicates that the remainder of the datastream contains a single PNG image, consisting of a series of
      chunks beginning with an <a class="chunk" href="#11IHDR">IHDR</a> chunk and ending with an <a class="chunk" href=
      "#11IEND">IEND</a> chunk.</p>

      <p>This signature differentiates a PNG datastream from other types of <a>datastream</a> and allows early detection of some
      transmission errors.</p>
    </section>
    <!-- Maintain a fragment named "5Chunk-layout" to preserve incoming links to it -->

    <section id="5Chunk-layout">
      <h2>Chunk layout</h2>

      <!-- Maintain a fragment named "3chunk" to preserve incoming links to it -->
      <p>Each <dfn id="3chunk">chunk</dfn> consists of three or four fields (see <a href="#figure411"></a>). The meaning of the fields is described in
      <a href="#table51"></a>. The chunk data field may be empty.</p>

      <figure id="figure411">
        <!-- Maintain a fragment named "figure411" to preserve incoming links to it -->
         <object style="width: 70vw" data="figures/chunk-parts.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Chunk parts
        </figcaption>
      </figure>
      <!-- Maintain a fragment named "table51" to preserve incoming links to it -->

      <table id="table51" class="numbered simple">
        <caption>
          Chunk fields
        </caption>

        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>

        <tr>
          <td>Length</td>
          <td>
            A <a>PNG four-byte unsigned integer</a> giving the number of bytes in the chunk's data field. The length counts
            <strong>only</strong> the data field, <strong>not</strong> itself, the chunk type, or the CRC. Zero is a valid
            length. Although encoders and decoders should treat the length as unsigned, its value shall not exceed 2<sup>31</sup>-1
            bytes.
          </td>
        </tr>

        <tr>
          <td>Chunk Type</td>
          <td>
            A sequence of four bytes defining the chunk type. Each byte of a chunk type is restricted to the hexadecimal values 41
            to 5A and 61 to 7A. These correspond to the uppercase and lowercase ISO 646 [[ISO646]] letters
            (<code>A</code>-<code>Z</code> and <code>a</code>-<code>z</code>) respectively for convenience in description and
            examination of PNG datastreams. Encoders and decoders shall treat the chunk types as fixed binary values, not character
            strings. For example, it would not be correct to represent the chunk type <a class="chunk" href="#11IDAT">IDAT</a> by
            the equivalents of those letters in the UCS 2 character set. Additional naming conventions for chunk types are
            discussed in <a href="#5Chunk-naming-conventions"></a>.
          </td>
        </tr>

        <tr>
          <td>Chunk Data</td>
          <td>The data bytes appropriate to the chunk type, if any.
            <span id="zero-length-data">This field can be of zero length.</span></td>
        </tr>

        <tr>
          <td>CRC</td>
          <td>
            A four-byte CRC calculated on the preceding bytes in the chunk, including the chunk type field and chunk data
            fields, but <strong>not</strong> including the length field. The CRC can be used to check for corruption of the
            data. The CRC is always present, even for chunks containing no data. See <a href="#5CRC-algorithm"></a>.
          </td>
        </tr>
      </table>

      <p>The chunk data length may be any number of bytes up to the maximum; therefore, implementors cannot assume that chunks are
      aligned on any boundaries larger than bytes.</p>
    </section>
    
    
    <!-- Maintain a fragment named "5Chunk-naming-conventions" to preserve incoming links to it -->

    <section id="5Chunk-naming-conventions">
      <h2>Chunk naming conventions</h2>

      <p>Chunk types are chosen to be meaningful names when the bytes of the chunk type are interpreted as ISO 646 letters
      [[ISO646]]. Chunk types are assigned so that a decoder can determine some properties of a chunk even when the type is not
      recognized. These rules allow safe, flexible extension of the PNG format, by allowing a PNG decoder to decide what to do when
      it encounters an unknown chunk.</p>

      <p>The naming rules are normally of interest only when the decoder does not recognize the chunk's type, as specified at
      <a href="#13Decoders"></a>.</p>

      <p>Four bits of the chunk type, the property bits, namely bit 5 (value 32) of each byte, are used to convey chunk properties.
      This choice means that a human can read off the assigned properties according to whether the letter corresponding to each
      byte of the chunk type is uppercase (bit 5 is 0) or lowercase (bit 5 is 1).</p>

      <p>The property bits are an inherent part of the chunk type, and hence are fixed for any chunk type. Thus, <span class=
      "chunk">CHNK</span> and <span class="chunk">cHNk</span> would be unrelated chunk types, not the same chunk with different
      properties.</p>

      <p>The semantics of the property bits are defined in <a href="#table52"></a>.</p>
      <!-- Maintain a fragment named "table52" to preserve incoming links to it -->

      <table id="table52" class="numbered simple">
        <caption>
          Semantics of property bits
        </caption>

        <tr>
          <th>Name &amp; location</th>
          <th>Definition</th>
          <th>Description</th>
        </tr>

        <tr>
          <td>Ancillary bit: first byte</td>
          <td>0 (uppercase) = critical,<br>
          1 (lowercase) = ancillary.</td>
          <td>
            Critical chunks are necessary for successful display of the contents of the datastream, for example the image header
            chunk (<a class="chunk" href="#11IHDR">IHDR</a>). A decoder trying to extract the image, upon encountering an unknown
            chunk type in which the ancillary bit is 0, shall indicate to the user that the image contains information it cannot
            safely interpret.<br>
            Ancillary chunks are not strictly necessary in order to meaningfully display the contents of the datastream, for
            example the time chunk ( <a class="chunk" href="#11tIME">tIME</a>). A decoder encountering an unknown chunk type in
            which the ancillary bit is 1 can safely ignore the chunk and proceed to display the image.
          </td>
        </tr>

        <tr>
          <td>Private bit: second byte</td>
          <td>0 (uppercase) = public,<br>
          1 (lowercase) = private.</td>
          <td>
            Public chunks are reserved for definition by the W3C. The definition of private chunks is specified at <a href=
            "#12Use-of-private-chunks"></a>. The names of private chunks have a lowercase second letter, while the names of public
            chunks have uppercase second letters.
          </td>
        </tr>

        <tr>
          <td>Reserved bit: third byte</td>
          <td>0 (uppercase) in this version of PNG.<br>
          If the reserved bit is 1, the datastream does not conform to this version of PNG.</td>
          <td>The significance of the case of the third letter of the chunk name is reserved for possible future extension. In this
          International Standard, all chunk names shall have uppercase third letters.</td>
        </tr>

        <tr>
          <td>Safe-to-copy bit: fourth byte</td>
          <td>0 (uppercase) = unsafe to copy,<br>
          1 (lowercase) = safe to copy.</td>
          <td>
            This property bit is not of interest to pure decoders, but it is needed by <a>PNG editors</a>. This bit defines the
            proper handling of unrecognized chunks in a datastream that is being modified. Rules for <a>PNG editors</a> are
            discussed further in <a href="#14Ordering"></a>.
          </td>
        </tr>
      </table>

      <p class="example">The hypothetical chunk type "<span class="chunk">cHNk</span>" has the property bits:</p>

      <pre>
   cHNk  &lt;-- 32 bit chunk type represented in text form
   ||||
   |||+- Safe-to-copy bit is 1 (lower case letter; bit 5 is 1)
   ||+-- Reserved bit is 0     (upper case letter; bit 5 is 0)
   |+--- Private bit is 0      (upper case letter; bit 5 is 0)
   +---- Ancillary bit is 1    (lower case letter; bit 5 is 1)
</pre>
      <p>Therefore, this name represents an ancillary, public, safe-to-copy chunk.</p>
    </section>
    <!-- Maintain a fragment named "5CRC-algorithm" to preserve incoming links to it -->

    <section id="5CRC-algorithm">
      <h2>CRC algorithm</h2>

      <p>CRC fields are calculated using standardized CRC methods with pre and post conditioning, as defined by [[ISO-3309]] and [[ITU-T-V.42]]. The CRC polynomial employed— which is identical to that used in the GZIP file format
      specification [[RFC1952]]— is</p>

      <p>x<sup>32</sup> + x<sup>26</sup> + x<sup>23</sup> + x<sup>22</sup> + x<sup>16</sup> + x<sup>12</sup> + x<sup>11</sup> +
      x<sup>10</sup> + x<sup>8</sup> + x<sup>7</sup> + x<sup>5</sup> + x<sup>4</sup> + x<sup>2</sup> + x + 1</p>

      <p>In PNG, the 32-bit CRC is initialized to all 1's, and then the data from each byte is processed from the least
      significant bit (1) to the most significant bit (128). After all the data bytes are processed, the CRC is inverted
      (its ones complement is taken). This value is transmitted (stored in the datastream) MSB first. For the purpose of separating
      into bytes and ordering, the least significant bit of the 32-bit CRC is defined to be the coefficient of the
      <code>x<sup>31</sup></code> term.</p>

      <p>Practical calculation of the CRC often employs a precalculated table to accelerate the computation. See <a href=
      "#D-CRCAppendix"></a>.</p>
    </section>
    <!-- Maintain a fragment 5ChunkOrderingg" to preserve incoming links to it -->

    <section id="5ChunkOrdering">
      <h2>Chunk ordering</h2>

      <p>The constraints on the positioning of the individual chunks are listed in <a href="#table53"></a> and illustrated
      diagrammatically for static images in <a href="#lattice-diagram-with-plte"></a> and <a href=
      "#lattice-diagram-without-plte"></a>, for animated images where the static image forms the first frame in <a href=
      "#lattice-apng-static-with-plte"></a> and <a href="#lattice-apng-static-without-plte"></a>, and for animated images where the
      static image is not part of the animation in <a href="#lattice-apng-nostatic-with-plte"></a> and <a href=
      "#lattice-apng-nostatic-without-plte"></a>. These lattice diagrams represent the constraints on positioning imposed by this
      specification. The lines in the diagrams define partial ordering relationships. Chunks higher up shall appear before chunks
      lower down. Chunks which are horizontally aligned and appear between two other chunk types (higher and lower than the
      horizontally aligned chunks) may appear in any order between the two higher and lower chunk types to which they are
      connected. The superscript associated with the chunk type is defined in <a href="#table54"></a>. It indicates whether the
      chunk is mandatory, optional, or may appear more than once. A vertical bar between two chunk types indicates
      alternatives.</p>
      
      
      <!-- Maintain a fragment named "table53" to preserve incoming links to it -->

      <table id="table53" class="numbered simple">
        <caption>
          Chunk ordering rules
        </caption>

        <tr>
          <th colspan="3">Critical chunks<br>
          (shall appear in this order, except PLTE is optional)</th>
        </tr>

        <tr>
          <th>Chunk name</th>
          <th>Multiple allowed</th>
          <th>Ordering constraints</th>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11IHDR">IHDR</a>
          </td>
          <td>No</td>
          <td>Shall be first</td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11PLTE">PLTE</a>
          </td>
          <td>No</td>
          <td>
            Before first <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
          <td>Yes</td>
          <td>
            Multiple <a class="chunk" href="#11IDAT">IDAT</a> chunks shall be consecutive
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11IEND">IEND</a>
          </td>
          <td>No</td>
          <td>Shall be last</td>
        </tr>

        <tr>
          <th colspan="3">Ancillary chunks<br>
          (need not appear in this order)</th>
        </tr>

        <tr>
          <th>Chunk name</th>
          <th>Multiple allowed</th>
          <th>Ordering constraints</th>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#acTL-chunk">acTL</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11cHRM">cHRM</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#cICP-chunk">cICP</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11gAMA">gAMA</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11iCCP">iCCP</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>. If the <a class="chunk"
            href="#11iCCP">iCCP</a> chunk is present, the <a class="chunk" href="#11sRGB">sRGB</a> chunk should not be present.
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#mDCv-chunk">mDCv</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>.
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#cLLi-chunk">cLLi</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>.
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11sBIT">sBIT</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11sRGB">sRGB</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11IDAT">IDAT</a>. If the <a class="chunk"
            href="#11sRGB">sRGB</a> chunk is present, the <a class="chunk" href="#11iCCP">iCCP</a> chunk should not be present.
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11bKGD">bKGD</a>
          </td>
          <td>No</td>
          <td>
            After <a class="chunk" href="#11PLTE">PLTE</a>; before <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11hIST">hIST</a>
          </td>
          <td>No</td>
          <td>
            After <a class="chunk" href="#11PLTE">PLTE</a>; before <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11tRNS">tRNS</a>
          </td>
          <td>No</td>
          <td>
            After <a class="chunk" href="#11PLTE">PLTE</a>; before <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#eXIf">eXIf</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#fcTL-chunk">fcTL</a>
          </td>
          <td>Yes</td>
          <td>
            One may occur before <a class="chunk" href="#11IDAT">IDAT</a>; all others shall be after <a class="chunk" href=
            "#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11pHYs">pHYs</a>
          </td>
          <td>No</td>
          <td>
            Before <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11sPLT">sPLT</a>
          </td>
          <td>Yes</td>
          <td>
            Before <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#fdAT-chunk">fdAT</a>
          </td>
          <td>Yes</td>
          <td>
            After <a class="chunk" href="#11IDAT">IDAT</a>
          </td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11tIME">tIME</a>
          </td>
          <td>No</td>
          <td>None</td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11iTXt">iTXt</a>
          </td>
          <td>Yes</td>
          <td>None</td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11tEXt">tEXt</a>
          </td>
          <td>Yes</td>
          <td>None</td>
        </tr>

        <tr>
          <td>
            <a class="chunk" href="#11zTXt">zTXt</a>
          </td>
          <td>Yes</td>
          <td>None</td>
        </tr>
      </table>
      <!-- Maintain a fragment named "table54" to preserve incoming links to it -->

      <table id="table54" class="numbered simple">
        <caption>
          Meaning of symbols used in lattice diagrams
        </caption>

        <tr>
          <th>Symbol</th>
          <th>Meaning</th>
        </tr>

        <tr>
          <td>+</td>
          <td>One or more</td>
        </tr>

        <tr>
          <td>1</td>
          <td>Only one</td>
        </tr>

        <tr>
          <td>?</td>
          <td>Zero or one</td>
        </tr>

        <tr>
          <td>*</td>
          <td>Zero or more</td>
        </tr>

        <tr>
          <td>|</td>
          <td>Alternative</td>
        </tr>
      </table>
      <!-- these lattice diagrams need the new chunks added -->
      
      

      <figure id="lattice-diagram-with-plte">
        <!-- Maintain a fragment named "figure52" to preserve incoming links to it -->
         <object id="figure52" data="figures/lattice-diagram-with-plte.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Lattice diagram: Static PNG images with <a class="chunk" href="#11PLTE">PLTE</a>
        </figcaption>
      </figure>

      <figure id="lattice-diagram-without-plte">
        <!-- Maintain a fragment named "figure53" to preserve incoming links to it -->
         <object id="figure53" data="figures/lattice-diagram-without-plte.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Lattice diagram: Static PNG images without <a class="chunk" href="#11PLTE">PLTE</a>
        </figcaption>
      </figure>

      <figure id="lattice-apng-static-with-plte">
        <object id="figure52a" data="figures/lattice-diagram-apng-static-first-with-plte.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Lattice diagram: Animated PNG images with <a class="chunk" href="#11PLTE">PLTE</a>, static image forms the first frame
        </figcaption>
      </figure>

      <figure id="lattice-apng-static-without-plte">
        <object id="figure53a" data="figures/lattice-diagram-apng-static-first-without-plte.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Lattice diagram: Animated PNG images without <a class="chunk" href="#11PLTE">PLTE</a>, static image forms the first frame
        </figcaption>
      </figure>

      <figure id="lattice-apng-nostatic-with-plte">
        <object id="figure52b" data="figures/lattice-diagram-apng-static-notfirst-with-plte.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Lattice diagram: Animated PNG images with <a class="chunk" href="#11PLTE">PLTE</a>, static image not part of animation
        </figcaption>
      </figure>

      <figure id="lattice-apng-nostatic-without-plte">
        <object id="figure53b" data="figures/lattice-diagram-apng-static-notfirst-without-plte.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Lattice diagram: Animated PNG images without <a class="chunk" href="#11PLTE">PLTE</a>, static image not part of animation
        </figcaption>
      </figure>
    </section>

    <section id="sec-defining-new-chunks">
      <h2>Defining chunks</h2>

      <section id="sec-defining-public-chunks-general">
        <h3>General</h3>

        <p>All chunks, private and public, SHOULD be listed at [[PNG-EXTENSIONS]].</p>
      </section>

      <section id="sec-defining-public-chunks">
        <h3>Defining public chunks</h3>

        <p>Public chunks are reserved for definition by the W3C.</p>

        <p>Public chunks are intended for broad use consistent with the philosophy of PNG.</p>

        <p>Organizations and applications are encouraged to submit any chunk that meet the criteria above for definition as a
        public chunk by the <a href="https://www.w3.org/groups/wg/png">PNG Working Group</a>.</p>

        <p>The definition as a public chunk is neither automatic nor immediate. A proposed public chunk type SHALL not be used in
        publicly available software or datastreams until defined as such.</p>

        <p>The definition of new critical chunk types is discouraged unless necessary.</p>
      </section>

      <section id="sec-defining-private-chunks">
        <h3>Defining private chunks</h3>

        <p>Organizations and applications MAY define private chunks for private and experimental use.</p>

        <p>A private chunk SHOULD NOT be defined merely to carry textual information of interest to a human user. Instead <a class=
        "chunk" href="#11iTXt">iTXt</a> chunk SHOULD BE used and corresponding keyword SHOULD BE used and a suitable keyword
        defined.</p>

        <p>Listing private chunks at [[PNG-EXTENSIONS]] reduces, but does not eliminate, the chance that the same private chunk is
        used for incompatible purposes by different applications. If a private chunk type is used, additional identifying
        information SHOULD BE be stored at the beginning of the chunk data to further reduce the risk of conflicts.</p>

        <p>An ancillary chunk type, not a critical chunk type, SHOULD be used for all private chunks that store information that is
        not absolutely essential to view the image.</p>

        <p>Private critical chunks SHOULD NOT be defined because PNG datastreams containing such chunks are not portable, and
        SHOULD NOT be used in publicly available software or datastreams. If a private critical chunk is essential for an
        application, it SHOULD appear near the start of the datastream, so that a standard decoder need not read very far before
        discovering that it cannot handle the datastream.</p>

        <p>See <a href="#newchunks"></a> for additional guidelines on defining private chunks.</p>
      </section>
    </section>

    <section id="sec-field-value-extensibility">
      <h2>Private field values</h2>

      <p>Values greater than or equal to 128 in the following fields are <dfn>private field values</dfn>:</p>

      <ul>
        <li>
          bit depth
        </li>
        <li>
          <a href="#3colourType">color type</a>
        </li>
        <li>
          <a href="#10CompressionCM0">compression method</a>
        </li>

        <li>
          <a href="#8InterlaceMethods">interlace method</a>
        </li>

        <li>
          <a href="#9FtIntro">filter method</a>
        </li>
      </ul>

      <p>These <a>private field values</a> are neither defined nor reserved by this specification.</p>

      <p><a>Private field values</a> MAY be used for experimental or private semantics.</p>

      <p><a>Private field values</a> SHOULD NOT appear in publicly available software or datastreams since they can result in
      datastreams that are unreadable by PNG decoders as detailed at <a href="#13Decoders"></a>.</p>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "6Transformation" to preserve incoming links to it -->

  <section id="6Transformation">
    <h2>Reference image to PNG image transformation</h2>
    <!-- Maintain a fragment named "6Colour-values" to preserve incoming links to it -->

    <section id="6Colour-values">
      <h2>Color types and values</h2>

      <p>As explained in <a href="#4Concepts.PNGImage"></a> there are five types of PNG
      <!-- Maintain "3colourType" to preserve incoming links to it -->
       image. Corresponding to each type is a <a id="colorType"><dfn id="3colourType">color type</dfn></a>, which is the sum of the following values: 1
      (palette used), 2 (<a>truecolor</a> used) and 4 (alpha used). <a>greyscale</a> and <a>truecolor</a> images may have an explicit
      alpha channel. The PNG image types and corresponding <a>color types</a> are listed in <a href="#table6.1"></a>.</p>
      <!-- Maintain a fragment named "table6.1" to preserve incoming links to it -->

      <table id="table6.1" class="numbered simple">
        <caption>
          PNG image types and color types
        </caption>

        <tr>
          <th>PNG image type</th>
          <th>Color type</th>
        </tr>

        <tr>
          <td>Greyscale</td>
          <td>0</td>
        </tr>

        <tr>
          <td>Truecolor</td>
          <td>2</td>
        </tr>

        <tr>
          <td>Indexed-color</td>
          <td>3</td>
        </tr>

        <tr>
          <td>Greyscale with alpha</td>
          <td>4</td>
        </tr>

        <tr>
          <td>Truecolor with alpha</td>
          <td>6</td>
        </tr>
      </table>

      <p>The allowed bit depths and sample depths for each PNG image type are listed in <a href="#11IHDR">Image header</a>.</p>

      <p>Greyscale samples represent luminance if the transfer curve is indicated (by <a class="chunk" href="#11gAMA">gAMA</a>,
      <a class="chunk" href="#11sRGB">sRGB</a>, <a class="chunk" href="#11iCCP">iCCP</a>) or <a href="#cICP-chunk" class="chunk">cICP</a>; or device-dependent greyscale if not.
      RGB samples represent calibrated color information if the color space is indicated (by <a class="chunk" href=
      "#11gAMA">gAMA</a> and <a class="chunk" href="#11cHRM">cHRM</a>, <a class="chunk" href="#11sRGB">sRGB</a>,  <a class=
      "chunk" href="#11iCCP">iCCP</a>,  or <a href="#cICP-chunk" class="chunk">cICP</a>; or uncalibrated device-dependent color if not.</p>

      <p>Sample values are not necessarily proportional to light intensity; the <a class="chunk" href="#11gAMA">gAMA</a> chunk
      specifies the relationship between sample values and display output intensity. Viewers are strongly encouraged to compensate
      properly. See <a href="#4Concepts.ColourSpaces"></a>, <a href="#13Decoder-gamma-handling"></a> and <a href=
      "#C-GammaAppendix"></a>.</p>
    </section>
    <!-- Maintain a fragment named "6AlphaRepresentation" to preserve incoming links to it -->

    <section id="6AlphaRepresentation">
      <h2>Alpha representation</h2>

      <p>In a PNG datastream transparency may be represented in one of four ways, depending on the PNG image type (see <a href="#4Concepts.Implied-alpha"></a> and <a href="#4Concepts.Alpha-indexing"></a>).</p>

      <!-- <ol start="1"> -->
      <ol>
        <li>
          <a>Truecolor with alpha</a>, <a>greyscale with alpha</a>: an alpha channel is part of the image array.
        </li>

        <li>
          <a>truecolor</a>, <a>greyscale</a>: A <a class="chunk" href="#11tRNS">tRNS</a> chunk contains a single pixel value
          distinguishing the fully transparent pixels from the fully opaque pixels.
        </li>

        <li><a>Indexed-color</a>: A <a class="chunk" href="#11tRNS">tRNS</a> chunk contains the alpha table that associates an alpha
        sample with each palette entry.
        </li>

        <li>
          <a>truecolor</a>, <a>greyscale</a>, <a>indexed-color</a>: there is no <a class="chunk" href="#11tRNS">tRNS</a> chunk present and all
          pixels are fully opaque.
        </li>
      </ol>

      <p>An alpha channel included in the image array has 8-bit or 16-bit samples, the same size as the other samples. The alpha
      sample for each pixel is stored immediately following the greyscale or RGB samples of the pixel. An alpha value of zero
      represents full transparency, and a value of 2<sup>sampledepth</sup> - 1 represents full opacity. Intermediate values
      indicate partially transparent pixels that can be <a>composited</a> against a background image to yield the delivered
      image.</p>

      <p>The color values in a pixel are not premultiplied by the alpha value assigned to the pixel. This rule is sometimes called
      "unassociated" or "non-premultiplied" alpha. (Another common technique is to store sample values premultiplied by the alpha
      value; in effect, such an image is already <a>composited</a> against a black background. PNG does <strong>not</strong> use
      premultiplied alpha. In consequence an image editor can take a PNG image and easily change its transparency.) See <a href=
      "#12Alpha-channel-creation"></a> and <a href="#13Alpha-channel-processing"></a>.</p>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "7Transformation" to preserve incoming links to it -->

  <section id="7Transformation">
    <h2>Encoding the PNG image as a PNG datastream</h2>
    <!-- Maintain a fragment named "7Integers-and-byte-order" to preserve incoming links to it -->

    <section id="7Integers-and-byte-order">
      <h2>Integers and byte order</h2>

      <p>All integers that require more than one byte shall be in <a>network byte order</a> (as illustrated in <a href=
      "#integer-representation-in-png"></a> ): the most significant byte comes first, then the less significant bytes in descending
      order of significance (MSB LSB for two-byte integers, MSB B2 B1 LSB for four-byte integers). The highest bit (value 128) of a
      byte is numbered bit 7; the lowest bit (value 1) is numbered bit 0. Values are unsigned unless otherwise noted. Values
      explicitly noted as signed are represented in two's complement notation.</p>

      <p><a>PNG four-byte unsigned integers</a> are limited to the range 0 to 2<sup>31</sup>-1 to accommodate languages that have
      difficulty with unsigned four-byte values.</p>

      <figure id="integer-representation-in-png">
        <!-- Maintain a fragment named "figure71" to preserve incoming links to it -->
         <object id="figure71" data="figures/integer-representation-in-png.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Integer representation in PNG
        </figcaption>
      </figure>
    </section>
    <!-- Maintain a fragment named "7Scanline" to preserve incoming links to it -->

    <section id="7Scanline">
      <h2>Scanlines</h2>

      <p>A PNG image (or pass, see <a href="#8Interlace"></a>) is a rectangular pixel array, with pixels appearing left-to-right
      within each scanline, and scanlines appearing top-to-bottom. The size of each pixel is determined by the number of bits per
      pixel.</p>

      <p>Pixels within a scanline are always packed into a sequence of bytes with no wasted bits between pixels. Scanlines always
      begin on byte boundaries. Permitted bit depths and <a>color types</a> are restricted so that in all cases the packing is
      simple and efficient.</p>

      <p>In PNG images of <a>color type</a> 0 (greyscale) each pixel is a single sample, which may have precision less than a byte
      (1, 2, or 4 bits). These samples are packed into bytes with the leftmost sample in the high-order bits of a byte followed by
      the other samples for the scanline.</p>

      <p>In PNG images of <a>color type</a> 3 (indexed-color) each pixel is a single palette index. These indices are packed into
      bytes in the same way as the samples for <a>color type</a> 0.</p>

      <p>When there are multiple pixels per byte, some low-order bits of the last byte of a scanline may go unused. The contents of
      these unused bits are not specified.</p>

      <p>PNG images that are not <a>indexed-color</a> images may have sample values with a bit depth of 16. Such sample values are in
      <a>network byte order</a> (MSB first, LSB second). PNG permits multi-sample pixels only with 8 and 16-bit samples, so multiple
      samples of a single pixel are never packed into one byte.</p>
    </section>
    
    
    <!-- Maintain a fragment named "7Filtering" to preserve incoming links to it -->

    <section id="7Filtering">
      <h2>Filtering</h2>
      <!-- Maintain a fragment named "3filter" to preserve incoming links to it -->

      <p>A <dfn id="3filter">filter method</dfn> is a transformation applied to an array of <a>scanlines</a> with the aim of
      improving their compressibility.</p>

      <p>PNG standardizes one <a>filter method</a> and several filter types that may be used to prepare <a>image data</a> for
      compression. It transforms the byte sequence into an equal length sequence of bytes preceded by a filter type byte (see
      <a href="#serializing-and-filtering-scanline"></a> for an example).</p>

      <p>The encoder shall use only a single <a>filter method</a> for an interlaced PNG image, but may use different filter types
      for each scanline in a reduced image. An intelligent encoder can switch filters from one scanline to the next. The method for
      choosing which filter to employ is left to the encoder.</p>

      <p>The filter type byte is not considered part of the <a>image data</a>, but it is included in the datastream sent to the
      compression step. See <a href="#9Filters"></a>.</p>

      <figure id="serializing-and-filtering-scanline">
        <!-- Maintain a fragment named "figure49" to preserve incoming links to it -->
         <object id="figure49" data="figures/serializing-and-filtering-scanline.svg" type="image/svg+xml">
        </object>
        <figcaption>
          Serializing and filtering a scanline
        </figcaption>
      </figure>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "8Interlace" to preserve incoming links to it -->

  <section id="8Interlace">
    <h2>Interlacing and pass extraction</h2>
    <!-- Maintain a fragment named "8InterlaceIntro" to preserve incoming links to it -->

    <section class="introductory" id="8InterlaceIntro">
      <h3>Introduction</h3>

      <p>Pass extraction (see <a href="#figure48">Figure 4.8</a>) splits a PNG image into a sequence of reduced images (the
      interlaced PNG image) where the first image defines a coarse view and subsequent images enhance this coarse view until the
      last image completes the PNG image. This allows progressive display of the interlaced PNG image by the decoder and allows
      images to "fade in" when they are being displayed on-the-fly. On average, interlacing slightly expands the datastream size,
      but it can give the user a meaningful display much more rapidly.</p>
    </section>
    <!-- Maintain a fragment named "8InterlaceMethods" to preserve incoming links to it -->

    <section id="8InterlaceMethods">
      <h2>Interlace methods</h2>

      <p>Two interlace methods are defined in this International Standard, methods 0 and 1. Other values of interlace method are
      reserved for future standardization.</p>

      <p>With interlace method 0, the null method, pixels are extracted sequentially from left to right, and scanlines sequentially
      from top to bottom. The interlaced PNG image is a single reduced image.</p>

      <p>Interlace method 1, known as Adam7, defines seven distinct passes over the image. Each pass transmits a subset of the
      pixels in the reference image. The pass in which each pixel is transmitted (numbered from 1 to 7) is defined by replicating
      the following 8-by-8 pattern over the entire image, starting at the upper left corner:</p>

      <pre>
   1 6 4 6 2 6 4 6
   7 7 7 7 7 7 7 7
   5 6 5 6 5 6 5 6
   7 7 7 7 7 7 7 7
   3 6 4 6 3 6 4 6
   7 7 7 7 7 7 7 7
   5 6 5 6 5 6 5 6
   7 7 7 7 7 7 7 7
</pre>
      <p><a href="#figure48">Figure 4.8</a> shows the seven passes of interlace method 1. Within each pass, the selected pixels are
      transmitted left to right within a scanline, and selected scanlines sequentially from top to bottom. For example, pass 2
      contains pixels 4, 12, 20, etc. of scanlines 0, 8, 16, etc. (where scanline 0, pixel 0 is the upper left corner). The last
      pass contains all of scanlines 1, 3, 5, etc. The transmission order is defined so that all the scanlines transmitted in a
      pass will have the same number of pixels; this is necessary for proper application of some of the filters. The interlaced PNG
      image consists of a sequence of seven reduced images. For example, if the PNG image is 16 by 16 pixels, then the third pass
      will be a reduced image of two scanlines, each containing four pixels (see <a href="#figure48">Figure 4.8</a>).</p>

      <p>Scanlines that do not completely fill an integral number of bytes are padded as defined in <a href="#7Scanline"></a>.</p>

      <p class="note">NOTE If the reference image contains fewer than five columns or fewer than five rows, some passes will be
      empty.</p>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "9Filters" to preserve incoming links to it -->

  <section id="9Filters">
    <h2>Filtering</h2>
    <!-- Maintain a fragment named "9FtIntro" to preserve incoming links to it -->

    <section id="9FtIntro">
      <h2>Filter methods and filter types</h2>

      <p>Filtering transforms the PNG image with the goal of improving compression. The overall process is depicted in <a href=
      "#encoding-png-image"></a> while the specifics of serializing and filtering a scanline are shown in <a href=
      "#serializing-and-filtering-scanline"></a>.</p>

      <p>PNG allows for a number of <a>filter methods</a>. All the reduced images in an interlaced image shall use a single
      <a>filter method</a>. Only <a>filter method</a> 0 is defined by this specification. Other <a>filter methods</a> are reserved
      for future standardization. <a>Filter method</a> 0 provides a set of five filter types, and individual scanlines in each
      reduced image may use different filter types.</p>

      <p>PNG imposes no additional restriction on which filter types can be applied to an interlaced PNG image. However, the filter
      types are not equally effective on all types of data. See <a href="#12Filter-selection"></a>.</p>

      <p>Filtering transforms the byte sequence in a scanline to an equal length sequence of bytes preceded by the filter type.
      Filter type bytes are associated only with non-empty scanlines. No filter type bytes are present in an empty pass. See
      <a href="#13Progressive-display"></a>.</p>
    </section>
    <!-- Maintain a fragment named "9Filter-types" to preserve incoming links to it -->

    <section id="9Filter-types">
      <h2>Filter types for filter method 0</h2>

      <p>Filters are applied to <strong>bytes</strong>, not to pixels, regardless of the bit depth or <a>color type</a> of the
      image. The filters operate on the byte sequence formed by a scanline that has been represented as described in <a href=
      "#7Scanline"></a>. If the image includes an alpha channel, the alpha data is filtered in the same way as the <a>image
      data</a>.</p>

      <p>Filters may use the original values of the following bytes to generate the new byte value:</p>

      <table class="numbered simple">
        <caption>
          Named filter bytes
        </caption>

        <tr>
          <th>Name</th>
          <th>Definition</th>
        </tr>

        <tr>
          <td><var>x</var>
          </td>
          <td>the byte being filtered;</td>
        </tr>

        <tr>
          <td><var>a</var>
          </td>
          <td>the byte corresponding to x in the pixel immediately before the pixel containing x (or the byte immediately before x,
          when the bit depth is less than 8);</td>
        </tr>

        <tr>
          <td><var>b</var>
          </td>
          <td>the byte corresponding to x in the previous scanline;</td>
        </tr>

        <tr>
          <td><var>c</var>
          </td>
          <td>the byte corresponding to b in the pixel immediately before the pixel containing b (or the byte immediately before b,
          when the bit depth is less than 8).</td>
        </tr>
      </table>

      <figure id="filter-byte-positions">
        <object id="figure72" data="figures/filter-bytes.svg" type="image/svg+xml" style="width: 12vw">
        </object>
        <figcaption>
          Positions of filter bytes a, b and c relative to x
        </figcaption>
      </figure>

      <p><a href="#filter-byte-positions"></a> shows the relative positions of the bytes <var>x</var>, <var>a</var>, <var>b</var>,
      and <var>c</var>.</p>

      <p><a>Filter method</a> 0 defines five basic filter types as listed in <a href="#9-table91"></a>. <code>Orig(y)</code>
      denotes the original (unfiltered) value of byte <var>y</var>. <code>Filt(y)</code> denotes the value after a filter type has
      been applied. <code>Recon(y)</code> denotes the value after the corresponding reconstruction function has been applied. The
      Paeth filter type <var>PaethPredictor</var> [[?Paeth]] is defined below.</p>

      <p><a>Filter method</a> 0 specifies exactly this set of five filter types and this shall not be extended. This ensures that
      decoders need not decompress the data to determine whether it contains unsupported filter types: it is sufficient to check
      the <a>filter method</a> in <a href="#11IHDR"></a>.</p>
      
      
      <!-- Maintain a fragment named "9-table91" to preserve incoming links to it -->

      <table id="9-table91" class="numbered simple">
        <caption>
          Filter types
        </caption>

        <tr>
          <th>Type</th>
          <th>Name</th>
          <th>Filter Function</th>
          <th>Reconstruction Function</th>
        </tr>

        <tr>
          <td>0</td>
          <td>None</td>
          <td><code>Filt(x) = Orig(x)</code>
          </td>
          <td><code>Recon(x) = Filt(x)</code>
          </td>
        </tr>

        <tr>
          <td>1</td>
          <td>Sub</td>
          <td><code>Filt(x) = Orig(x) - Orig(a)</code>
          </td>
          <td><code>Recon(x) = Filt(x) + Recon(a)</code>
          </td>
        </tr>

        <tr>
          <td>2</td>
          <td>Up</td>
          <td><code>Filt(x) = Orig(x) - Orig(b)</code>
          </td>
          <td><code>Recon(x) = Filt(x) + Recon(b)</code>
          </td>
        </tr>

        <tr>
          <td>3</td>
          <td>Average</td>
          <td><code>Filt(x) = Orig(x) - floor((Orig(a) + Orig(b)) / 2)</code>
          </td>
          <td><code>Recon(x) = Filt(x) + floor((Recon(a) + Recon(b)) / 2)</code>
          </td>
        </tr>

        <tr>
          <td>4</td>
          <td>Paeth</td>
          <td><code>Filt(x) = Orig(x) - PaethPredictor(Orig(a), Orig(b), Orig(c))</code>
          </td>
          <td><code>Recon(x) = Filt(x) + PaethPredictor(Recon(a), Recon(b), Recon(c))</code>
          </td>
        </tr>
      </table>

      <p>For all filters, the bytes "to the left of" the first pixel in a scanline shall be treated as being zero. For filters that
      refer to the prior scanline, the entire prior scanline and bytes "to the left of" the first pixel in the prior scanline shall
      be treated as being zeroes for the first scanline of a reduced image.</p>

      <p>To reverse the effect of a filter requires the decoded values of the prior pixel on the same scanline, the pixel
      immediately above the current pixel on the prior scanline, and the pixel just to the left of the pixel above.</p>

      <p>Unsigned arithmetic modulo 256 is used, so that both the inputs and outputs fit into bytes. Filters are applied to each
      byte regardless of bit depth. The sequence of <code>Filt</code> values is transmitted as the filtered scanline.</p>
    </section>
    <!-- Maintain a fragment named "9Filter-type-3-Average" to preserve incoming links to it -->

    <section id="9Filter-type-3-Average">
      <h2>Filter type 3: Average</h2>

      <p>The sum <code>Orig(a) + Orig(b)</code> shall be performed without overflow (using at least nine-bit arithmetic).
      <code>floor()</code> indicates that the result of the division is rounded to the next lower integer if fractional; in other
      words, it is an integer division or right shift operation.</p>
    </section>
    <!-- Maintain a fragment named "9Filter-type-4-Paeth" to preserve incoming links to it -->

    <section id="9Filter-type-4-Paeth">
      <h2>Filter type 4: Paeth</h2>

      <p>The Paeth filter type computes a simple linear function of the three neighboring pixels (left, above, upper left), then
      chooses as predictor the neighboring pixel closest to the computed value. The algorithm used in this specification is an
      adaptation of the technique due to Alan W. Paeth [[Paeth]].</p>

      <p>The PaethPredictor function is defined in the code below. The logic of the function and the locations of the bytes
      <var>a</var>, <var>b</var>, <var>c</var>, and <var>x</var> are shown in <a href="#paethpredictor-function"></a>.
      <var>Pr</var> is the predictor for byte <var>x</var>.</p>

      <pre>
    p = a + b - c
    pa = abs(p - a)
    pb = abs(p - b)
    pc = abs(p - c)
    if pa &lt;= pb and pa &lt;= pc then Pr = a
    else if pb &lt;= pc then Pr = b
    else Pr = c
    return Pr
</pre>
      

      <figure id="paethpredictor-function">
        <!-- Maintain a fragment named "9-figure91" to preserve incoming links to it -->
         <object id="9-figure91" data="figures/paethpredictor-function.svg" type="image/svg+xml">
        </object>
        <figcaption>
          The PaethPredictor function
        </figcaption>
      </figure>

      <p>The calculations within the PaethPredictor function shall be performed exactly, without overflow.</p>

      <p><strong>The order in which the comparisons are performed is critical and shall not be altered.</strong> The function tries
      to establish in which of the three directions (vertical, horizontal, or diagonal) the gradient of the image is smallest.</p>

      <p>Exactly the same PaethPredictor function is used by both encoder and decoder.</p>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "10Compression" to preserve incoming links to it -->

  <section id="10Compression">
    <h2>Compression</h2>
    <!-- Maintain a fragment named "10CompressionCM0" to preserve incoming links to it -->

    <section id="10CompressionCM0">
      <h2>Compression method 0</h2>

      <p>Only PNG compression method 0 is defined by this International Standard. Other values of compression method are reserved
      for future standardization. PNG compression method 0 is <a>deflate</a> compression with a sliding window (which is an upper
      bound on the distances appearing in the <a>deflate</a> stream) of at most 32768 bytes. <a>Deflate</a> compression is derived
      from <a>LZ77</a>.</p>

      <p><a>Deflate</a>-compressed datastreams within PNG are stored in the <a>zlib</a> format, which has the structure:</p>

      <table id="zlib-structure" class="simple numbered">
        <tr>
          <td>zlib compression method/flags code</td>
          <td>1 byte</td>
        </tr>

        <tr>
          <td>Additional flags/check bits</td>
          <td>1 byte</td>
        </tr>

        <tr>
          <td>Compressed data blocks</td>
          <td>n bytes</td>
        </tr>

        <tr>
          <td>Check value</td>
          <td>4 bytes</td>
        </tr>
      </table>

      <p><a>zlib</a> is specified at [[rfc1950]].</p>

      <p>For PNG compression method 0, the <a>zlib</a> compression method/flags code shall specify method code 8 (<a>deflate</a>
      compression) and an <a>LZ77</a> window size of not more than 32768 bytes. The <a>zlib</a> compression method number is not
      the same as the PNG compression method number in the <a class="chunk" href="#11IHDR">IHDR</a> chunk. The additional flags
      shall not specify a preset dictionary.</p>

      <p>If the data to be compressed contain 16384 bytes or fewer, the PNG encoder may set the window size by rounding up to a
      power of 2 (256 minimum). This decreases the memory required for both encoding and decoding, without adversely affecting the
      compression ratio.</p>

      <p>The compressed data within the <a>zlib</a> datastream are stored as a series of blocks, each of which can represent raw
      (uncompressed) data, <a>LZ77</a>-compressed data encoded with fixed Huffman codes, or <a>LZ77</a>-compressed data encoded
      with custom Huffman codes. A marker bit in the final block identifies it as the last block, allowing the decoder to recognize
      the end of the compressed datastream. Further details on the compression algorithm and the encoding are given in the
      <a>deflate</a> specification [[rfc1951]].</p>

      <p>The check value stored at the end of the <a>zlib</a> datastream is calculated on the uncompressed data represented by the
      datastream. The algorithm used to calculate this is not the same as the CRC calculation used for PNG chunk CRC
      field values. The <a>zlib</a> check value is useful mainly as a cross-check that the <a>deflate</a> algorithms are
      implemented correctly. Verifying the individual PNG chunk CRCs provides confidence that the PNG datastream has been
      transmitted undamaged.</p>
    </section>
    <!-- Maintain a fragment named "10CompressionFSL" to preserve incoming links to it -->

    <section id="10CompressionFSL">
      <h2>Compression of the sequence of filtered scanlines</h2>

      <p>The sequence of filtered scanlines is compressed and the resulting data stream is split into <a class="chunk" href=
      "#11IDAT">IDAT</a> chunks. The concatenation of the contents of all the <a class="chunk" href="#11IDAT">IDAT</a> chunks makes
      up a <a>zlib</a> datastream. This datastream decompresses to filtered <a>image data</a>.</p>

      <p>It is important to emphasize that the boundaries between <a class="chunk" href="#11IDAT">IDAT</a> chunks are arbitrary and
      can fall anywhere in the <a>zlib</a> datastream. There is not necessarily any correlation between <a class="chunk" href=
      "#11IDAT">IDAT</a> chunk boundaries and <a>deflate</a> block boundaries or any other feature of the <a>zlib</a> data. For
      example, it is entirely possible for the terminating <a>zlib</a> check value to be split across <a class="chunk" href=
      "#11IDAT">IDAT</a> chunks.</p>

      <p>Similarly, there is no required correlation between the structure of the <a>image data</a> (i.e., scanline boundaries) and
      <a>deflate</a> block boundaries or <a class="chunk" href="#11IDAT">IDAT</a> chunk boundaries. The complete filtered PNG image
      is represented by a single <a>zlib</a> datastream that is stored in a number of <a class="chunk" href="#11IDAT">IDAT</a>
      chunks.</p>
    </section>
    
    
    <!-- Maintain a fragment named "9Filters" to preserve incoming links to it -->

    <section id="10CompressionOtherUses">
      <h2>Other uses of compression</h2>

      <p>PNG also uses compression method 0 in <a class="chunk" href="#11iTXt">iTXt</a>, <a class="chunk" href="#11iCCP">iCCP</a>,
      and <a class="chunk" href="#11zTXt">zTXt</a> chunks. Unlike the <a>image data</a>, such datastreams are not split across
      chunks; each such chunk contains an independent <a>zlib</a> datastream (see <a href="#10CompressionCM0"></a>).</p>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "11Chunks" to preserve incoming links to it -->

  <section id="11Chunks">
    <h2>Chunk specifications</h2>
    <!-- Maintain a fragment named "11Introduction" to preserve incoming links to it -->

    <section id="11Introduction">
      <h3>General</h3>

      <p>This clause defines chunk used in this specification.</p>
    </section>
    <!-- Maintain a fragment named "11Critical-chunks" to preserve incoming links to it -->

    <section id="11Critical-chunks">
      <h2>Critical chunks</h2>
      <!-- Maintain a fragment named "11CcGen" to preserve incoming links to it -->

      <section class="introductory" id="11CcGen">
        <h3>Introduction</h3>

        <!-- Maintain a fragment named "3criticalChunk" to preserve incoming links to it -->
        <p>A <dfn id="3criticalChunk" class="lint-ignore">critical chunk</dfn> is a chunk that is absolutely required in order to successfully decode a PNG image from a PNG
        datastream. Extension chunks may be defined as critical chunks (see <a href="#14EditorsExt"></a>), though this practice is
        strongly discouraged.</p>

        <p>A valid PNG datastream shall begin with a PNG signature, immediately followed by an <a class="chunk" href=
        "#11IHDR">IHDR</a> chunk, then one or more <a class="chunk" href="#11IDAT">IDAT</a> chunks, and shall end with an <a class=
        "chunk" href="#11IEND">IEND</a> chunk. Only one <a class="chunk" href="#11IHDR">IHDR</a> chunk and one <a class="chunk"
        href="#11IEND">IEND</a> chunk are allowed in a PNG datastream.</p>
      </section>
      <!-- Maintain a fragment named "11IHDR" to preserve incoming links to it -->

      <section id="11IHDR">
        <h2><span class="chunk">IHDR</span> Image header</h2>

        <p>The four-byte chunk type field contains the hexadecimal values</p>

        <pre>
<!-- 73 72 68 82 -->49 48 44 52
</pre>
        <p>The <a class="chunk" href="#11IHDR">IHDR</a> chunk shall be the first chunk in the PNG datastream. It contains:</p>

        <table id="IHDR-structure"  class="simple numbered">
          <tr>
            <td>Width</td>
            <td>4 bytes</td>
          </tr>

          <tr>
            <td>Height</td>
            <td>4 bytes</td>
          </tr>

          <tr>
            <td>Bit depth</td>
            <td>1 byte</td>
          </tr>

          <tr>
            <td>Color type</td>
            <td>1 byte</td>
          </tr>

          <tr>
            <td>Compression method</td>
            <td>1 byte</td>
          </tr>

          <tr>
            <td>Filter method</td>
            <td>1 byte</td>
          </tr>

          <tr>
            <td>Interlace method</td>
            <td>1 byte</td>
          </tr>
        </table>

        <p>Width and height give the image dimensions in pixels. They are <a>PNG four-byte unsigned integers</a>. Zero is an
        invalid value.</p>

        <!-- Maintain a fragment named "3bitDepth" to preserve incoming links to it -->
        <p id="3bitDepth">Bit depth is a single-byte integer giving the number of bits per sample or per palette index (not per pixel). Valid
        values are 1, 2, 4, 8, and 16, although not all values are allowed for all <a>color types</a>. See <a href=
        "#6Colour-values"></a>.</p>

        <p><a>Color type</a> is a single-byte integer.</p>

        <p>Bit depth restrictions for each <a>color type</a> are imposed to simplify implementations and to prohibit combinations
        that do not compress well. The allowed combinations are defined in <a href="#table111"></a>.</p>
        <!-- Maintain a fragment named "table111" to preserve incoming links to it -->

        <table id="table111" class="numbered simple">
          <caption>
            Allowed combinations of <a>color type</a> and bit depth
          </caption>

          <tr>
            <th>PNG image type</th>
            <th>Color type</th>
            <th>Allowed bit depths</th>
            <th>Interpretation</th>
          </tr>

          <tr>
            <td>Greyscale</td>
            <td>0</td>
            <td>1, 2, 4, 8, 16</td>
            <td>Each pixel is a greyscale sample</td>
          </tr>

          <tr>
            <td>Truecolor</td>
            <td>2</td>
            <td>8, 16</td>
            <td>Each pixel is an R,G,B triple</td>
          </tr>

          <tr>
            <td>Indexed-color</td>
            <td>3</td>
            <td>1, 2, 4, 8</td>
            <td>
              Each pixel is a palette index; a <a class="chunk" href="#11PLTE">PLTE</a> chunk shall appear.
            </td>
          </tr>

          <tr>
            <td>Greyscale with alpha</td>
            <td>4</td>
            <td>8, 16</td>
            <td>Each pixel is a greyscale sample followed by an alpha sample.</td>
          </tr>

          <tr>
            <td>Truecolor with alpha</td>
            <td>6</td>
            <td>8, 16</td>
            <td>Each pixel is an R,G,B triple followed by an alpha sample.</td>
          </tr>
        </table>

        <p>The sample depth is the same as the bit depth except in the case of <a>indexed-color</a> PNG images (<a>color type</a> 3), in
        which the sample depth is always 8 bits (see <a href="#4Concepts.PNGImage"></a>).</p>

        <p>Compression method is a single-byte integer that indicates the method used to compress the <a>image data</a>. Only
        compression method 0 (<a>deflate</a> compression with a sliding window of at most 32768 bytes) is defined in this
        specification. All conforming PNG images shall be compressed with this scheme.</p>

        <p>Filter method is a single-byte integer that indicates the preprocessing method applied to the <a>image data</a> before
        compression. Only <a>filter method</a> 0 (adaptive filtering with five basic filter types) is defined in this
        specification. See <a href="#9Filters"></a> for details.</p>

        <p>Interlace method is a single-byte integer that indicates the transmission order of the <a>image data</a>. Two values are
        defined in this specification: 0 (no interlace) or 1 (Adam7 interlace). See <a href="#8Interlace"></a> for details.</p>
      </section>
      <!-- Maintain a fragment named "11PLTE" to preserve incoming links to it -->

      <section id="11PLTE">
        <h2><span class="chunk">PLTE</span> Palette</h2>

        <p>The four-byte chunk type field contains the hexadecimal values</p>

        <pre>
<!-- 80 76 84 69 -->50 4C 54 45
</pre>
        <p>The <span class="chunk">PLTE</span> chunk contains from 1 to 256 palette entries, each a three-byte series of the
        form:</p>

        <table id="PLTE-structure" class="simple numbered">
          <tr>
            <td>Red</td>
            <td>1 byte</td>
          </tr>

          <tr>
            <td>Green</td>
            <td>1 byte</td>
          </tr>

          <tr>
            <td>Blue</td>
            <td>1 byte</td>
          </tr>
        </table>

        <p>The number of entries is determined from the chunk length. A chunk length not divisible by 3 is an error.</p>

        <p>This chunk shall appear for <a>color type</a> 3, and may appear for <a>color types</a> 2 and 6; it shall not appear
        for <a>color types</a> 0 and 4. There shall not be more than one <span class="chunk">PLTE</span> chunk.</p>

        <p>For <a>color type</a> 3 (indexed-color), the <span class="chunk">PLTE</span> chunk is required. The first entry in
        <span class="chunk">PLTE</span> is referenced by pixel value 0, the second by pixel value 1, etc. The number of palette
        entries shall not exceed the range that can be represented in the image bit depth (for example, 2<sup>4</sup> = 16 for a
        bit depth of 4). It is permissible to have fewer entries than the bit depth would allow. In that case, any out-of-range
        pixel value found in the <a>image data</a> is an error.</p>

        <p>For <a>color types</a> 2 and 6 (<a>truecolor</a> and <a>truecolor with alpha</a>), the <span class="chunk">PLTE</span> chunk
        is optional. If present, it provides a suggested set of colors (from 1 to 256) to which the <a>truecolor</a> image can be
        quantized if it cannot be displayed directly. It is, however, recommended that the <a class="chunk" href="#11sPLT">sPLT</a>
        chunk be used for this purpose, rather than the <span class="chunk">PLTE</span> chunk. If neither <span class=
        "chunk">PLTE</span> nor <a class="chunk" href="#11sPLT">sPLT</a> chunks are present and the image cannot be displayed
        directly, quantization has to be done by the viewing system. However, it is often preferable for the selection of colors
        to be done once by the PNG encoder. (See <a href="#12Suggested-palettes"></a>.)</p>

        <p>Note that the palette uses 8 bits (1 byte) per sample regardless of the image bit depth. In particular, the palette is 8
        bits deep even when it is a suggested quantization of a 16-bit <a>truecolor</a> image.</p>

        <p>There is no requirement that the palette entries all be used by the image, nor that they all be different.</p>
      </section>
      <!-- Maintain a fragment named "11IDAT" to preserve incoming links to it -->

      <section id="11IDAT">
        <h2><span class="chunk">IDAT</span> Image data</h2>

        <p>The four-byte chunk type field contains the hexadecimal values</p>

        <pre>
<!-- 73 68 65 84 -->49 44 41 54
</pre>
        <p>The <span class="chunk">IDAT</span> chunk contains the actual <a>image data</a> which is the output stream of the
        compression algorithm. See <a href="#9Filters"></a> and <a href="#10Compression"></a> for details.</p>

        <p>There may be multiple <span class="chunk">IDAT</span> chunks; if so, they shall appear consecutively with no other
        intervening chunks. The compressed datastream is then the concatenation of the contents of the data fields of all the
        <span class="chunk">IDAT</span> chunks
        (noting that data fields <a href="#zero-length-data">may be of zero length</a>).</p>

        <p>Some images have unused trailing bytes at the end of the final IDAT chunk. This could happen when an entire buffer is stored rather than just the portion of the buffer which is used. This is undesirable. Preferably, an encoder would not include these unused bytes. If it must, setting the bytes to zero will prevent accidental data sharing. A decoder should ignore these trailing bytes.</p>
      </section>
      <!-- Maintain a fragment named "11IEND" to preserve incoming links to it -->

      <section id="11IEND">
        <h2><span class="chunk">IEND</span> Image trailer</h2>

        <p>The four-byte chunk type field contains the hexadecimal values</p>

        <pre>
<!-- 73 69 78 68 -->49 45 4E 44
</pre>
        <p>The <span class="chunk">IEND</span> chunk marks the end of the PNG datastream. The chunk's data field is empty.</p>
      </section>
    </section>
    <!-- Maintain a fragment named "11Ancillary-chunks" to preserve incoming links to it -->

    <section id="11Ancillary-chunks">
      <h2>Ancillary chunks</h2>
      <!-- Maintain a fragment named "11AcGen" to preserve incoming links to it -->

      <section class="introductory" id="11AcGen">
        <h3>Introduction</h3>

        <p>The ancillary chunks defined in this specification are listed in the order in <a href="#4Concepts.FormatTypes"></a>.
        This is not the order in which they appear in a PNG datastream. Ancillary chunks may be ignored by a decoder. For each
        ancillary chunk, the actions described are under the assumption that the decoder is not ignoring the chunk.</p>
      </section>
      <!-- Maintain a fragment named "11transinfo" to preserve incoming links to it -->

      <section id="11transinfo">
        <h2>Transparency information</h2>
        <!-- Maintain a fragment named "11tRNS" to preserve incoming links to it -->

        <section id="11tRNS">
          <h2><span class="chunk">tRNS</span> Transparency</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 116 82 78 83 -->74 52 4E 53
</pre>
          <p>The <span class="chunk">tRNS</span> chunk specifies either alpha values that are associated with palette entries (for
          <a>indexed-color</a> images) or a single transparent color (for <a>greyscale</a> and <a>truecolor</a> images). The <span class=
          "chunk">tRNS</span> chunk contains: </p>
          

          <table id="tRNS-structure" class="simple numbered">
            <tr>
              <th colspan="2">
                <a>Color type</a> 0
              </th>
            </tr>

            <tr>
              <td>Grey sample value</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <th colspan="2">
                <a>Color type</a> 2
              </th>
            </tr>

            <tr>
              <td>Red sample value</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>Green sample value</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>Blue sample value</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <th colspan="2">
                <a>Color type</a> 3
              </th>
            </tr>

            <tr>
              <td>Alpha for palette index 0</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Alpha for palette index 1</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>...etc...</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>For <a>color type</a> 3 (indexed-color), the <span class="chunk">tRNS</span> chunk contains a series of one-byte
          alpha values, corresponding to entries in the <a class="chunk" href="#11PLTE">PLTE</a> chunk. Each entry indicates that
          pixels of the corresponding palette index shall be treated as having the specified alpha value. Alpha values have the
          same interpretation as in an 8-bit full alpha channel: 0 is fully transparent, 255 is fully opaque, regardless of image
          bit depth. The <span class="chunk">tRNS</span> chunk shall not contain more alpha values than there are palette entries,
          but a <span class="chunk">tRNS</span> chunk may contain fewer values than there are palette entries. In this case, the
          alpha value for all remaining palette entries is assumed to be 255. In the common case in which only palette index 0 need
          be made transparent, only a one-byte <span class="chunk">tRNS</span> chunk is needed, and when all palette indices are
          opaque, the <span class="chunk">tRNS</span> chunk may be omitted.</p>

          <p>For <a>color types</a> 0 or 2, two bytes per sample are used regardless of the image bit depth (see <a href=
          "#7Integers-and-byte-order"></a>). Pixels of the specified grey sample value or RGB sample values are treated as
          transparent (equivalent to alpha value 0); all other pixels are to be treated as fully opaque (alpha value
          2<sup>bitdepth</sup>-1).
          If the image bit depth is less than 16, the least significant bits are used.
          Encoders should set the other bits to 0, and decoders must mask the other bits to 0 before the value is used.</p>

          <p>A <span class="chunk">tRNS</span> chunk shall not appear for <a>color types</a> 4 and 6, since a full alpha channel
          is already present in those cases.</p>

          <p class="note">NOTE For 16-bit <a>greyscale</a> or <a>truecolor</a> data,
          as described in <a href="#13Sample-depth-rescaling"></a>,
          only <a href="#tRNS-compare-exactly">pixels matching the entire 16-bit values</a> in
          <span class="chunk">tRNS</span> chunks are transparent. Decoders have to postpone any sample depth rescaling until after
          the pixels have been tested for transparency.</p>
        </section>
      </section>
      <!-- Maintain a fragment named "11addnlcolinfo" to preserve incoming links to it -->

      <section id="11addnlcolinfo">
        <h2>Color space information</h2>
        <!-- Maintain a fragment named "11cHRM" to preserve incoming links to it -->

        <section id="11cHRM">
          <h2><span class="chunk">cHRM</span> Primary chromaticities and white point</h2>
          <!-- <p>The four decimal values below correspond to the four-byte cHRM chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 99 72 82 77 -->63 48 52 4D
</pre>
          <p>The <span class="chunk">cHRM</span> chunk may be used to specify the 1931 CIE <i>x,y</i> chromaticities of the red,
          green, and blue display primaries used in the <a>PNG image</a>, and the referenced <a>white point</a>. See <a href=
          "#C-GammaAppendix"></a> for more information. The <a class="chunk" href="#11iCCP">iCCP</a>, and <a class="chunk" href=
          "#11sRGB">sRGB</a> chunks provide more sophisticated support for color management and control.</p>

          <p>The <span class="chunk">cHRM</span> chunk contains:</p>
          
          

          <table id="cHRM-structure" class="numbered simple">
            <caption>
              cHRM chunk components
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>White point x</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>White point y</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>Red x</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>Red y</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>Green x</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>Green y</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>Blue x</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>Blue y</td>
              <td>4 bytes</td>
            </tr>
          </table>

          <p>Each value is encoded as a <a>PNG four-byte unsigned integer</a>, representing the <i>x</i> or <i>y</i> value times
          100000.</p>

          <p class="example">A value of 0.3127 would be stored as the integer 31270.</p>

          <p>The <span class="chunk">cHRM</span> chunk is allowed in all PNG datastreams, although it is of little value for
          <a>greyscale</a> images.</p>

          <p>This chunk is ignored 
            unless it is the <a href="#color-chunk-precendence">highest-precedence color chunk</a>
            understood by the decoder.</p>
        </section>
        <!-- Maintain a fragment named "11gAMA" to preserve incoming links to it -->

        <section id="11gAMA">
          <h2><span class="chunk">gAMA</span> Image gamma</h2>
          <!-- <p>The four decimal values below correspond to the four-byte gAMA chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 103 65 77 65 -->67 41 4D 41
</pre>
          <p>The <a class="chunk" href="#11gAMA">gAMA</a> chunk specifies a <a>gamma value</a>.</p>

          <p>In fact specifying the desired display output intensity is insufficient. It is also necessary to specify the viewing
          conditions under which the output is desired. For <span class="chunk">gAMA</span> these are the reference viewing
          conditions of the sRGB specification [[SRGB]]. Adjustment for different viewing conditions is normally handled by a
          Color Management System. If the adjustment is not performed, the error is usually small. Applications desiring high
          color fidelity may wish to use an <a class="chunk" href="#11sRGB">sRGB</a>, <a class="chunk" href="#11iCCP">iCCP</a>
          chunk.</p>

          <p>The <span class="chunk">gAMA</span> chunk contains:</p>

          <table id="gAMA-structure" class="simple numbered">
            <tr>
              <td>Image gamma</td>
              <td>4 bytes</td>
            </tr>
          </table>

          <p>The value is encoded as a <a>PNG four-byte unsigned integer</a>, representing the <a>gamma value</a> times 100000.</p>

          <p class="example">A <a>gamma value</a> of 1/2.2 would be stored as the integer 45455.</p>

          <p>See <a href="#12Encoder-gamma-handling"></a> and <a href="#13Decoder-gamma-handling"></a> for more information.</p>

          <p>This chunk is ignored 
            unless it is the <a href="#color-chunk-precendence">highest-precedence color chunk</a>
            understood by the decoder.</p>
        </section>
        <!-- Maintain a fragment named "11iCCP" to preserve incoming links to it -->

        <section id="11iCCP">
          <h2><span class="chunk">iCCP</span> Embedded ICC profile</h2>
          <!-- <p>The four decimal values below correspond to the four-byte iCCP chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 105 67 67 80 -->69 43 43 50
</pre>
          <p>The <span class="chunk">iCCP</span> chunk contains:</p>

          <table id="iCCP-structure" class="simple numbered">
            <tr>
              <td>Profile name</td>
              <td>1-79 bytes (character string)</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Compression method</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Compressed profile</td>
              <td>n bytes</td>
            </tr>
          </table>

          <p>The profile name may be any convenient name for referring to the profile. It is case-sensitive. Profile names shall
          contain only printable Latin-1 characters and spaces (only code points 0x20-7E and 0xA1-FF are allowed). Leading,
          trailing, and consecutive spaces are not permitted. The only compression method defined in this specification is method 0
          (<a>zlib</a> datastream with <a>deflate</a> compression, see <a href='#10CompressionOtherUses'></a>). The compression
          method entry is followed by a compressed profile that makes up the remainder of the chunk. Decompression of this
          datastream yields the embedded ICC profile.</p>

          <p>If the <span class="chunk">iCCP</span> chunk is present, the image samples conform to the color space represented by
          the embedded ICC profile as defined by the International Color Consortium [[ICC]][[ISO_15076-1]]. The color space of the
          ICC profile shall be an RGB color space for color images (<a>color types</a> 2, 3, and 6), or a greyscale color space
          for <a>greyscale</a> images (<a>color types</a> 0 and 4). A PNG encoder that writes the <span class="chunk">iCCP</span> chunk
          is encouraged to also write <a class="chunk" href="#11gAMA">gAMA</a> and <a class="chunk" href="#11cHRM">cHRM</a> chunks
          that approximate the ICC profile, to provide compatibility with applications that do not use the <span class=
          "chunk">iCCP</span> chunk.</p> 
          
          <p>
            This chunk is ignored 
            unless it is the <a href="#color-chunk-precendence">highest-precedence color chunk</a>
            understood by the decoder.
          </p>

          <p>Unless a <a class="chunk" href="#cICP-chunk">cICP</a> chunk exists, a PNG datastream should contain at most one
          embedded profile, whether specified explicitly with an <span class="chunk">iCCP</span> or implicitly with an <a class=
          "chunk" href="#srgb-standard-colour-space">sRGB</a> chunk.</p>
        </section>
        <!-- Maintain a fragment named "11sBIT" to preserve incoming links to it -->

        <section id="11sBIT">
          <h2><span class="chunk">sBIT</span> Significant bits</h2>
          <!-- <p>The four decimal values below correspond to the four-byte sBIT chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 115 66 73 84 -->73 42 49 54
</pre>
          <p>To simplify decoders, PNG specifies that only certain sample depths may be used, and further specifies that sample
          values should be scaled to the full range of possible values at the sample depth. The <span class="chunk">sBIT</span>
          chunk defines the original number of significant bits (which can be less than or equal to the sample depth). This allows
          PNG decoders to recover the original data losslessly even if the data had a sample depth not directly supported by
          PNG.</p>

          <p>The <span class="chunk">sBIT</span> chunk contains:</p>
          
          

          <table id="sBIT-structure" class="numbered simple">
            <caption>
              sBIT chunk contents
            </caption>

            <tr>
              <th colspan="2">Color type 0</th>
            </tr>

            <tr>
              <td>significant greyscale bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <th colspan="2">Color types 2 and 3</th>
            </tr>

            <tr>
              <td>significant red bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>significant green bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>significant blue bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <th colspan="2">Color type 4</th>
            </tr>

            <tr>
              <td>significant greyscale bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>significant alpha bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <th colspan="2">Color type 6</th>
            </tr>

            <tr>
              <td>significant red bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>significant green bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>significant blue bits</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>significant alpha bits</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>Each depth specified in <span class="chunk">sBIT</span> shall be greater than zero and less than or equal to the
          sample depth (which is 8 for <a>indexed-color</a> images, and the bit depth given in <a class="chunk" href="#11IHDR">IHDR</a>
          for other <a>color types</a>). Note that <span class="chunk">sBIT</span> does not provide a sample depth for the alpha
          channel that is implied by a <a class="chunk" href="#11tRNS">tRNS</a> chunk; in that case, all of the sample bits of the
          alpha channel are to be treated as significant. If the <span class="chunk">sBIT</span> chunk is not present, then all of
          the sample bits of all channels are to be treated as significant.</p>
        </section>
        <!-- Maintain a fragment named "11sRGB" to preserve incoming links to it -->

        <section id="11sRGB">
          <h2 id="srgb-standard-colour-space"><span class="chunk">sRGB</span> Standard RGB color space</h2>
          <!-- <p>The four decimal values below correspond to the four-byte sRGB chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 115 82 71 66 -->73 52 47 42
</pre>
          <p>If the <span class="chunk">sRGB</span> chunk is present, the image samples conform to the sRGB color space [[SRGB]]
          and should be displayed using the specified rendering intent defined by the International Color Consortium [[ICC]] or
          [[ICC-2]].</p>

          <p>The <span class="chunk">sRGB</span> chunk contains:</p>

          <table id="sRGB-structure" class="numbered simple">
            <caption>
              sRGB chunk contents
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>Rendering intent</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>The following values are defined for rendering intent:</p>

          <table id="rendering-intent-structure" class="numbered simple">
            <caption>
              Rendering intent values
            </caption>

            <tr>
              <th>Value</th>
              <th>Name</th>
              <th>Description</th>
            </tr>

            <tr>
              <td>0</td>
              <td>Perceptual</td>
              <td>for images preferring good adaptation to the output device gamut at the expense of colorimetric accuracy, such as
              photographs.</td>
            </tr>

            <tr>
              <td>1</td>
              <td>Relative colorimetric</td>
              <td>
                for images requiring color appearance matching (relative to the output device <a>white point</a>), such as logos.
              </td>
            </tr>

            <tr>
              <td>2</td>
              <td>Saturation</td>
              <td>for images preferring preservation of saturation at the expense of hue and lightness, such as charts and
              graphs.</td>
            </tr>

            <tr>
              <td>3</td>
              <td>Absolute colorimetric</td>
              <td>for images requiring preservation of absolute colorimetry, such as previews of images destined for a different
              output device (proofs).</td>
            </tr>
          </table>

          <p>It is recommended that a PNG encoder that writes the <span class="chunk">sRGB</span> chunk also write a <a class=
          "chunk" href="#11gAMA">gAMA</a> chunk (and optionally a <a class="chunk" href="#11cHRM">cHRM</a> chunk) for compatibility
          with decoders that do not use the <span class="chunk">sRGB</span> chunk. Only the following values shall be used.</p>

          <table id="sRGB-gAMA-cHRM" class="numbered simple">
            <caption>
              gAMA and cHRM values for sRGB
            </caption>

            <tr>
              <th colspan="2">gAMA</th>
            </tr>

            <tr>
              <td>Gamma</td>
              <td>45455</td>
            </tr>

            <tr>
              <th colspan="2">cHRM</th>
            </tr>

            <tr>
              <td>White point x</td>
              <td>31270</td>
            </tr>

            <tr>
              <td>White point y</td>
              <td>32900</td>
            </tr>

            <tr>
              <td>Red x</td>
              <td>64000</td>
            </tr>

            <tr>
              <td>Red y</td>
              <td>33000</td>
            </tr>

            <tr>
              <td>Green x</td>
              <td>30000</td>
            </tr>

            <tr>
              <td>Green y</td>
              <td>60000</td>
            </tr>

            <tr>
              <td>Blue x</td>
              <td>15000</td>
            </tr>

            <tr>
              <td>Blue y</td>
              <td>6000</td>
            </tr>
          </table>

          <p>
            This chunk is ignored 
            unless it is the <a href="#color-chunk-precendence">highest-precedence color chunk</a>
            understood by the decoder.
          </p>

          <p>It is recommended that the <a class="chunk" href="#11sRGB">sRGB</a> and <a class="chunk" href="#11iCCP">iCCP</a>
          chunks do not appear simultaneously in a PNG datastream.</p>
        </section>
        <!-- Maintain a fragment named "cICP-chunk" to preserve incoming links to it -->

        <section id="cICP-chunk">
          <h2><span class="chunk">cICP</span> Coding-independent code points for video signal type identification</h2>
          <!-- <p>The four decimal values below correspond to the four-byte cICP chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 99 73 67 80 -->63 49 43 50
</pre>
          <p>If present, the <span class="chunk">cICP</span> chunk specifies the color space (primaries), transfer function, matrix
          coefficients and scaling factor of the image using the code points specified in [[ITU-T-H.273]]. The video format signaling SHOULD be used
          when processing the image, including by a decoder or when rendering the image.</p>

          <p>The cICP chunk consists of four 1-byte unsigned integers to identify the characteristics described above.</p>

          <p>The following specifies the syntax of the <span class="chunk">cICP</span> chunk:</p>

          <table id="cICP-chunk-syntax" class="numbered simple">
            <caption>
              cICP chunk components
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>Color Primaries</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Transfer Function</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Matrix Coefficients</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Video Full Range Flag</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>Each of the fields of the <span class="chunk">cICP</span> chunk corresponds to the parameter of the same name in
          [[ITU-T-H.273]].</p>

          <p>RGB is currently the only supported color model in PNG, and as such <code>Matrix Coefficients</code> shall be set to <code>0</code>.</p>

          <aside class="note">
            If <code>Video Full Range Flag</code> value is <code>1</code>, then the image is a <a>full-range image</a>. Typically,
            images in the RGB color representation are stored in the full-range signal quantization, therefore the vast
            majority of computer graphics and web images, including those used in traditional PNG workflows, are <a>full-range
            images</a>. If <code>Video Full Range Flag</code> value is <code>0</code>, then the image is a <a>narrow-range
            image</a>. Narrow range images are found in video workflows where there are sample values below reference
            black (0% signal level) or above nominal peak (100% signal level). For example, [[ITU-R-BT.709]] specifies that, for
            10-bit coding, reference black (called black level) corresponds to a code value of 64 and nominal peak to a 
            code value of 940. In narrow range, momentary excursions defined as overshoots and undershoots exist below 
            reference black and above nominal peak in order to preserve processing artifacts caused by filtering/compression 
            or by uncontrolled lighting without clipping. This can improve image quality during additional stages of processing 
            and compression. The use of undershoot/overshoot has also been used to preserve additional color volume (both light 
            and color) as described in [[EBU-R-103]]. [[SMPTE-RP-2077]] describes full range in more detail and includes the mapping
            from <a>full-range images</a> to <a>narrow-range images</a> and describes protected code values for SDI (baseband)
            carriage.
          </aside>

          <p>If <code>Video Full Range Flag</code> is <code>0</code>
            (a <a>narrow-range image</a>), recommended practice 
            is to define transfer functions 
            such as <a>EOTF</a> or inverse <a>OETF</a> 
            over the extended range, 
            so as to include negative values.
            This is done as follows:
          </p>

          <pre>out = sign(in) * TransferFunction(abs(in))</pre>

          <p>The <span class="chunk">cICP</span> chunk MUST come before the <a class="chunk" href="#11PLTE">PLTE</a> and <a class=
          "chunk" href="#11IDAT">IDAT</a> chunks.</p>

          <p>
            This chunk, if understood by the decoder, is the 
            <a href="#color-chunk-precendence">highest-precedence color chunk</a>.
          </p>


          <aside class="example" id="ex-cICP-BT.2100-PQ-full">
            <span class="chunk">cICP</span> chunk field values for a <a>full-range image</a> that uses the color primaries and the
            <a>PQ</a> <a>transfer function</a> specified at [[ITU-R-BT.2100]]:

            <pre>
<!-- 9 16 0 1  -->09 10 00 01
</pre>
            <p>(Four 1-byte unsigned integers, in hexadecimal)</p>
          </aside>

          <aside class="example" id="ex-cICP-BT.2100-HLG-full">
            <span class="chunk">cICP</span> chunk field values for a <a>full-range image</a> that uses the color primaries and the
            <a>HLG</a> <a>transfer function</a> specified at [[ITU-R-BT.2100]]:

            <pre>
<!-- 9 18 0 1 -->09 12 00 01
</pre>
            <p>(Four 1-byte unsigned integers, in hexadecimal)</p>
          </aside>

          <aside class="example" id="ex-cICP-BT.709-narrow">
            <span class="chunk">cICP</span> chunk field values for a <a>narrow-range image</a>
            that uses the color primaries and the <a>transfer function</a> defined at [[ITU-R-BT.709]]:

            <pre>
<!-- 1 1 0 0 -->01 01 00 00
</pre>
            <p>(Four 1-byte unsigned integers, in hexadecimal)</p>
          </aside>

          <p id="display-p3">In a similar way to the use of the 
          <a href="#srgb-standard-colour-space"><span class="chunk">sRGB</span></a> chunk
          to compactly signal an sRGB image, <span class="chunk">cICP</span> can be used
          to compactly signal a Display P3 image [[Display-P3]].
          </p>

          <aside class="example" id="ex-cICP-Display-P3-full">
            <span class="chunk">cICP</span> chunk field values for a <a>full-range image</a>
            that uses the color primaries and the <a>transfer function</a> defined by [[Display-P3]]:

            <pre>
<!--12 13 0 1 -->0C 0D 00 01
</pre>
            <p>(Four 1-byte unsigned integers, in hexadecimal)</p>
          </aside>

        </section>
        <!-- Maintain a fragment named "mDCv-chunk" to preserve incoming links to it -->

        <section id="mDCv-chunk">
          <h2><span class="chunk">mDCv</span> Mastering Display Color Volume</h2>
          <!-- <p>The four decimal values below correspond to the four-byte mDCv chunk type field:</p> -->

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 109 68 67 118 -->6D 44 43 76
</pre>

          <p>If present, the <span class="chunk">mDCv</span> chunk characterizes
          the Mastering Display Color Volume (mDCv) used at the point of content creation,
          as specified in [[SMPTE-ST-2086]]. The mDCv chunk provides informative static metadata which
          allows a target (consumer) display to potentially optimize its tone mapping decisions
          on a comparison of its inherent capabilities versus the original mastering display's capabilites.</p>

          <p>mDCv is typically used with the <a>PQ</a> [[ITU-R-BT.2100]] transfer function
          and additional <a href="#cLLi-chunk">cLLI</a> metadata and is commonly then called 
          [[?HDR10]] (PQ with ST 2086 static metadata, MaxFALL and MaxCLL).
          The mDCv chunk may also be included with <a>HLG</a> [[ITU-R-BT.2100]] and 
          <a>SDR</a> image formats (for example [[ITU-R-BT.709]]). </p>

          <p>Since mDCv was originally created as supplemental static metadata meant to
          optimize the tone-mapping of images on a video display target, a cICP chunk
          must accompany the use of mDCv in order to establish the basic characteristics
          of the image content. Color Primaries and White Point characteristics
          can be derived from cICP chunk formats.
          Specific examples of its most common use-cases for images using
          both HDR [[ITU-R-BT.2100]] and SDR [[ITU-R-BT.709]] are available in
          [[ITU-T-Series-H-Supplement-19]]. The basic (cICP) characteristics plus the supplemental
          (mDCv) static metadata may provide valuable information to optimize
          tone-mapping decisions.</p>


          <p class="note"><a href="https://github.com/w3c/png/issues/319">Issue #319</a> discusses tone-mapping behavior when
          the <span class="chunk">mDCv</span> chunk is present.</p>

          <p>For <a>SDR</a> images, if mDCv display min/max luminance are unknown, the default
          characteristics can be derived from the values in [[ITU-T-Series-H-Supplement-19]] Table 11 or from the relevant <a>SDR</a> specification.
          At present, there is no published, standardized method for translating an SDR image signal from its default viewing
          condition (display luminance and ambient illumination) to that signalled in the mDCV chunk.</p>

          <aside class="note">
            The <a>HLG</a> [[ITU-R-BT.2100]] image format does have published methods for translating the image for both changes in display luminance (within [[ITU-R-BT.2100]]) and
              ambient illumination (within the accompanying report [[ITU-R-BT.2390]]). This may be used with SDR images.
          </aside>

          <p>The following specifies the syntax of the <span class="chunk">mDCv</span> chunk:</p>

          <table id="mDCv-chunk-syntax" class="numbered simple">
            <caption>
              mDCv chunk components
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
              <th>Divisor value</th>
            </tr>

            <tr>
              <td>Mastering display color primary chromaticities (CIE 1931 <i>x,y</i> of R,G,B )</td>
              <td>12 bytes</td>
              <td>0.00002</td>
            </tr>

            <tr>
              <td>Mastering display white point chromaticity (CIE 1931 <i>x,y</i>)</td>
              <td>4 bytes</td>
              <td>0.00002</td>
            </tr>

            <tr>
              <td>Mastering display maximum luminance</td>
              <td>4 bytes</td>
              <td>0.0001 cd/m<sup>2</sup></td>
            </tr>

            <tr>
              <td>Mastering display minimum luminance</td>
              <td>4 bytes</td>
              <td>0.0001 cd/m<sup>2</sup></td>
            </tr>
          </table>

          <p>The color primaries are encoded as
            three pairs of <a>PNG two-byte unsigned integer</a>s,
            in the order <em>x</em> and then <em>y</em>,
            each representing the x or y primary chromaticity value divided by the divisor value.
            They are ordered starting with the primary with the largest x chromaticity,
            followed by the primary with the largest y chromaticity,
            followed by the remaining primary.
            For RGB color spaces, this corresponds to the order R, G, B.

          <p>
            The white point is encoded as
            a pair of <a>PNG two-byte unsigned integer</a>s,
            in the order <em>x</em> and then <em>y</em>,
            each representing the x or y whie chromaticity value divided by the divisor value.
          </p>

          <p>
            The maximum and minimum luminance values are encoded as
            <a>PNG four-byte unsigned integer</a>s,
            representing the absolute luminance value in cd/m<sup>2</sup>
            divided by the divisor value.
          </p>

          <p>The divisor maps from actual value to stored value. For example, the unitless divisor of 0.00002 for the primaries and
          white point would store the chromaticity (0.6800, 0.3200) as {34000, 16000}.</p>

          <p>The <span class="chunk">mDCv</span> chunk MUST come before the <a class="chunk" href="#11PLTE">PLTE</a> and <a class=
          "chunk" href="#11IDAT">IDAT</a> chunks.</p>

          <p>Below are mDCv examples for [[ITU-R-BT.2100]] <a>HDR</a>.</p>

          <aside class="example">
            Example <span class="chunk">mDCv</span> chunk mastering display color primaries for <a>HDR</a> [[ITU-R-BT.2100]]:
            <table id="mDCv-chunk-hdr-primaries-example" class="numbered simple">
              <tr>
                <th>Name</th>
                <th>Actual values</th>
                <th>Stored Decimal values</th>
                <th>Stored Hexadecimal values</th>
              </tr>

              <tr>
                <td rowspan="3">Color primaries specified in [[ITU-R-BT.2020]]</td>
                <td>(0.708, 0.292)</td>
                <td>{ 35400, 14600 }</td>
                <td>{ 8A 48, 39 08 }</td>
              </tr>

              <tr>
                <td>(0.170, 0.797)</td>
                <td>{ 8500, 39850 }</td>
                <td>{ 21 34, 9B AA }</td>
              </tr>

              <tr>
                <td>(0.131, 0.046)</td>
                <td>{ 6550, 2300 }</td>
                <td>{ 19 96, 08 FC }</td>
              </tr>
            </table>
          </aside>

          <aside class="example">
            Example <span class="chunk">mDCv</span> chunk mastering display white point for <a>HDR</a> [[ITU-R-BT.2100]]:

            <table id="mDCv-chunk-hdr-white-point-example" class="numbered simple">
              <tr>
                <th>Name</th>
                <th>Actual values</th>
                <th>Stored Decimal values</th>
                <th>Stored Hexadecimal values</th>
              </tr>

              <tr>
                <td>Illuminant D65 specified in [[SMPTE-RP-177]]</td>
                <td>(0.3127, 0.3290)</td>
                <td>{ 15635, 16450 }</td>
                <td>{ 3C 05, 40 42 }</td>
              </tr>
            </table>
          </aside>

          <aside class="example">

            Example <span class="chunk">mDCv</span> chunk mastering display maximum luminance for <a>HDR</a> [[ITU-R-BT.2100]]:

            <table id="mDCv-chunk-hdr-max-luminance-example" class="numbered simple">
              <tr>
                <th>Actual value</th>
                <th>Stored Decimal value</th>
                <th>Stored Hexadecimal value</th>
              </tr>

              <tr>
                <td>4000 cd/m<sup>2</sup></td>
                <td>40000000</td>
                <td>02 62 5A 00</td>
              </tr>
            </table>
          </aside>

          <aside class="example">
            Example <span class="chunk">mDCv</span> chunk mastering display minimum luminance:
            <table id="mDCv-chunk-hdr-min-luminance-example" class="numbered simple">
              <tr>
                <th>Actual value</th>
                <th>Stored Decimal value</th>
                <th>Stored Hexadecimal value</th>
              </tr>

              <tr>
                <td>0.0005 cd/m<sup>2</sup></td>
                <td>5</td>
                <td>00 00 00 05</td>
              </tr>
            </table>
          </aside>

          <p>Below are mDCv examples for [[Display-P3]] <a>SDR</a>.</p>

          <aside class="example">
            Example <span class="chunk">mDCv</span> chunk mastering display color primaries for [[SRGB]]:

            <table id="mDCv-chunk-sdr-primaries-example" class="numbered simple">
              <tr>
                <th>Name</th>
                <th>Actual values</th>
                <th>Stored Decimal values</th>
                <th>Stored Hexadecimal values</th>
              </tr>

              <tr>
                <td rowspan="3">Color primaries specified in [[Display-P3]]</td>
                <td>(0.68, 0.32)</td>
                <td>{ 34000, 16000 }</td>
                <td>{ 84 D0, 3E 80 }</td>
              </tr>

              <tr>
                <td>(0.265, 0.69)</td>
                <td>{ 13520, 34500 }</td>
                <td>{ 34 D0, 86 C4 }</td>
              </tr>

              <tr>
                <td>(0.15, 0.06)</td>
                <td>{ 7500, 3000 }</td>
                <td>{ 1D 4C, 0B B8 }</td>
              </tr>
            </table>
          </aside>

          <aside class="example">
            Example <span class="chunk">mDCv</span> chunk mastering display white point for [[Display-P3]]:

            <table id="mDCv-chunk-sdr-white-point-example" class="numbered simple">
              <tr>
                <th>Name</th>
                <th>Actual values</th>
                <th>Stored Decimal values</th>
                <th>Stored Hexadecimal values</th>
              </tr>

              <tr>
                <td>Illuminant D65 specified in [[SMPTE-RP-177]]</td>
                <td>(0.3127, 0.3290)</td>
                <td>{ 15635, 16450 }</td>
                <td>{ 3D 13, 40 42 }</td>
              </tr>
            </table>
          </aside>

          <aside class="example">
            Example <span class="chunk">mDCv</span> chunk mastering display maximum
          luminance for [[Display-P3]]:
            <table id="mDCv-chunk-sdr-max-luminance-example" class="numbered simple">
              <tr>
                <th>Actual value</th>
                <th>Stored Decimal values</th>
                <th>Stored Hexadecimal values</th>
              </tr>

              <tr>
                <td>80 cd/m<sup>2</sup></td>
                <td>800000</td>
                <td>00 0C 35 00</td>
              </tr>
            </table>
          </aside>

          <aside class="example">
            Example mDCv chunk mastering display minimum luminance for [[Display-P3]]:
            <table id="mDCv-chunk-sdr-min-luminance-example" class="numbered simple">
              <tr>
                <th>Actual value</th>
                <th>Stored Decimal values</th>
                <th>Stored Hexadecimal values</th>
              </tr>

              <tr>
                <td>0.05 cd/m<sup>2</sup></td>
                <td>500</td>
                <td>00 00 01 F4</td>
              </tr>
            </table>
          </aside>
        </section>

        <section id="cLLi-chunk">
          <h2><span class="chunk">cLLi</span> Content Light Level Information</h2>
          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 99 76 76 105 -->63 4C 4C 69
</pre>
          <p>If present, the <span class="chunk">cLLi</span> chunk identifies two characteristics of <a>HDR</a> content:</p>

          <p>The <span class="chunk">cLLi</span> chunk adds static metadata which provides an opportunity
          to optimize tone mapping of the associated content to a specific target display. This is 
          accomplished by tailoring the tone mapping of the content itself to the specific peak brightness 
          capabilities of the target display to prevent clipping. The method of tone-mapping optimization 
          is currently subjective.</p>
             
          <p>MaxCLL (Maximum Content Light Level) uses a static metadata value to indicate the maximum light 
            level of any single pixel (in cd/m<sup>2</sup>, also known as nits) of the entire playback sequence. 
            There is often an algorithmic filter to eliminate false values occurring from processing or noise 
            that could adversely affect intended downstream tone mapping.</p>
          
          <p>MaxFALL (Maximum Frame Average Light Level) uses a static metadata value to indicate the 
            maximum value of the <a>frame</a> average light level (in cd/m<sup>2</sup>, also known as nits) 
            of the entire playback sequence. MaxFALL is calculated by first averaging the decoded luminance 
            values of all the pixels in each frame, and then using the value for the frame with the highest value.</p>
             
	  <p>The MaxCLL and MaxFALL values are encoded as <a>PNG four-byte unsigned integers</a>.</p>

          <p class="note">[[CTA-861.3-A]] describes the method of calculation for generating the
            <span class="chunk">cLLi</span> values,
            but does not specify any filtering.
            [[HDR-Static-Meta]] describes an improved method which rejects extreme values from
            statistical outliers, noise or ringing from resampling filters,
            and is recommended for practical implementations.
          </p>

          <p class="note">[[SMPTE-ST-2067-21]] Section 7.5 adds additional
            information in Section 7.5 in the case where the <span class="chunk">cLLi</span> values are unknown and have not been calculated.</p>

          <p class="note"><a href="https://github.com/w3c/png/issues/319">Issue #319</a> discusses tone-mapping behavior when
          the <span class="chunk">cLLi</span> chunk is present.</p>

          <p>Each <a>frame</a> is analyzed.</p>

          <p>A value of zero for either MaxCLL or MaxFALL means that the value is unknown or not currently calculable.</p>

          <p class="note">An example where this will not be calculable is when creating a live animated PNG stream, when not all frames will be available to compute the values until the stream ends.  The encoder may wish to use the value zero initially and replace this with the calculated value when the stream ends.</p>

           <p>The following specifies the syntax of the <span class="chunk">cLLi</span> chunk:</p>

           <table id="cLLi-chunk-syntax" class="numbered simple">
             <caption>cLLi chunk components</caption>

             <tr>
               <th>Name</th>
               <th>Size</th>
               <th>Divisor value</th>
             </tr>

             <tr>
               <td>Maximum Content Light Level (MaxCLL)</td>
               <td>4 bytes</td>
               <td>0.0001 cd/m<sup>2</sup></td>
             </tr>

             <tr>
               <td>Maximum Frame-Average Light Level (MaxFALL)</td>
               <td>4 bytes</td>
               <td>0.0001 cd/m<sup>2</sup></td>
             </tr>
           </table>

           <aside class="example">
             Example <span class="chunk">cLLi</span> chunk Maximum Content Light Level:

             <table id="cLLi-chunk-max-content-light-level-example" class="numbered simple">
               <tr>
                 <th>Actual value</th>
                 <th>Stored Decimal values</th>
                 <th>Stored Hexadecimal values</th>
               </tr>

               <tr>
                 <td>1000 cd/m<sup>2</sup></td>
                 <td>10000000</td>
                 <td>00 98 96 80</td>
               </tr>
             </table>
           </aside>

           <aside class="example">
             Example <span class="chunk">cLLi</span> chunk Maximum Frame-Average Light Level:

             <table id="cLLi-chunk-max-frame-avg-luminance-example" class="numbered simple">
               <tr>
                 <th>Actual value</th>
                 <th>Stored Decimal values</th>
                 <th>Stored Hexadecimal values</th>
               </tr>

               <tr>
                 <td>250 cd/m<sup>2</sup></td>
                 <td>2500000</td>
                 <td>00 26 25 A0</td>
              </tr>
            </table>
          </aside>
        </section>
      </section>

      <section id="dWLm-chunk">
        <h2><span class="chunk">dWLm</span> Diffuse white luminance metadata</h2>
        <p>The two-byte chunk type field contains the hexadecimal values</p>

        <pre>
<!-- xx xx xx xx
</pre>

        <p>If present, the <span class="chunk">dWLm</span> chunk stores the luminance value 
          of the images nominal diffuse white, in cd/m2 as defined in [ISO/TS 22028-5]:</p>

        <p>If the luminance of the diffuse white differs from the nominal luminance for an HDR reference displays
          diffuse white as defined in in [[ITU-R-BT.2408]], the contents diffuse white luminance level
          should be indicated using this metadata.</p>
           
         <p>The following specifies the syntax of the <span class="chunk">dWLn</span> chunk:</p>

         <table id="dWLn-chunk-syntax" class="numbered simple">
           <caption>dWLn chunk components</caption>

           <tr>
             <th>Name</th>
             <th>Size</th>
             <th>Divisor value</th>
           </tr>

           <tr>
             <td>Diffuse white luminance metadata</td>
             <td>2 bytes</td>
             <td>1 cd/m<sup>2</sup></td>
           </tr>

         </table>

         <aside class="example">
           Example <span class="chunk">dWLn</span> Diffuse white luminance metadata:

           <table id="dWLn-diffuse-white-luminance-metadata-example" class="numbered simple">
             <tr>
               <th>Actual value</th>
               <th>Stored Decimal value</th>
               <th>Stored 2-byte unsigned value</th>
             </tr>

             <tr>
               <td>203 cd/m<sup>2</sup></td>
               <td>203</td>
               <td>CB 00</td>
             </tr>
           </table>
         </aside>
      </section>
    </section>


<!-- Maintain a fragment named "11textinfo" to preserve incoming links to it -->
      <section id="11textinfo">
        <h2>Textual information</h2>
        <!-- Maintain a fragment named "11textIntro" to preserve incoming links to it -->

        <section class="introductory" id="11textIntro">
          <h3>Introduction</h3>

          <p>PNG provides the <a class="chunk" href="#11tEXt">tEXt</a>, <a class="chunk" href="#11iTXt">iTXt</a>, and <a class=
          "chunk" href="#11zTXt">zTXt</a> chunks for storing text strings associated with the image, such as an image description
          or copyright notice. Keywords are used to indicate what each text string represents. Any number of such text chunks may
          appear, and more than one with the same keyword is permitted.</p>
        </section>
        <!-- Maintain a fragment named "11keywords" to preserve incoming links to it -->

        <section id="11keywords">
          <h2>Keywords and text strings</h2>

          <p>The following keywords are predefined and should be used where appropriate.</p>

          <table id="keywords-predefined" class="numbered simple">
            <caption>
              Predefined keywords
            </caption>

            <tr>
              <th>Keyword value</th>
              <th>Description</th>
            </tr>

            <tr>
              <td>Title</td>
              <td>Short (one line) title or caption for image</td>
            </tr>

            <tr>
              <td>Author</td>
              <td>Name of image's creator</td>
            </tr>

            <tr>
              <td>Description</td>
              <td>Description of image (possibly long)</td>
            </tr>

            <tr>
              <td>Copyright</td>
              <td>Copyright notice</td>
            </tr>

            <tr>
              <td>Creation Time</td>
              <td>Time of original image creation</td>
            </tr>

            <tr>
              <td>Software</td>
              <td>Software used to create the image</td>
            </tr>

            <tr>
              <td>Disclaimer</td>
              <td>Legal disclaimer</td>
            </tr>

            <tr>
              <td>Warning</td>
              <td>Warning of nature of content</td>
            </tr>

            <tr>
              <td>Source</td>
              <td>Device used to create the image</td>
            </tr>

            <tr>
              <td>Comment</td>
              <td>Miscellaneous comment</td>
            </tr>

            <tr>
              <td>XML:com.adobe.xmp</td>
              <td>
                Extensible Metadata Platform (XMP) information, formatted as required by the XMP specification [[XMP]]. The use of
                <a class="chunk" href="#11iTXt">iTXt</a>, with Compression Flag set to 0, and both Language Tag and Translated
                Keyword set to the null string, are recommended for XMP compliance.
              </td>
            </tr>
          </table>

          <p>Other keywords MAY be defined by any application for private or general interest.</p>

          <p>Keywords SHOULD be .</p>

          <ul>
            <li>reasonably self-explanatory, since the aim is to let other human users understand what the chunk contains; and</li>

            <li>chosen to minimize the chance that the same keyword is used for incompatible purposes by different
            applications.</li>
          </ul>

          <p>Keywords of general interest SHOULD be listed in [[PNG-EXTENSIONS]].</p>

          <p>Keywords shall contain only printable Latin-1 [[ISO_8859-1]] characters and spaces; that is, only code points 0x20-7E
          and 0xA1-FF are allowed. To reduce the chances for human misreading of a keyword, leading spaces, trailing spaces, and
          consecutive spaces are not permitted in keywords, nor is U+00A0 NON-BREAKING SPACE since it is visually indistinguishable
          from an ordinary space.</p>

          <p>Keywords shall be spelled exactly as registered, so that decoders can use simple literal comparisons when looking for
          particular keywords. In particular, keywords are considered case-sensitive. Keywords are restricted to 1 to 79 bytes in
          length.</p>

          <p>For the Creation Time keyword, the date format SHOULD be in the RFC 3339 [[rfc3339]] date-time format or in the date format defined in section&#160;5.2.14 of RFC 1123 [[rfc1123]]. The RFC3339 date-time format is preferred. The actual format of this field is undefined.</p>

          <p>The <a class="chunk" href="#11iTXt">iTXt</a> chunk uses the UTF-8 encoding [[rfc3629]] and can be used to convey
          characters in any language. There is an option to compress text strings in the <a class="chunk" href="#11iTXt">iTXt</a>
          chunk. <a class="chunk" href="#11iTXt">iTXt</a> is recommended for all text strings, as it supports Unicode. There are
          also <a class="chunk" href="#11tEXt">tEXt</a> and <a class="chunk" href="#11zTXt">zTXt</a> chunks, whose content is
          restricted to the printable Latin-1 character set plus U+000A LINE FEED (LF). Text strings in <a class="chunk" href=
          "#11zTXt">zTXt</a> are compressed into <a>zlib</a> datastreams using <a>deflate</a> compression (see <a href=
          '#10CompressionOtherUses'></a>).</p>
        </section>
        <!-- Maintain a fragment named "11tEXt" to preserve incoming links to it -->

        <section id="11tEXt">
          <h2><span class="chunk">tEXt</span> Textual data</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 116 69 88 116 -->74 45 58 74
</pre>
          <p>Each <span class="chunk">tEXt</span> chunk contains a keyword and a text string, in the format:</p>

          <table id="tEXt-structure" class="simple numbered">
            <tr>
              <td>Keyword</td>
              <td>1-79 bytes (character string)</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Text string</td>
              <td>0 or more bytes (character string)</td>
            </tr>
          </table>

          <p>The keyword and text string are separated by a zero byte (null character). Neither the keyword nor the text string may
          contain a null character. The text string is <strong>not</strong> null-terminated (the length of the chunk defines the
          ending). The text string may be of any length from zero bytes up to the maximum permissible chunk size less the length of
          the keyword and null character separator.</p>

          <p>The keyword indicates the type of information represented by the text string as described in <a href=
          "#11keywords"></a>.</p>

          <p>Text is interpreted according to the Latin-1 character set [[ISO_8859-1]]. The text string may contain any Latin-1
          character. Newlines in the text string should be represented by a single linefeed character (decimal 10). Characters
          other than those defined in Latin-1 plus the linefeed character have no defined meaning in <span class=
          "chunk">tEXt</span> chunks. Text containing characters outside the repertoire of ISO/IEC 8859-1 should be encoded using
          the <a class="chunk" href="#11iTXt">iTXt</a> chunk.</p>
        </section>
        <!-- Maintain a fragment named "11zTXt" to preserve incoming links to it -->

        <section id="11zTXt">
          <h2><span class="chunk">zTXt</span> Compressed textual data</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 122 84 88 116 -->7A 54 58 74
</pre>
          <p>The <span class="chunk">zTXt</span> and <a class="chunk" href="#11tEXt">tEXt</a> chunks are semantically equivalent,
          but the <span class="chunk">zTXt</span> chunk is recommended for storing large blocks of text.</p>

          <p>A <span class="chunk">zTXt</span> chunk contains:</p>

          <table id="zTXt-structure" class="simple numbered">
            <tr>
              <td>Keyword</td>
              <td>1-79 bytes (character string)</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Compression method</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Compressed text datastream</td>
              <td>n bytes</td>
            </tr>
          </table>

          <p>The keyword and null character are the same as in the <a class="chunk" href="#11tEXt">tEXt</a> chunk. The keyword is not compressed. The compression method entry defines the compression method used. The
          only value defined in this International Standard is 0 (<a>deflate</a> compression). Other values are reserved for future
          standardization. The compression method entry is followed by the compressed text datastream that makes up the remainder
          of the chunk. For compression method 0, this datastream is a <a>zlib</a> datastream with deflate compression (see
          <a href="#10CompressionOtherUses"></a>). Decompression of this datastream yields Latin-1 text that is identical to the
          text that would be stored in an equivalent <a class="chunk" href="#11tEXt">tEXt</a> chunk.</p>
        </section>
        <!-- Maintain a fragment named "11iTXt" to preserve incoming links to it -->

        <section id="11iTXt">
          <h2><span class="chunk">iTXt</span> International textual data</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 105 84 88 116 -->69 54 58 74
</pre>
          <p>An <span class="chunk">iTXt</span> chunk contains:</p>

          <table id="iTXt-structure" class="simple numbered">
            <tr>
              <td>Keyword</td>
              <td>1-79 bytes (character string)</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Compression flag</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Compression method</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Language tag</td>
              <td>0 or more bytes (character string)</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Translated keyword</td>
              <td>0 or more bytes</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Text</td>
              <td>0 or more bytes</td>
            </tr>
          </table>

          <p>The keyword is described in <a href="#11keywords"></a>.</p>

          <p>The compression flag is 0 for uncompressed text, 1 for compressed text. Only the text field may be compressed. The
          compression method entry defines the compression method used. The only compression method defined in this specification
          is 0 (<a>zlib</a> datastream with <a>deflate</a> compression, see <a href='#10CompressionOtherUses'></a>). For
          uncompressed text, encoders shall set the compression method to 0, and decoders shall ignore it.</p>

          <p>The language tag is a well-formed language tag defined by [[BCP47]]. Unlike the keyword, the language tag is
          case-insensitive. Subtags must appear in the 
          <a href="https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry">IANA language subtag registry</a>. 
          If the language tag is empty, the language is
          unspecified. Examples of language tags include: <code>en</code>, <code>en-GB</code>, <code>es-419</code>,
          <code>zh-Hans</code>, <code>zh-Hans-CN</code>, <code>tlh-Cyrl-AQ</code>, <code>ar-AE-u-nu-latn</code>, and
          <code>x-private</code>.</p>

          <p>The translated keyword and text both use the UTF-8 encoding [[rfc3629]], and neither shall contain a zero byte (null
          character). The text, unlike other textual data in this chunk, is not null-terminated; its length is derived from the
          chunk length.</p>

          <p>Line breaks should not appear in the translated keyword. In the text, a newline should be represented by a single
          linefeed character (hexadecimal 0A). The remaining control characters (01-09, 0B-1F, 7F-9F) are discouraged in both the
          translated keyword and text. In UTF-8 there is a difference between the characters 80-9F (which are discouraged) and the
          bytes 80-9F (which are often necessary).</p>

          <p>The translated keyword, if not empty, should contain a translation of the keyword into the language indicated by the
          language tag, and applications displaying the keyword should display the translated keyword in addition.</p>
        </section>
      </section>
      
      
      <!-- Maintain a fragment named "11addnlsiinfo" to preserve incoming links to it -->

      <section id="11addnlsiinfo">
        <h2>Miscellaneous information</h2>
        <!-- Maintain a fragment named "11bKGD" to preserve incoming links to it -->

        <section id="11bKGD">
          <h2><span class="chunk">bKGD</span> Background color</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 98 75 71 68 -->62 4B 47 44
</pre>
          <p>The <span class="chunk">bKGD</span> chunk specifies a default background color to present the image against. If there
          is any other preferred background, either user-specified or part of a larger page (as in a browser), the <span class=
          "chunk">bKGD</span> chunk should be ignored. The <span class="chunk">bKGD</span> chunk contains:</p>

          <table id="bKGD-structure" class="numbered simple">
            <caption>
              bKGD chunk contents
            </caption>

            <tr>
              <th colspan="2">Color types 0 and 4</th>
            </tr>

            <tr>
              <td>Greyscale</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <th colspan="2">Color types 2 and 6</th>
            </tr>

            <tr>
              <td>Red</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>Green</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>Blue</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <th colspan="2">Color type 3</th>
            </tr>

            <tr>
              <td>Palette index</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>For <a>color type</a> 3 (<a>indexed-color</a>), the value is the palette index of the color to be used as background.</p>

          <p>For <a>color types</a> 0 and 4 (<a>greyscale</a>, <a>greyscale with alpha</a>), the value is the grey level to be used as
          background in the range 0 to (2<sup>bitdepth</sup>)-1. For <a>color types</a> 2 and 6 (<a>truecolor</a>, <a>truecolor
          with alpha</a>), the values are the color to be used as background, given as RGB samples in the range 0 to
          (2<sup>bitdepth</sup>)-1. In each case, for consistency, two bytes per sample are used regardless of the image bit depth.
          If the image bit depth is less than 16, the least significant bits are used.
          Encoders should set the other bits to 0, and decoders must mask the other bits to 0 before the value is used.</p>
        </section>
        <!-- Maintain a fragment named "11hIST" to preserve incoming links to it -->

        <section id="11hIST">
          <h2><span class="chunk">hIST</span> Image histogram</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 104 73 83 84 -->68 49 53 54
</pre>
          <p>The <span class="chunk">hIST</span> chunk contains a series of two-byte unsigned integers:</p>

          <table id="hIST-structure" class="simple numbered">
            <tr>
              <td>Frequency</td>
              <td>2 bytes (unsigned integer)</td>
            </tr>

            <tr>
              <td>...etc...</td>
              <td>&nbsp;</td>
            </tr>
          </table>

          <p>The <span class="chunk">hIST</span> chunk gives the approximate usage frequency of each color in the palette. A
          histogram chunk can appear only when a <a class="chunk" href="#11PLTE">PLTE</a> chunk appears. If a viewer is unable to
          provide all the colors listed in the palette, the histogram may help it decide how to choose a subset of the colors for
          display.</p>

          <p>There shall be exactly one entry for each entry in the <a class="chunk" href="#11PLTE">PLTE</a> chunk. Each entry is
          proportional to the fraction of pixels in the image that have that palette index; the exact scale factor is chosen by the
          encoder.</p>

          <p>Histogram entries are approximate, with the exception that a zero entry specifies that the corresponding palette entry
          is not used at all in the image. A histogram entry shall be nonzero if there are any pixels of that color.</p>

          <p class="note">NOTE When the palette is a suggested quantization of a <a>truecolor</a> image, the histogram is
          necessarily approximate, since a decoder may map pixels to palette entries differently than the encoder did. In this
          situation, zero entries should not normally appear, because any entry might be used.</p>
        </section>
        <!-- Maintain a fragment named "11pHYs" to preserve incoming links to it -->

        <section id="11pHYs">
          <h2><span class="chunk">pHYs</span> Physical pixel dimensions</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 112 72 89 115 -->70 48 59 73
</pre>
          <p>The <span class="chunk">pHYs</span> chunk specifies the intended pixel size or aspect ratio for display of the image.
          It contains:</p>

          <table id="pHYs-structure" class="numbered simple">
            <caption>
              pHYs chunk contents
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>Pixels per unit, X axis</td>
              <td>
                4 bytes (<a>PNG four-byte unsigned integer</a>)
              </td>
            </tr>

            <tr>
              <td>Pixels per unit, Y axis</td>
              <td>
                4 bytes (<a>PNG four-byte unsigned integer</a>)
              </td>
            </tr>

            <tr>
              <td>Unit specifier</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>The following values are defined for the unit specifier:</p>

          <table id="unit-specifiers" class="numbered simple">
            <caption>
              Unit specifier values
            </caption>

            <tr>
              <th>Value</th>
              <th>Description</th>
            </tr>

            <tr>
              <td>0</td>
              <td>unit is unknown</td>
            </tr>

            <tr>
              <td>1</td>
              <td>unit is the metre</td>
            </tr>
          </table>

          <p>When the unit specifier is 0, the <span class="chunk">pHYs</span> chunk defines pixel aspect ratio only; the actual
          size of the pixels remains unspecified.</p>

          <p>If the <span class="chunk">pHYs</span> chunk is not present, pixels are assumed to be square, and the physical size of
          each pixel is unspecified.</p>
        </section>
        <!-- Maintain a fragment named "11sPLT" to preserve incoming links to it -->

        <section id="11sPLT">
          <h2><span class="chunk">sPLT</span> Suggested palette</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 115 80 76 84 -->73 50 4C 54
</pre>
          <p>The <span class="chunk">sPLT</span> chunk contains:</p>

          <table id="sPLT-structure" class="numbered simple">
            <caption>
              sPLT chunk contents
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>Palette name</td>
              <td>1-79 bytes (character string)</td>
            </tr>

            <tr>
              <td>Null separator</td>
              <td>1 byte (null character)</td>
            </tr>

            <tr>
              <td>Sample depth</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>Red</td>
              <td>1 or 2 bytes</td>
            </tr>

            <tr>
              <td>Green</td>
              <td>1 or 2 bytes</td>
            </tr>

            <tr>
              <td>Blue</td>
              <td>1 or 2 bytes</td>
            </tr>

            <tr>
              <td>Alpha</td>
              <td>1 or 2 bytes</td>
            </tr>

            <tr>
              <td>Frequency</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>...etc...</td>
              <td>&nbsp;</td>
            </tr>
          </table>

          <p>Each palette entry is six bytes or ten bytes containing five unsigned integers (red, blue, green, alpha, and
          frequency).</p>

          <p>There may be any number of entries. A PNG decoder determines the number of entries from the length of the chunk
          remaining after the sample depth byte. This shall be divisible by 6 if the <span class="chunk">sPLT</span> sample depth
          is 8, or by 10 if the <span class="chunk">sPLT</span> sample depth is 16. Entries shall appear in decreasing order of
          frequency. There is no requirement that the entries all be used by the image, nor that they all be different.</p>

          <p>The palette name can be any convenient name for referring to the palette (for example "256 color including Macintosh
          default", "256 color including Windows-3.1 default", "Optimal 512"). The palette name may aid the choice of the
          appropriate suggested palette when more than one appears in a PNG datastream.</p>

          <p>The palette name is case-sensitive, and subject to the same restrictions as the keyword parameter for the <a class=
          "chunk" href="#11tEXt">tEXt</a> chunk. Palette names shall contain only printable Latin-1 characters and spaces (only
          code points 0x20-7E and 0xA1-FF are allowed). Leading, trailing, and consecutive spaces are not permitted.</p>

          <p>The <span class="chunk">sPLT</span> sample depth shall be 8 or 16.</p>

          <p>The red, green, blue, and alpha samples are either one or two bytes each, depending on the <span class=
          "chunk">sPLT</span> sample depth, regardless of the image bit depth. The color samples are not premultiplied by alpha,
          nor are they precomposited against any background. An alpha value of 0 means fully transparent. An alpha value of 255
          (when the <span class="chunk">sPLT</span> sample depth is 8) or 65535 (when the <span class="chunk">sPLT</span> sample
          depth is 16) means fully opaque. The <span class="chunk">sPLT</span> chunk may appear for any <a>color type</a>. Entries
          in <span class="chunk">sPLT</span> use the same <a>gamma value</a> and <a>chromaticity</a> values as the PNG image, but
          may fall outside the range of values used in the color space of the PNG image; for example, in a <a>greyscale</a> PNG image,
          each <span class="chunk">sPLT</span> entry would typically have equal red, green, and blue values, but this is not
          required. Similarly, <span class="chunk">sPLT</span> entries can have non-opaque alpha values even when the PNG image
          does not use transparency.</p>

          <p>Each frequency value is proportional to the fraction of the pixels in the image for which that palette entry is the
          closest match in RGBA space, before the image has been <a>composited</a> against any background. The exact scale factor
          is chosen by the PNG encoder; it is recommended that the resulting range of individual values reasonably fills the range
          0 to 65535. A PNG encoder may artificially inflate the frequencies for colors considered to be "important", for example
          the colors used in a logo or the facial features of a portrait. Zero is a valid frequency meaning that the color is
          "least important" or that it is rarely, if ever, used. When all the frequencies are zero, they are meaningless, that is
          to say, nothing may be inferred about the actual frequencies with which the colors appear in the PNG image.</p>

          <p>Multiple <span class="chunk">sPLT</span> chunks are permitted, but each shall have a different palette name.</p>
        </section>
        <!-- Maintain a fragment named "eXIf" to preserve incoming links to it -->

        <section id="eXIf">
          <h2><span class="chunk">eXIf</span> Exchangeable Image File (Exif) Profile</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
  <!-- 101 88 73 102 -->65 58 49 66
  </pre>
          <p>The data segment of the <span class="chunk">eXIf</span> chunk contains an Exif profile in the format specified in
          "4.7.2 Interoperability Structure of APP1 in Compressed Data" of [[CIPA-DC-008]] except that the JPEG APP1 marker,
          length, and the "Exif ID code" described in 4.7.2(C), i.e., "Exif", NULL, and padding byte, are not included.</p>

          <p>The
          <span class="chunk">eXIf</span> chunk size is constrained only by the maximum of 2<sup>31</sup>-1 bytes imposed by the
          PNG specification. Only one <span class="chunk">eXIf</span> chunk is allowed in a PNG datastream.</p>

          <p>The <span class="chunk">eXIf</span> chunk contains metadata concerning the original <a>image data</a>. If the image
          has been edited subsequent to creation of the Exif profile, this data might no longer apply to the PNG <a>image data</a>.
          It is recommended that unless a decoder has independent knowledge of the validity of the Exif data, the data should be
          considered to be of historical value only. It is beyond the scope of this specification to resolve potential conflicts
          between data in the eXIf chunk and in other PNG chunks.</p>

          <section>
            <h3><span class="chunk">eXIf</span> General Recommendations</h3>

            <p>While the PNG specification allows the chunk size to be as large as 2<sup>31</sup>-1 bytes, application authors
            should be aware that, if the Exif profile is going to be written to a JPEG [[JPEG]] datastream, the total length of the
            <span class="chunk">eXIf</span> chunk data may need to be adjusted to not exceed 2<sup>16</sup>-9 bytes, so it can fit
            into a JPEG APP1 marker (Exif) segment.</p>
          </section>

          <section>
            <h3><span class="chunk">eXIf</span> Recommendations for Decoders</h3>

            <p>The first two bytes of data are either "II" for little-endian (Intel) or "MM" for big-endian (Motorola) byte order.
            Decoders should check the first four bytes to ensure that they have the following hexadecimal values:</p>

            <pre><!-- 73 73 42 0  -->49 49 2A 00 (ASCII "II", 16-bit little-endian integer 42)</pre>
            <p>or</p>

            <pre><!-- 77 77 0 42 -->4D 4D 00 2A (ASCII "MM", 16-bit big-endian integer 42)</pre>
            <p>All other values are reserved for possible future definition.</p>
          </section>

          <section>
            <h3><span class="chunk">eXIf</span> Recommendations for Encoders</h3>

            <p>Image editing applications should consider Paragraph E.3 of the Exif Specification [[CIPA-DC-008]], which discusses
            requirements for updating Exif data when the image is changed. Encoders should follow those requirements, but decoders
            should not assume that it has been accomplished.</p>

            <p>While encoders may choose to update them, there is no expectation that any thumbnails present in the Exif profile
            have (or have not) been updated if the main image was changed.</p>
          </section>
        </section>
      </section>
      <!-- Maintain a fragment named "11timestampinfo" to preserve incoming links to it -->

      <section id="11timestampinfo">
        <h2>Time stamp information</h2>
        <!-- Maintain a fragment named "11tIME" to preserve incoming links to it -->

        <section id="11tIME">
          <h2><span class="chunk">tIME</span> Image last-modification time</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 116 73 77 69 -->74 49 4D 45
</pre>
          <p>The <span class="chunk">tIME</span> chunk gives the time of the last image modification (<strong>not</strong> the time
          of initial image creation). It contains:</p>

          <table id="tIME-structure" class="numbered simple">
            <caption>
              tIME chunk contents
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>Year</td>
              <td>2 bytes (complete; for example, 1995, <strong>not</strong> 95)</td>
            </tr>

            <tr>
              <td>Month</td>
              <td>1 byte (1-12)</td>
            </tr>

            <tr>
              <td>Day</td>
              <td>1 byte (1-31)</td>
            </tr>

            <tr>
              <td>Hour</td>
              <td>1 byte (0-23)</td>
            </tr>

            <tr>
              <td>Minute</td>
              <td>1 byte (0-59)</td>
            </tr>

            <tr>
              <td>Second</td>
              <td>1 byte (0-60) (to allow for leap seconds)</td>
            </tr>
          </table>

          <p>Universal Time (UTC) should be specified rather than local time.</p>

          <p>The <span class="chunk">tIME</span> chunk is intended for use as an automatically-applied time stamp that is updated
          whenever the <a>image data</a> are changed.</p>
        </section>
      </section>

      <section id="animation-information">
        <h2>Animation information</h2>

        <section id="acTL-chunk">
          <h2><span class="chunk">acTL</span> Animation Control Chunk</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
<!-- 97 99 84 76 -->61 63 54 4C
    </pre>
          <p>The <span class="chunk">acTL</span> chunk declares that this is an animated PNG image, gives the number of frames, and
          the number of times to loop. It contains:</p>

          <table id="acTL-structure" class="simple numbered">
            <tr>
              <td>`num_frames`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`num_plays`</td>
              <td>4 bytes</td>
            </tr>
          </table>

          <p>Each value is encoded as a <a>PNG four-byte unsigned integer</a>.</p>

          <p>`num_frames` indicates the total number of frames in the animation. This must equal the number of <a class="chunk"
          href="#fcTL-chunk">fcTL</a> chunks. 0 is not a valid value. 1 is a valid value, for a single-frame PNG. If this value
          does not equal the actual number of frames it should be treated as an error.</p>

          <p>`num_plays` indicates the number of times that this animation should play; if it is 0, the animation should play
          indefinitely. If nonzero, the animation should come to rest on the final frame at the end of the last play.</p>

          <p>The <span class="chunk">acTL</span> chunk must appear before the first <a class="chunk" href="#11IDAT">IDAT</a> chunk
          within a valid PNG stream.</p>

          <p class="note">For Web compatibility, due to the long time between the development and deployment of this chunk and it's
          incorporation into the PNG specification, this chunk name is exceptionally defined as if it were a private chunk.</p>
        </section>

        <section id="fcTL-chunk">
          <h2><span class="chunk">fcTL</span> Frame Control Chunk</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
    <!-- 102 99 84 76 -->66 63 54 4C
    </pre>
          <p>The <span class="chunk">fcTL</span> chunk defines the dimensions, position, delay and disposal of an individual frame.
          Exactly one <span class="chunk">fcTL</span> chunk chunk is required for each frame. It contains:</p>

          <table id="fcTL-structure" class="numbered simple">
            <caption>
              fcTL chunk contents
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>`sequence_number`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`width`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`height`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`x_offset`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`y_offset`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`delay_num`</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>`delay_den`</td>
              <td>2 bytes</td>
            </tr>

            <tr>
              <td>`dispose_op`</td>
              <td>1 byte</td>
            </tr>

            <tr>
              <td>`blend_op`</td>
              <td>1 byte</td>
            </tr>
          </table>

          <p>`sequence_number` defines the <a href="#4Concepts.APNGSequence">sequence number</a> of the animation chunk, starting from 0. It is encoded as a <a>PNG
          four-byte unsigned integer</a>.</p>

          <p>`width` and `height` define the width and height of the following frame. They are encoded as <a>PNG four-byte unsigned
          integers</a>. They must be greater than zero.</p>

          <p>`x_offset` and `y_offset` define the x and y position of the following frame. They are encoded as <a>PNG four-byte
          unsigned integers</a>. They must be greater than or equal to zero.</p>

          <p>The frame must be rendered within the region defined by `x_offset`, `y_offset`, `width`, and `height`. This region may
          not fall outside of the default image; thus `x_offset` plus `width` must not be greater than the <a class="chunk" href=
          "#11IHDR">IHDR</a> width; similarly `y_offset` plus `height` must not be greater than the <a class="chunk" href=
          "#11IHDR">IHDR</a> height.</p>

          <p>`delay_num` and `delay_den` define the numerator and denominator of the delay fraction; indicating the time to display
          the current frame, in seconds. If the denominator is 0, it is to be treated as if it were 100 (that is, `delay_num` then
          specifies 1/100ths of a second). If the the value of the numerator is 0 the decoder should render the next frame as
          quickly as possible, though viewers may impose a reasonable lower bound. They are encoded as two-byte unsigned
          integers.</p>

          <p>Frame timings should be independent of the time required for decoding and display of each frame, so that animations
          will run at the same rate regardless of the performance of the decoder implementation.</p>

          <p>`dispose_op` defines the type of frame area disposal to be done after rendering this frame; in other words, it
          specifies how the output buffer should be changed at the end of the delay (before rendering the next frame). It is
          encoded as a one-byte unsigned integer.</p>

          <p>Valid values for `dispose_op` are:</p>

          <table id="dispose-op-values" class="simple numbered">
            <tr>
              <td>0</td>
              <td>`APNG_DISPOSE_OP_NONE`</td>
            </tr>

            <tr>
              <td>1</td>
              <td>`APNG_DISPOSE_OP_BACKGROUND`</td>
            </tr>

            <tr>
              <td>2</td>
              <td>`APNG_DISPOSE_OP_PREVIOUS`</td>
            </tr>
          </table>

          <dl>
            <dt>`APNG_DISPOSE_OP_NONE`</dt>

            <dd>no disposal is done on this frame before rendering the next; the contents of the output buffer are left as is.</dd>

            <dt>`APNG_DISPOSE_OP_BACKGROUND`</dt>

            <dd>the frame's region of the output buffer is to be cleared to fully transparent black before rendering the next
            frame.</dd>

            <dt>`APNG_DISPOSE_OP_PREVIOUS`</dt>

            <dd>the frame's region of the output buffer is to be reverted to the previous contents before rendering the next
            frame.</dd>
          </dl>

          <p>If the first <span class="chunk">fcTL</span> chunk uses a `dispose_op` of `APNG_DISPOSE_OP_PREVIOUS` it should be
          treated as `APNG_DISPOSE_OP_BACKGROUND`.</p>

          <p>`blend_op` specifies whether the frame is to be alpha blended into the current output buffer content, or whether it
          should completely replace its region in the output buffer. It is encoded as a one-byte unsigned integer.</p>

          <p>Valid values for `blend_op` are:</p>

          <table id="blend-op-values" class="simple numbered">
            <tr>
              <td>0</td>
              <td>`APNG_BLEND_OP_SOURCE`</td>
            </tr>

            <tr>
              <td>1</td>
              <td>`APNG_BLEND_OP_OVER`</td>
            </tr>
          </table>

          <p>If `blend_op` is `APNG_BLEND_OP_SOURCE` all color components of the frame, including alpha, overwrite the current
          contents of the frame's output buffer region. If `blend_op` is `APNG_BLEND_OP_OVER` the frame should be <a>composited</a>
          onto the output buffer based on its alpha, using a simple OVER operation as described in <a href=
          "#13Alpha-channel-processing">Alpha Channel Processing</a>. Note that the second variation of the sample code is
          applicable.</p>

          <p>Note that for the first frame, the two blend modes are functionally equivalent due to the clearing of the output
          buffer at the beginning of each play.</p>

          <p>The <span class="chunk">fcTL</span> chunk corresponding to the default image, if it exists, has these
          restrictions:</p>

          <ul>
            <li>The `x_offset` and `y_offset` fields must be 0.</li>

            <li>The `width` and `height` fields must equal the corresponding fields from the <a class="chunk" href=
            "#11IHDR">IHDR</a> chunk.
            </li>
          </ul>

          <p>As noted earlier, the output buffer must be completely initialized to fully transparent black at the beginning of each
          play. This is to ensure that each play of the animation will be identical. Decoders are free to avoid an explicit clear
          step as long as the result is guaranteed to be identical. For example, if the default image is included in the animation,
          and uses a `blend_op` of `APNG_BLEND_OP_SOURCE`, clearing is not necessary because the entire output buffer will be
          overwritten.</p>

          <!--
  8.1 Integers and byte order only covers multibyte integers. So add:
   a "byte" shall be an 8-bit unsigned integer with the range 0 to (2^8)-1
 -->

          <p class="note">For Web compatibility, due to the long time between the development and deployment of this chunk and it's
          incorporation into the PNG specification, this chunk name is exceptionally defined as if it were a private chunk.</p>
        </section>

        <section id="fdAT-chunk">
          <h2><span class="chunk">fdAT</span> Frame Data Chunk</h2>

          <p>The four-byte chunk type field contains the hexadecimal values</p>

          <pre>
    <!-- 102 100 65 84 -->66 64 41 54
    </pre>
          <p>The <span class="chunk">fdAT</span> chunk serves the same purpose for animations as the <a class="chunk" href=
          "#11IDAT">IDAT</a> chunks do for static images;
          the set of <span class="chunk">fdAT</span> chunks
          contains the <a>image data</a> for all frames (or, for animations
          which include the <a>static image</a> as first frame, for all frames after the first one). It contains:</p>

          <table id="fdAT-structure" class="numbered simple">
            <caption>
              fdAT chunk contents
            </caption>

            <tr>
              <th>Name</th>
              <th>Size</th>
            </tr>

            <tr>
              <td>`sequence_number`</td>
              <td>4 bytes</td>
            </tr>

            <tr>
              <td>`frame_data`</td>
              <td><i>n</i> bytes</td>
            </tr>
          </table>

          <p>At least one <span class="chunk">fdAT</span> chunk is required for each frame, except for the first frame, if that
          frame is represented by an <a class="chunk" href="#11IDAT">IDAT</a> chunk.</p>

          <p>The compressed datastream for each frame is then the concatenation,
          in ascending <a href="#4Concepts.APNGSequence">sequence number</a> order,
          of the contents of the `frame_data` fields of all the <span class=
          "chunk">fdAT</span> chunks within a frame.</p>

          <p>Because of the sequence number, <span class="chunk">fdAT</span> chunks
          <a href="#zero-length-data">may not be of zero length</a>);
          however the `frame_data` fields may be of zero length.

          When decompressed, the datastream is the complete pixel data of a PNG image,
          including the filter byte at the beginning of each scanline, similar to the uncompressed data of all the <a class="chunk"
          href="#11IDAT">IDAT</a> chunks. It utilizes the same bit depth, <a>color type</a>, compression method, <a>filter
          method</a>, interlace method, and palette (if any) as the <a>static image</a>.</p>

          <p>Each frame inherits every property specified by any critical or ancillary chunks <em>before</em> the first <a class=
          "chunk" href="#11IDAT">IDAT</a> chunk in the file, except the width and height, which come from the <span class=
          "chunk">fcTL</span> chunk.</p>

          <p>If the PNG <a class="chunk" href="#11pHYs">pHYs</a> chunk is present, the APNG images and their `x_offset` and
          `y_offset` values must be scaled in the same way as the main image. Conceptually, such scaling occurs while mapping the
          output buffer onto the <a>canvas</a>.</p>

          <p class="note">For Web compatibility, due to the long time between the development and deployment of this chunk and it's
          incorporation into the PNG specification, this chunk name is exceptionally defined as if it were a private chunk.</p>
        </section>
      </section>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "12Encoders" to preserve incoming links to it -->

  <section id="12Encoders">
    <h2>PNG Encoders</h2>
    <!-- Maintain a fragment named "12Introduction" to preserve incoming links to it -->

    <section class="introductory" id="12Introduction">
      <h3>Introduction</h3>

      <p>This clause gives requirements and recommendations for encoder behavior. A PNG encoder shall produce a PNG datastream
      from a PNG image that conforms to the format specified in the preceding clauses. Best results will usually be achieved by
      following the additional recommendations given here.</p>
    </section>
    <!-- Maintain a fragment named "12Encoder-gamma-handling" to preserve incoming links to it -->

    <section id="12Encoder-gamma-handling">
      <h2>Encoder gamma handling</h2>

      <p>See <a href="#C-GammaAppendix"></a> for a brief introduction to <a>gamma</a> issues.</p>

      <p>PNG encoders capable of full color management will perform more sophisticated calculations than those described here and
      may choose to use the <a class="chunk" href="#11iCCP">iCCP</a> chunk. If it is known that the image samples conform to the
      sRGB specification [[SRGB]], encoders are strongly encouraged to write the <a class="chunk" href=
      "#srgb-standard-colour-space">sRGB</a> chunk without performing additional <a>gamma</a> handling. In both cases it is
      recommended that an appropriate <a class="chunk" href="#11gAMA">gAMA</a> chunk be generated for use by PNG decoders that do
      not recognize the <a class="chunk" href="#11iCCP">iCCP</a> or <a class="chunk" href="#srgb-standard-colour-space">sRGB</a>
      chunks.</p>

      <p>A PNG encoder has to determine:</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>what value to write in the <a class="chunk" href="#11gAMA">gAMA</a> chunk;
        </li>

        <li>how to transform the provided image samples into the values to be written in the PNG datastream.</li>
      </ol>

      <p>The value to write in the <a class="chunk" href="#11gAMA">gAMA</a> chunk is that value which causes a PNG decoder to
      behave in the desired way. See <a class='Href' href='#13Decoder-gamma-handling'></a>.</p>

      <p>The transform to be applied depends on the nature of the image samples and their precision. If the samples represent light
      intensity in floating-point or high precision integer form (perhaps from a computer graphics renderer), the encoder may
      perform <dfn>gamma encoding</dfn> (applying a power function with exponent less than 1) before quantizing the data to integer
      values for inclusion in the PNG datastream. This results in fewer banding artifacts at a given sample depth, or allows
      smaller samples while retaining the same visual quality. An intensity level expressed as a floating-point value in the range
      0 to 1 can be converted to a datastream image sample by:</p>

      <p><code>integer_sample = floor((2<sup>sampledepth</sup>-1) * intensity<sup>encoding_exponent</sup> + 0.5)</code>
      </p>

      <p>If the intensity in the equation is the desired output intensity, the encoding exponent is the <a>gamma value</a> to be
      used in the <a class="chunk" href="#11gAMA">gAMA</a> chunk.</p>

      <p>If the intensity available to the PNG encoder is the original scene intensity, another transformation may be needed. There
      is sometimes a requirement for the displayed image to have higher contrast than the original source image. This corresponds
      to an end-to-end <a>transfer function</a> from original scene to display output with an exponent greater than 1. In this
      case:</p>

      <pre>
gamma = encoding_exponent/end_to_end_exponent
</pre>
      <p>If it is not known whether the conditions under which the original image was captured or calculated warrant such a
      contrast change, it may be assumed that the display intensities are proportional to original scene intensities, i.e. the
      end-to-end exponent is 1 and hence:</p>

      <pre>
gamma = encoding_exponent
</pre>
      

      <p>If the image is being written to a datastream only, the encoder is free to choose the encoding exponent. Choosing a value
      that causes the <a>gamma value</a> in the <a class="chunk" href="#11gAMA">gAMA</a> chunk to be 1/2.2 is often a reasonable
      choice because it minimizes the work for a PNG decoder displaying on a typical video monitor.</p>

      <p>Some image renderers may simultaneously write the image to a PNG datastream and display it on-screen. The displayed pixels
      should be <a>gamma</a> corrected for the display system and viewing conditions in use, so that the user sees a proper
      representation of the intended scene.</p>

      <p>If the renderer wants to write the displayed sample values to the PNG datastream, avoiding a separate <a>gamma
      encoding</a> step for the datastream, the renderer should approximate the <a>transfer function</a> of the display system by a
      power function, and write the reciprocal of the exponent into the <a class="chunk" href="#11gAMA">gAMA</a> chunk. This will
      allow a PNG decoder to reproduce what was displayed on screen for the originator during rendering.</p>

      <p>However, it is equally reasonable for a renderer to compute displayed pixels appropriate for the display device, and to
      perform separate <a>gamma encoding</a> for data storage and transmission, arranging to have a value in the <a class="chunk"
      href="#11gAMA">gAMA</a> chunk more appropriate to the future use of the image.</p>

      <p>Computer graphics renderers often do not perform <a>gamma encoding</a>, instead making sample values directly proportional
      to scene light intensity. If the PNG encoder receives sample values that have already been quantized into integer values,
      there is no point in doing <a>gamma encoding</a> on them; that would just result in further loss of information. The encoder
      should just write the sample values to the PNG datastream. This does not imply that the <a class="chunk" href=
      "#11gAMA">gAMA</a> chunk should contain a <a>gamma value</a> of 1.0 because the desired end-to-end <a>transfer function</a>
      from scene intensity to display output intensity is not necessarily linear. However, the desired <a>gamma value</a> is
      probably not far from 1.0. It may depend on whether the scene being rendered is a daylight scene or an indoor scene, etc.</p>

      <p>When the sample values come directly from a piece of hardware, the correct <a class="chunk" href="#11gAMA">gAMA</a> value
      can, in principle, be inferred from the <a>transfer function</a> of the hardware and lighting conditions of the scene. In the
      case of video digitizers ("frame grabbers"), the samples are probably in the sRGB color space, because the sRGB
      specification was designed to be compatible with modern video standards. Image scanners are less predictable. Their output
      samples may be proportional to the input light intensity since CCD sensors themselves are linear, or the scanner hardware may
      have already applied a power function designed to compensate for dot gain in subsequent printing (an exponent of about 0.57),
      or the scanner may have corrected the samples for display on a monitor. It may be necessary to refer to the scanner's manual
      or to scan a calibrated target in order to determine the characteristics of a particular scanner. It should be remembered
      that <a>gamma</a> relates samples to desired display output, not to scanner input.</p>

      <p>Datastream format converters generally should not attempt to convert supplied images to a different <a>gamma</a>. The data
      should be stored in the PNG datastream without conversion, and the <a>gamma value</a> should be deduced from information in
      the source datastream if possible. <a>Gamma</a> alteration at datastream conversion time causes re-quantization of the set of
      intensity levels that are represented, introducing further roundoff error with little benefit. It is almost always better to
      just copy the sample values intact from the input to the output file.</p>

      <p>If the source datastream describes the <a>gamma</a> characteristics of the image, a datastream converter is strongly
      encouraged to write a <a class="chunk" href="#11gAMA">gAMA</a> chunk. Some datastream formats specify the display exponent
      (the exponent of the function which maps image samples to display output rather than the other direction). If the source
      file's <a>gamma value</a> is greater than 1.0, it is probably a display exponent, and the reciprocal of this value should be
      used for the PNG <a>gamma value</a>. If the source file format records the relationship between image samples and a quantity
      other than display output, it will be more complex than this to deduce the PNG <a>gamma value</a>.</p>

      <p>If a PNG encoder or datastream converter knows that the image has been displayed satisfactorily using a display system
      whose <a>transfer function</a> can be approximated by a power function with exponent <var>display_exponent</var>, the image
      can be marked as having the <a>gamma value</a>:</p>

      <pre>
gamma = 1/display_exponent
</pre>
      

      <p>It is better to write a <a class="chunk" href="#11gAMA">gAMA</a> chunk with a value that is approximately correct than to
      omit the chunk and force PNG decoders to guess an approximate <a>gamma value</a>. If a PNG encoder is unable to infer the
      <a>gamma value</a>, it is preferable to omit the <a class="chunk" href="#11gAMA">gAMA</a> chunk. If a guess has to be made
      this should be left to the PNG decoder.</p>

      <p><a>gamma</a> does not apply to alpha samples; alpha is always represented linearly.</p>

      <p>See also <a href="#13Decoder-gamma-handling"></a>.</p>
    </section>
    <!-- Maintain a fragment named "12Encoder-colour-handling" to preserve incoming links to it -->

    <section id="12Encoder-colour-handling">
      <h2>Encoder color handling</h2>

      <p>See <a href="#C-GammaAppendix"></a> for references to color issues.</p>

      <p>PNG encoders capable of full color management will perform more sophisticated calculations than those described here and
      may choose to use the <a class="chunk" href="#11iCCP">iCCP</a> chunk. If it is known that the image samples conform to the
      sRGB specification [[SRGB]], PNG encoders are strongly encouraged to use the <a class="chunk" href=
      "#srgb-standard-colour-space">sRGB</a> chunk.</p>

      <p>If it is possible for the encoder to determine the chromaticities of the source display primaries, or to make a strong
      guess based on the origin of the image, or the hardware running it, the encoder is strongly encouraged to output the
      <a class="chunk" href="#11cHRM">cHRM</a> chunk. If this is done, the <a class="chunk" href="#11gAMA">gAMA</a> chunk should
      also be written; decoders can do little with a <a class="chunk" href="#11cHRM">cHRM</a> chunk if the <a class="chunk" href=
      "#11gAMA">gAMA</a> chunk is missing.</p>

      <p>There are a number of recommendations and standards for primaries and <a>white points</a>, some of which are linked to
      particular technologies, for example the CCIR 709 standard [[ITU-R-BT.709]] and the SMPTE-C standard [[SMPTE-170M]].</p>

      <p>There are three cases that need to be considered:</p>

      <ol>
        <li>the encoder is part of the generation system;</li>

        <li>the source image is captured by a camera or scanner;</li>

        <li>the PNG datastream was generated by translation from some other format.</li>
      </ol>
      <!--  deleted - comment PDG 31<p>Scanners that produce PNG datastreams as output should insert
the filter chromaticities into a <a class="chunk" href="#11cHRM">
cHRM</a> chunk.</p>-->

      <p>In the case of hand-drawn or digitally edited images, it is necessary to determine what monitor they were viewed on when
      being produced. Many image editing programs allow the type of monitor being used to be specified. This is often because they
      are working in some device-independent space internally. Such programs have enough information to write valid <a class=
      "chunk" href="#11cHRM">cHRM</a> and <a class="chunk" href="#11gAMA">gAMA</a> chunks, and are strongly encouraged to do so
      automatically.</p>

      <p>If the encoder is compiled as a portion of a computer image renderer that performs full-spectral rendering, the monitor
      values that were used to convert from the internal device-independent color space to RGB should be written into the
      <a class="chunk" href="#11cHRM">cHRM</a> chunk. Any colors that are outside the gamut of the chosen RGB device should be
      mapped to be within the gamut; PNG does not store out-of-gamut colors.</p>

      <p>If the computer image renderer performs calculations directly in device-dependent RGB space, a <a class="chunk" href=
      "#11cHRM">cHRM</a> chunk should not be written unless the scene description and rendering parameters have been adjusted for a
      particular monitor. In that case, the data for that monitor should be used to construct a <a class="chunk" href=
      "#11cHRM">cHRM</a> chunk.</p>

      <p>A few image formats store calibration information, which can be used to fill in the <a class="chunk" href=
      "#11cHRM">cHRM</a> chunk. For example, TIFF 6.0 files [[?TIFF-6.0]] can optionally store calibration information, which if
      present should be used to construct the <a class="chunk" href="#11cHRM">cHRM</a> chunk.</p>

      <p>Video created with recent video equipment probably uses the CCIR 709 primaries and D65 <a>white point</a> [[ITU-R-BT.709]], which are given in <a href="#12-table121"></a>.</p>
      
      
      <!-- Maintain a fragment named "12-table121" to preserve incoming links to it -->

      <table id="12-table121" class="numbered simple">
        <caption>
          CCIR 709 primaries and D65 whitepoint
        </caption>

        <tr>
          <th>&nbsp;</th>
          <th>R</th>
          <th>G</th>
          <th>B</th>
          <th>White</th>
        </tr>

        <tr>
          <td>x</td>
          <td>0.640</td>
          <td>0.300</td>
          <td>0.150</td>
          <td>0.3127</td>
        </tr>

        <tr>
          <td>y</td>
          <td>0.330</td>
          <td>0.600</td>
          <td>0.060</td>
          <td>0.3290</td>
        </tr>
      </table>

      <p>An older but still very popular video standard is SMPTE-C [[SMPTE-170M]] given in <a href="#12-table122"></a>.</p>
      <!-- Maintain a fragment named "12-table122" to preserve incoming links to it -->

      <table id="12-table122" class="numbered simple">
        <caption>
          SMPTE-C video standard
        </caption>

        <tr>
          <th>&nbsp;</th>
          <th>R</th>
          <th>G</th>
          <th>B</th>
          <th>White</th>
        </tr>

        <tr>
          <td>x</td>
          <td>0.630</td>
          <td>0.310</td>
          <td>0.155</td>
          <td>0.3127</td>
        </tr>

        <tr>
          <td>y</td>
          <td>0.340</td>
          <td>0.595</td>
          <td>0.070</td>
          <td>0.3290</td>
        </tr>
      </table>

      <p>It is <strong>not</strong> recommended that datastream format converters attempt to convert supplied images to a different
      RGB color space. The data should be stored in the PNG datastream without conversion, and the source primary chromaticities
      should be recorded if they are known. Color space transformation at datastream conversion time is a bad idea because of
      gamut mismatches and rounding errors. As with <a>gamma</a> conversions, it is better to store the data losslessly and incur
      at most one conversion when the image is finally displayed.</p>

      <p>See <a href="#13Decoder-colour-handling"></a>.</p>
    </section>
    <!-- Maintain a fragment named "12Alpha-channel-creation" to preserve incoming links to it -->

    <section id="12Alpha-channel-creation">
      <h2>Alpha channel creation</h2>

      <p>The alpha channel can be regarded either as a mask that temporarily hides transparent parts of the image, or as a means
      for constructing a non-rectangular image. In the first case, the color values of fully transparent pixels should be
      preserved for future use. In the second case, the transparent pixels carry no useful data and are simply there to fill out
      the rectangular image area required by PNG. In this case, fully transparent pixels should all be assigned the same color
      value for best compression.</p>

      <p>Image authors should keep in mind the possibility that a decoder will not support transparency control in full (see
      <a href="#13Alpha-channel-processing"></a>). Hence, the colors assigned to transparent pixels should be reasonable
      background colors whenever feasible.</p>

      <p>For applications that do not require a full alpha channel, or cannot afford the price in compression efficiency, the
      <a class="chunk" href="#11tRNS">tRNS</a> transparency chunk is also available.</p>

      <p>If the image has a known background color, this color should be written in the <a class="chunk" href="#11bKGD">bKGD</a>
      chunk. Even decoders that ignore transparency may use the <a class="chunk" href="#11bKGD">bKGD</a> color to fill unused
      screen area.</p>

      <p>If the original image has premultiplied (also called "associated") alpha data, it can be converted to PNG's
      non-premultiplied format by dividing each sample value by the corresponding alpha value, then multiplying by the maximum
      value for the image bit depth, and rounding to the nearest integer. In valid premultiplied data, the sample values never
      exceed their corresponding alpha values, so the result of the division should always be in the range 0 to 1. If the alpha
      value is zero, output black (zeroes).</p>
    </section>
    
    
    <!-- Maintain a fragment named "12Sample-depth-scaling" to preserve incoming links to it -->

    <section id="12Sample-depth-scaling">
      <h2>Sample depth scaling</h2>

      <p>When encoding input samples that have a sample depth that cannot be directly represented in PNG, the encoder shall scale
      the samples up to a sample depth that is allowed by PNG. The most accurate scaling method is the linear equation:</p>

      <pre>
output = floor((input * MAXOUTSAMPLE / MAXINSAMPLE) + 0.5)
</pre>
      <p>where the input samples range from 0 to <var>MAXINSAMPLE</var> and the outputs range from 0 to <var>MAXOUTSAMPLE</var>
      (which is 2<sup>sampledepth</sup>-1).</p>

      <p>A close approximation to the linear scaling method is achieved by "left bit replication", which is shifting the valid bits
      to begin in the most significant bit and repeating the most significant bits into the open bits. This method is often faster
      to compute than linear scaling.</p>

      <p class="example">Assume that 5-bit samples are being scaled up to 8 bits. If the source sample value is 27 (in the range from
      0-31), then the original bits are:</p>

      <pre>
   4 3 2 1 0
   ---------
   1 1 0 1 1
</pre>
      <p>Left bit replication gives a value of 222:</p>

      <pre>
   7 6 5 4 3  2 1 0
   ----------------
   1 1 0 1 1  1 1 0
   |=======|  |===|
       |      Leftmost Bits Repeated to Fill Open Bits
       |
   Original Bits
</pre>
      <p>which matches the value computed by the linear equation. Left bit replication usually gives the same value as linear
      scaling, and is never off by more than one.</p>

      <p>A distinctly less accurate approximation is obtained by simply left-shifting the input value and filling the low order
      bits with zeroes. This scheme cannot reproduce white exactly, since it does not generate an all-ones maximum value; the net
      effect is to darken the image slightly. This method is not recommended in general, but it does have the effect of improving
      compression, particularly when dealing with greater-than-8-bit sample depths. Since the relative error introduced by
      zero-fill scaling is small at high sample depths, some encoders may choose to use it. Zero-fill shall <strong>not</strong> be
      used for alpha channel data, however, since many decoders will treat alpha values of all zeroes and all ones as special
      cases. It is important to represent both those values exactly in the scaled data.</p>

      <p>When the encoder writes an <a class="chunk" href="#11sBIT">sBIT</a> chunk, it is required to do the scaling in such a way
      that the high-order bits of the stored samples match the original data. That is, if the <a class="chunk" href=
      "#11sBIT">sBIT</a> chunk specifies a sample depth of S, the high-order S bits of the stored data shall agree with the
      original S-bit data values. This allows decoders to recover the original data by shifting right. The added low-order bits are
      not constrained. All the above scaling methods meet this restriction.</p>

      <p>When scaling up source <a>image data</a>, it is recommended that the low-order bits be filled consistently for all
      samples; that is, the same source value should generate the same sample value at any pixel position. This improves
      compression by reducing the number of distinct sample values. This is not a mandatory requirement, and some encoders may
      choose not to follow it. For example, an encoder might instead dither the low-order bits, improving displayed image quality
      at the price of increasing file size.</p>

      <p>In some applications the original source data may have a range that is not a power of 2. The linear scaling equation still
      works for this case, although the shifting methods do not. It is recommended that an <a class="chunk" href="#11sBIT">sBIT</a>
      chunk not be written for such images, since <a class="chunk" href="#11sBIT">sBIT</a> suggests that the original data range
      was exactly 0..2<sup>S</sup>-1.</p>
    </section>
    
    
    <!-- Maintain a fragment named "12Suggested-palettes" to preserve incoming links to it -->

    <section id="12Suggested-palettes">
      <h2>Suggested palettes</h2>

      <p>Suggested palettes may appear as <a class="chunk" href="#11sPLT">sPLT</a> chunks in any PNG datastream, or as a <a class=
      "chunk" href="#11PLTE">PLTE</a> chunk in <a>truecolor</a> PNG datastreams. In either case, the suggested palette is not an
      essential part of the <a>image data</a>, but it may be used to present the image on indexed-color display hardware.
      Suggested palettes are of no interest to viewers running on <a>truecolor</a> hardware.</p>

      <p>When an <a class="chunk" href="#11sPLT">sPLT</a> chunk is used to provide a suggested palette, it is recommended that the
      encoder use the frequency fields to indicate the relative importance of the palette entries, rather than leave them all zero
      (meaning undefined). The frequency values are most easily computed as "nearest neighbor" counts, that is, the approximate
      usage of each RGBA palette entry if no dithering is applied. (These counts will often be available "for free" as a
      consequence of developing the suggested palette.) Because the suggested palette includes transparency information, it should
      be computed for the un-<a>composited</a> image.</p>

      <p>Even for indexed-color images, <a class="chunk" href="#11sPLT">sPLT</a> can be used to define alternative reduced
      palettes for viewers that are unable to display all the colors present in the <a class="chunk" href="#11PLTE">PLTE</a>
      chunk. If the <a class="chunk" href="#11PLTE">PLTE</a> chunk appears without the <a class="chunk" href="#11bKGD">bKGD</a>
      chunk in an image of <a>color type</a> 6, the circumstances under which the palette was computed are unspecified.</p>

      <p>An older method for including a suggested palette in a <a>truecolor</a> PNG datastream uses the <a class="chunk" href=
      "#11PLTE">PLTE</a> chunk. If this method is used, the histogram (frequencies) should appear in a separate <a class="chunk"
      href="#11hIST">hIST</a> chunk. The <a class="chunk" href="#11PLTE">PLTE</a> chunk does not include transparency information.
      Hence for images of <a>color type</a> 6 (<a>truecolor with alpha</a>), it is recommended that a <a class="chunk" href=
      "#11bKGD">bKGD</a> chunk appear and that the palette and histogram be computed with reference to the image as it would appear
      after compositing against the specified background color. This definition is necessary to ensure that useful palette entries
      are generated for pixels having fractional alpha values. The resulting palette will probably be useful only to viewers that
      present the image against the same background color. It is recommended that <a>PNG editors</a> delete or recompute the
      palette if they alter or remove the <a class="chunk" href="#11bKGD">bKGD</a> chunk in an image of <a>color type</a> 6.</p>

      <p>For images of <a>color type</a> 2 (<a>truecolor</a>), it is recommended that the <a class="chunk" href=
      "#11PLTE">PLTE</a> and <a class="chunk" href="#11hIST">hIST</a> chunks be computed with reference to the RGB data only,
      ignoring any transparent-color specification. If the datastream uses transparency (has a <a class="chunk" href=
      "#11tRNS">tRNS</a> chunk), viewers can easily adapt the resulting palette for use with their intended background color (see
      <a href="#13Histogram-and-suggested-palette-usage"></a>).</p>

      <p>For providing suggested palettes, the <a class="chunk" href="#11sPLT">sPLT</a> chunk is more flexible than the <a class=
      "chunk" href="#11PLTE">PLTE</a> chunk in the following ways:</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>With <a class="chunk" href="#11sPLT">sPLT</a> multiple suggested palettes may be provided. A PNG decoder may choose an
        appropriate palette based on name or number of entries.
        </li>

        <li>In a PNG datastream of <a>color type</a> 6 (<a>truecolor with alpha</a> channel), the <a class="chunk" href=
        "#11PLTE">PLTE</a> chunk represents a palette already <a>composited</a> against the <a class="chunk" href=
        "#11bKGD">bKGD</a> color, so it is useful only for display against that background color. The <a class="chunk" href=
        "#11sPLT">sPLT</a> chunk provides an un-<a>composited</a> palette, which is useful for display against backgrounds chosen
        by the PNG decoder.
        </li>

        <li>Since the <a class="chunk" href="#11sPLT">sPLT</a> chunk is an ancillary chunk, a <a>PNG editor</a> may add or modify
        suggested palettes without being forced to discard unknown unsafe-to-copy chunks.
        </li>

        <li>Whereas the <a class="chunk" href="#11sPLT">sPLT</a> chunk is allowed in PNG datastreams for <a>color types</a> 0, 3,
        and 4 (<a>greyscale</a> and <a>indexed-color</a>), the <a class="chunk" href="#11PLTE">PLTE</a> chunk cannot be used to provide reduced
        palettes in these cases.
        </li>

        <li>More than 256 entries may appear in the <a class="chunk" href="#11sPLT">sPLT</a> chunk.
        </li>
      </ol>

      <p>A PNG encoder that uses the <a class="chunk" href="#11sPLT">sPLT</a> chunk may choose to write a suggested palette
      represented by <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href="#11hIST">hIST</a> chunks as well, for
      compatibility with decoders that do not recognize the <a class="chunk" href="#11sPLT">sPLT</a> chunk.</p>
    </section>
    
    
    <!-- Maintain a fragment named "12Interlacing" to preserve incoming links to it -->

    <section id="12Interlacing">
      <h2>Interlacing</h2>

      <p>This specification defines two interlace methods, one of which is no interlacing. Interlacing provides a convenient basis
      from which decoders can progressively display an image, as described in <a href="#13Progressive-display"></a>.</p>
    </section>
    <!-- Maintain a fragment named "12Filter-selection" to preserve incoming links to it -->

    <section id="12Filter-selection">
      <h2>Filter selection</h2>

      <p>For images of <a>color type</a> 3 (indexed-color), filter type 0 (None) is usually the most effective. Color images
      with 256 or fewer colors should almost always be stored in <a>indexed-color</a> format; <a>truecolor</a> format is likely to be
      much larger.</p>

      <p>Filter type 0 is also recommended for images of bit depths less than 8. For low-bit-depth greyscale images, in rare cases,
      better compression may be obtained by first expanding the image to 8-bit representation and then applying filtering.</p>

      <p>For <a>truecolor</a> and <a>greyscale</a> images, any of the five filters may prove the most effective. If an encoder uses a
      fixed filter, the Paeth filter type is most likely to be the best.</p>

      <p>For best compression of <a>truecolor</a> and <a>greyscale</a> images,
      and if compression efficiency is valued over speed of compression,
      the recommended approach is adaptive filtering in which a
      filter type is chosen for each scanline.
      Each unique image will have a different set of filters which perform best for it.
      An encoder could try every combination of filters to find what compresses best
      for a given image. However, when an exhaustive search is unacceptable,
      here are some general heuristics which may perform well enough:
      compute the output
      scanline using all five filters, and select the filter that gives the smallest sum of absolute values of outputs. (Consider
      the output bytes as signed differences for this test.)
      This method usually outperforms any single fixed filter type choice.</p>

      <p>Filtering according to these recommendations is effective in conjunction with either of the two interlace methods defined
      in this specification.</p>
    </section>
    <!-- Maintain a fragment named "12Compression" to preserve incoming links to it -->

    <section id="12Compression">
      <h2>Compression</h2>

      <p>The encoder may divide the compressed datastream into <a class="chunk" href="#11IDAT">IDAT</a> chunks however it wishes.
      (Multiple <a class="chunk" href="#11IDAT">IDAT</a> chunks are allowed so that encoders may work in a fixed amount of memory;
      typically the chunk size will correspond to the encoder's buffer size.) A PNG datastream in which each <a class="chunk" href=
      "#11IDAT">IDAT</a> chunk contains only one data byte is valid, though remarkably wasteful of space. (<a href="#zero-length-data">Zero-length</a> <a class=
      "chunk" href="#11IDAT">IDAT</a> chunks are also valid, though even more wasteful.)</p>
    </section>
    <!-- Maintain a fragment named "12Text-chunk-processing" to preserve incoming links to it -->

    <section id="12Text-chunk-processing">
      <h2>Text chunk processing</h2>

      <p>A nonempty keyword shall be provided for each text chunk. The generic keyword "Comment" can be used if no better
      description of the text is available. If a user-supplied keyword is used, encoders should check that it meets the
      restrictions on keywords.</p>

      <p>The <a class="chunk" href="#11iTXt">iTXt</a> chunk uses the UTF-8 encoding of Unicode and thus can store text in any
      language. The <a class="chunk" href="#11tEXt">tEXt</a> and <a class="chunk" href="#11zTXt">zTXt</a> chunks use the Latin-1
      (ISO 8859-1) character encoding, which limits the range of characters that can be used in these chunks. Encoders should
      prefer <a class="chunk" href="#11iTXt">iTXt</a> to <a class="chunk" href="#11tEXt">tEXt</a> and <a class="chunk" href=
      "#11zTXt">zTXt</a> chunks, in order to allow a wide range of characters without data loss. Encoders must convert characters
      that use local <a>legacy character encodings</a> to the appropriate encoding when storing text.
      </p>

      <p>When creating <a href="#11iTXt" class="chunk">iTXt</a> chunks,
        encoders should follow <a href="https://encoding.spec.whatwg.org/#utf-8-encode">UTF-8 encode</a> in [[[ENCODING]]].
      </p>

      <p>Encoders should discourage
      the creation of single lines of text longer than 79 Unicode <a>code points</a>, in order to facilitate easy reading. It is
      recommended that text items less than 1024 bytes in size should be output using uncompressed text chunks. It is recommended
      that the basic title and author keywords be output using uncompressed text chunks. Placing large text chunks after the
      <a>image data</a> (after the <a class="chunk" href="#11IDAT">IDAT</a> chunks) can speed up image display in some situations,
      as the decoder will decode the <a>image data</a> first. It is recommended that small text chunks, such as the image title,
      appear before the <a class="chunk" href="#11IDAT">IDAT</a> chunks.</p>
    </section>
    
    
    <!-- Maintain a fragment named "12Chunk-processing" to preserve incoming links to it -->

    <section id="12Chunk-processing">
      <h2>Chunking</h2>
      <!-- Maintain a fragment named "12Use-of-private-chunks" to preserve incoming links to it -->

      <section id="12Use-of-private-chunks">
        <h2>Use of private chunks</h2>

        <p>Encoders MAY use private chunks to carry information that need not be understood by other applications.</p>
      </section>
      <!-- Maintain a fragment named "12Private-type-and-method-codes" to preserve incoming links to it -->

      <section id="12Private-type-and-method-codes">
        <h2>Use of non-reserved field values</h2>

        <p>Encoders MAY use non-reserved field values for experimental or private use.</p>
      </section>
      <!-- Maintain a fragment named "12Ancillary" to preserve incoming links to it -->

      <section id="12Ancillary">
        <h2>Ancillary chunks</h2>

        <p>All ancillary chunks are optional, encoders need not write them. However, encoders are encouraged to write the standard
        ancillary chunks when the information is available.</p>
      </section>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "13Decoders" to preserve incoming links to it -->

  <section id="13Decoders">
    <h2>PNG decoders and viewers</h2>
    <!-- Maintain a fragment named "13Introduction" to preserve incoming links to it -->

    <section class="introductory" id="13Introduction">
      <h2>Introduction</h2>

      <p>This clause gives some requirements and recommendations for PNG decoder behavior and viewer behavior. A viewer presents
      the decoded PNG image to the user. Since viewer and decoder behavior are closely connected, decoders and viewers are treated
      together here. The only absolute requirement on a PNG decoder is that it successfully reads any datastream conforming to the
      format specified in the preceding chapters. However, best results will usually be achieved by following these additional
      recommendations.</p>

      <p>PNG decoders shall support all valid combinations of bit depth, <a>color type</a>, compression method, <a>filter
      method</a>, and interlace method that are explicitly defined in this International Standard.</p>
    </section>

    <section>
      <!-- Maintain a fragment named "13Decoders.Errors" to preserve incoming links to it -->

      <h2 id="13Decoders.Errors">Error handling</h2>

      <p>Errors in a PNG datastream will fall into two general classes, transmission errors and syntax errors (see <a href=
      "#4Concepts.Errors"></a>).</p>

      <p>Examples of transmission errors are transmission in "text" or "ascii" mode, in which byte codes 13 and/or 10 may be added,
      removed, or converted throughout the datastream; unexpected termination, in which the datastream is truncated; or a physical
      error on a storage device, in which one or more blocks (typically 512 bytes each) will have garbled or random values. Some
      examples of syntax errors are an invalid value for a row filter, an invalid compression method, an invalid chunk length, the
      absence of a <a class="chunk" href="#11PLTE">PLTE</a> chunk before the first <a class="chunk" href="#11IDAT">IDAT</a> chunk
      in an indexed image, or the presence of multiple <a class="chunk" href="#11gAMA">gAMA</a> chunks. A PNG decoder should handle
      errors as follows:</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>Detect errors as early as possible using the PNG signature bytes and CRCs on each chunk. Decoders should verify
        that all eight bytes of the PNG signature are correct. A decoder can have additional confidence in the datastream's
        integrity if the next eight bytes begin an <a class="chunk" href="#11IHDR">IHDR</a> chunk with the correct chunk length. A
        CRC should be checked before processing the chunk data. Sometimes this is impractical, for example when a streaming
        PNG decoder is processing a large <a class="chunk" href="#11IDAT">IDAT</a> chunk. In this case the CRC should be
        checked when the end of the chunk is reached.
        </li>

        <li>Recover from an error, if possible; otherwise fail gracefully. Errors that have little or no effect on the processing
        of the image may be ignored, while those that affect critical data shall be dealt with in a manner appropriate to the
        application.</li>

        <li>Provide helpful messages describing errors, including recoverable errors.</li>
      </ol>

      <p>Three classes of PNG chunks are relevant to this philosophy. For the purposes of this classification, an "unknown chunk"
      is either one whose type was genuinely unknown to the decoder's author, or one that the author chose to treat as unknown,
      because default handling of that chunk type would be sufficient for the program's purposes. Other chunks are called "known
      chunks". Given this definition, the three classes are as follows:</p>
      <!-- <ol start="4"> -->

      <ol>
        <li>known chunks, which necessarily includes all of the critical chunks defined in this specification (<a class="chunk"
        href="#11IHDR">IHDR</a>, <a class="chunk" href="#11PLTE">PLTE</a>, <a class="chunk" href="#11IDAT">IDAT</a>, <a class=
        "chunk" href="#11IEND">IEND</a>)
        </li>

        <li>unknown critical chunks (bit 5 of the first byte of the chunk type is 0)</li>

        <li>unknown ancillary chunks (bit 5 of the first byte of the chunk type is 1)</li>
      </ol>

      <p>See <a href="#5Chunk-naming-conventions"></a> for a description of chunk naming conventions.</p>
      
      

      <p>PNG chunk types are marked "critical" or "ancillary" according to whether the chunks are critical for the purpose of
      extracting a viewable image (as with <a class="chunk" href="#11IHDR">IHDR</a>, <a class="chunk" href="#11PLTE">PLTE</a>, and
      <a class="chunk" href="#11IDAT">IDAT</a>) or critical to understanding the datastream structure (as with <a class="chunk"
      href="#11IEND">IEND</a>). This is a specific kind of criticality and one that is not necessarily relevant to every
      conceivable decoder. For example, a program whose sole purpose is to extract text annotations (for example, copyright
      information) does not require a viewable image
      but should  <a href="https://encoding.spec.whatwg.org/#utf-8-decode">decode UTF-8 correctly</a>.
      Another decoder might consider the <a class="chunk" href="#11tRNS">tRNS</a>
      and <a class="chunk" href="#11gAMA">gAMA</a> chunks essential to its proper execution.</p>

      <p>Syntax errors always involve known chunks because syntax errors in unknown chunks cannot be detected. The PNG decoder has
      to determine whether a syntax error is fatal (unrecoverable) or not, depending on its requirements and the situation. For
      example, most decoders can ignore an invalid <a class="chunk" href="#11IEND">IEND</a> chunk; a text-extraction program can
      ignore the absence of <a class="chunk" href="#11IDAT">IDAT</a>; an image viewer cannot recover from an empty <a class="chunk"
      href="#11PLTE">PLTE</a> chunk in an indexed image but it can ignore an invalid <a class="chunk" href="#11PLTE">PLTE</a> chunk
      in a <a>truecolor</a> image; and a program that extracts the alpha channel can ignore an invalid <a class="chunk" href=
      "#11gAMA">gAMA</a> chunk, but may consider the presence of two <a class="chunk" href="#11tRNS">tRNS</a> chunks to be a fatal
      error. Anomalous situations other than syntax errors shall be treated as follows:</p>
      <!-- <ol start="7"> -->

      <ol>
        <li>Encountering an unknown ancillary chunk is never an error. The chunk can simply be ignored.</li>

        <li>Encountering an unknown critical chunk is a fatal condition for any decoder trying to extract the image from the
        datastream. A decoder that ignored a critical chunk could not know whether the image it extracted was the one intended by
        the encoder.</li>

        <li>A PNG signature mismatch, a CRC mismatch, or an unexpected end-of-stream indicates a corrupted datastream, and
        may be regarded as a fatal error. A decoder could try to salvage something from the datastream, but the extent of the
        damage will not be known.
        </li>
      </ol>

      <p>When a fatal condition occurs, the decoder should fail immediately, signal an error to the user if appropriate, and
      optionally continue displaying any <a>image data</a> already visible to the user (i.e. "fail gracefully"). The application as
      a whole need not terminate.</p>

      <p>When a non-fatal error occurs, the decoder should signal a warning to the user if appropriate, recover from the error, and
      continue processing normally.</p>

      <p>When decoding an indexed-color PNG, if out-of-range indexes are encountered, decoders have historically varied in their
      handling of this error. <span id="oor-index-black">Displaying the pixel as opaque black</span> is one common error recovery tactic,
      and is now required by this specification.
      Older implementations will vary, and so the behavior
      must not be relied on by encoders.</p>

      <p>Decoders that do not compute CRCs should interpret apparent syntax errors as indications of corruption (see also
      <a href="#13Error-checking"></a>).</p>

      <p>Errors in compressed chunks ( <a class="chunk" href="#11IDAT">IDAT</a>, <a class="chunk" href="#11zTXt">zTXt</a>,
      <a class="chunk" href="#11iTXt">iTXt</a>, <a class="chunk" href="#11iCCP">iCCP</a>) could lead to buffer overruns.
      Implementors of <a>deflate</a> decompressors should guard against this possibility.</p>

      <p>APNG is designed to allow incremental display of frames before the entire <a href="#5DataRep">datastream</a> has been
      read. This implies that some errors may not be detected until partway through the animation. It is strongly recommended that
      when any error is encountered decoders should discard all subsequent frames, stop the animation, and revert to displaying the
      static image. A decoder which detects an error before the animation has started should display the static image. An error
      message may be displayed to the user if appropriate.</p>

      <p>Decoders shall treat out-of-order APNG chunks as an error. APNG-aware <a>PNG editors</a> should restore them to correct
      order, using the sequence numbers.</p>
    </section>
    <!-- Maintain a fragment named "13Error-checking" to preserve incoming links to it -->

    <section id="13Error-checking">
      <h2>Error checking</h2>

      <p>The PNG error handling philosophy is described in <a href="#13Decoders.Errors"></a>.</p>

      <p>An unknown chunk type is <strong>not</strong> to be treated as an error unless it is a critical chunk.</p>

      <p>The chunk type can be checked for plausibility by seeing whether all four bytes are in the range codes 41-5A and 61-7A
      (hexadecimal); note that this need be done only for unrecognized chunk types. If the total datastream size is known (from
      file system information, HTTP protocol, etc), the chunk length can be checked for plausibility as well. If CRCs are
      not checked, dropped/added data bytes or an erroneous chunk length can cause the decoder to get out of step and misinterpret
      subsequent data as a chunk header.</p>

      <p>For known-length chunks, such as <a class="chunk" href="#11IHDR">IHDR</a>, decoders should treat an unexpected chunk
      length as an error. Future extensions to this specification will not add new fields to existing chunks; instead, new chunk
      types will be added to carry new information.</p>

      <p>Unexpected values in fields of known chunks (for example, an unexpected compression method in the <a class="chunk" href=
      "#11IHDR">IHDR</a> chunk) shall be checked for and treated as errors. However, it is recommended that unexpected field values
      be treated as fatal errors only in <strong>critical</strong> chunks. An unexpected value in an ancillary chunk can be handled
      by ignoring the whole chunk as though it were an unknown chunk type. (This recommendation assumes that the chunk's CRC
      has been verified. In decoders that do not check CRCs, it is safer to treat any unexpected value as indicating a
      corrupted datastream.)</p>

      <p>Standard PNG images shall be compressed with compression method 0. The compression method field of the <a class="chunk"
      href="#11IHDR">IHDR</a> chunk is provided for possible future standardization or proprietary variants. Decoders shall check
      this byte and report an error if it holds an unrecognized code. See <a href="#10Compression"></a> for details.</p>
    </section>
    <!-- Maintain a fragment named "13Security-considerations" to preserve incoming links to it -->

    <section id="13Security-considerations">
      <h2>Security considerations</h2>

      <p>A PNG datastream is composed of a collection of explicitly typed chunks.
      Chunks whose contents are defined by the
      specification could actually contain anything, including malicious code.
      Similarly there could be data after the <a class="chunk" href="#11IEND">IEND</a> chunk
      which could contain anything, including malicious code.
      There is no known risk that such malicious code
      could be executed on the recipient's computer <em>as a result of decoding the PNG image</em>.
      However, a malicious application might hide such code inside an innocent-looking image file
      and then execute it.</p>

      <p>The possible security risks associated with future chunk types cannot be specified at this time. Security issues will be
      considered when defining future public chunks. There is no additional security risk associated with unknown or unimplemented
      chunk types, because such chunks will be ignored, or at most be copied into another PNG datastream.</p>

      <p>The <a class="chunk" href="#11iTXt">iTXt</a>, <a class="chunk" href="#11tEXt">tEXt</a>, and <a class="chunk" href=
      "#11zTXt">zTXt</a> chunks contain keywords and data that are meant to be displayed as plain text. The <a class="chunk" href=
      "#11iCCP">iCCP</a> and <a class="chunk" href="#11sPLT">sPLT</a> chunks contain keywords that are meant to be displayed as
      plain text. It is possible that if the decoder displays such text without filtering out control characters, especially the
      ESC (escape) character, certain systems or terminals could behave in undesirable and insecure ways. It is recommended that
      decoders filter out control characters to avoid this risk; see <a href="#13Text-chunk-processing"></a>.</p>

      <p>Every chunk begins with a length field, which makes it easier to write decoders that are invulnerable to fraudulent chunks
      that attempt to overflow buffers. The CRC at the end of every chunk provides a robust defence against accidentally
      corrupted data. The PNG signature bytes provide early detection of common file transmission errors.</p>

      <p>A decoder that fails to check CRCs could be subject to data corruption. The only likely consequence of such
      corruption is incorrectly displayed pixels within the image. Worse things might happen if the CRC of the <a class=
      "chunk" href="#11IHDR">IHDR</a> chunk is not checked and the width or height fields are corrupted. See <a href=
      "#13Error-checking"></a>.</p>

      <p>A poorly written decoder might be subject to buffer overflow, because chunks can be extremely large, up to
      2<sup>31</sup>-1 bytes long. But properly written decoders will handle large chunks without difficulty.</p>
    </section>

    <section id="Privacy-considerations">
      <h2>Privacy considerations</h2>

      <p>Some image editing tools have historically performed redaction
        by merely setting the alpha channel of the redacted area to zero,
        without also removing the actual image data.
        Users who rely solely on the visual appearance of such images
        run a privacy risk
        because the actual image data can be easily recovered.</p>

      <p>Similarly, some image editing tools have historically performed clipping
        by rewriting the width and height in <span class="chunk">IHDR</span>
        without re-encoding the image data,
        which thus extends beyond the new width and height and may be recovered.</p>

      <p>Images with <span class="chunk">eXIf</span> chunks
        may contain automatically-included data,
        such as photographic GPS coordinates,
        which could be a privacy risk if the user is unaware that the PNG image contains this data.
        (Other image formats that contain EXIF, such as JPEG/JFIF, have the same privacy risk).</p>
    </section>
    <!-- Maintain a fragment named "13Chunking" to preserve incoming links to it -->

    <section id="13Chunking">
      <h2>Chunking</h2>

      <p>Decoders shall recognize chunk types by a simple four-byte literal comparison; it is incorrect to perform case conversion
      on chunk types. A decoder encountering an unknown chunk in which the ancillary bit is 1 may safely ignore the chunk and
      proceed to display the image. A decoder trying to extract the image, upon encountering an unknown chunk in which the
      ancillary bit is 0, indicating a critical chunk, shall indicate to the user that the image contains information it cannot
      safely interpret.</p>

      <p>Decoders should test the properties of an unknown chunk type by numerically testing the specified bits. Testing whether a
      character is uppercase or lowercase is inefficient, and even incorrect if a locale-specific case definition is used.</p>

      <p>Decoders should not flag an error if the reserved bit is set to 1, however, as some future version of the PNG
      specification could define a meaning for this bit. It is sufficient to treat a chunk with this bit set in the same way as any
      other unknown chunk type.</p>

      <p>Decoders do not need to test the chunk type private bit, since it has no functional significance and is used to avoid
      conflicts between chunks defined by W3C and those defined privately.</p>

      <p>All ancillary chunks are optional; decoders may ignore them. However, decoders are encouraged to interpret these chunks
      when appropriate and feasible.</p>
    </section>
    <!-- Maintain a fragment named "13Pixel-dimensions" to preserve incoming links to it -->

    <section id="13Pixel-dimensions">
      <h2>Pixel dimensions</h2>

      <p>Non-square pixels can be represented (see <a href="#11pHYs"></a>), but viewers are not required to account for them; a
      viewer can present any PNG datastream as though its pixels are square.</p>

      <p>Where the pixel aspect ratio of the display differs from the aspect ratio of the physical pixel dimensions defined in the
      PNG datastream, viewers are strongly encouraged to rescale images for proper display.</p>

      <p>When the <a class="chunk" href="#11pHYs">pHYs</a> chunk has a unit specifier of 0 (unit is unknown), the behavior of a
      decoder may depend on the ratio of the two pixels-per-unit values, but should not depend on their magnitudes. For example, a
      <a class="chunk" href="#11pHYs">pHYs</a> chunk containing <code>(ppuX, ppuY, unit) = (2, 1, 0)</code> is equivalent to one
      containing <code>(1000, 500, 0)</code>; both are equally valid indications that the image pixels are twice as tall as they
      are wide.</p>

      <p>One reasonable way for viewers to handle a difference between the pixel aspect ratios of the image and the display is to
      expand the image either horizontally or vertically, but not both. The scale factors could be obtained using the following
      floating-point calculations:</p>

      <pre>
<code>image_ratio = pHYs_ppuY / pHYs_ppuX
display_ratio = display_ppuY / display_ppuX
scale_factor_X = max(1.0, image_ratio/display_ratio)
scale_factor_Y = max(1.0, display_ratio/image_ratio)</code>
</pre>
      <p>Because other methods such as maintaining the image area are also reasonable, and because ignoring the <a class="chunk"
      href="#11pHYs">pHYs</a> chunk is permissible, authors should not assume that all viewing applications will use this scaling
      method.</p>

      <p>As well as making corrections for pixel aspect ratio, a viewer may have reasons to perform additional scaling both
      horizontally and vertically. For example, a viewer might want to shrink an image that is too large to fit on the display, or
      to expand images sent to a high-resolution printer so that they appear the same size as they did on the display.</p>
    </section>
    <!-- Maintain a fragment named "13Text-chunk-processing" to preserve incoming links to it -->

    <section id="13Text-chunk-processing">
      <h2>Text chunk processing</h2>

      <p>If practical, PNG decoders should have a way to display to the user all the <a class="chunk" href="#11iTXt">iTXt</a>,
      <a class="chunk" href="#11tEXt">tEXt</a>, and <a class="chunk" href="#11zTXt">zTXt</a> chunks found in the datastream. Even
      if the decoder does not recognize a particular text keyword, the user might be able to understand it.</p>

      <p>When processing <a class="chunk" href="#11tEXt">tEXt</a> and <a class="chunk" href="#11zTXt">zTXt</a> chunks, decoders
      could encounter characters other than those permitted. Some can be safely displayed (e.g., TAB, FF, and CR, hexadecimal 09,
      0C, and 0D, respectively), but others, especially the ESC character (hexadecimal 1B), could pose a security hazard (because
      unexpected actions may be taken by display hardware or software). Decoders should not attempt to directly display any
      non-Latin-1 characters (except for newline and perhaps TAB, FF, CR) encountered in a <a class="chunk" href="#11tEXt">tEXt</a>
      or <a class="chunk" href="#11zTXt">zTXt</a> chunk. Instead, they should be ignored or displayed in a visible notation such as
      "<code>\nnn</code>". See <a href="#13Security-considerations"></a>.</p>

      <p>When processing <a href="#11iTXt" class="chunk">iTXt</a> chunks,
        decoders should follow <a href="https://encoding.spec.whatwg.org/#utf-8-decode">UTF-8 decode</a> in [[[ENCODING]]].
      </p>

      <p>Even though encoders are recommended to represent newlines as linefeed (hexadecimal 0A), it is recommended that decoders
      not rely on this; it is best to recognize all the common newline combinations (CR, LF, and CR-LF) and display each as a
      single newline. TAB can be expanded to the proper number of spaces needed to arrive at a column multiple of 8.</p>

      <p>Decoders running on systems with a non-Latin-1 <a>legacy character encoding</a> should remap character codes so that
      Latin-1 characters are displayed correctly. Unsupported characters should be replaced with a system-appropriate replacement
      character (such as U+FFFD REPLACEMENT CHARACTER, U+003F QUESTION MARK, or U+001A SUB) or mapped to a visible notation such as
      "<code>\nnn</code>". Characters should be only displayed if they are printable characters on the decoding system. Some byte
      values may be interpreted by the decoding system as control characters; for security, decoders running on such systems should
      not display these control characters.</p>

      <p>Decoders should be prepared to display text chunks that contain any number of printing characters between newline
      characters, even though it is recommended that encoders avoid creating lines in excess of 79 characters.</p>
    </section>
    <!-- Maintain a fragment named "13Decompression" to preserve incoming links to it -->

    <section id="13Decompression">
      <h2>Decompression</h2>

      <p>The compression technique used in this specification does not require the entire compressed datastream to be available
      before decompression can start. Display can therefore commence before the entire decompressed datastream is available. It is
      extremely unlikely that any general purpose compression methods in future versions of this specification will not have this
      property.</p>

      <p>It is important to emphasize that <a class="chunk" href="#11IDAT">IDAT</a> chunk boundaries have no semantic significance
      and can occur at any point in the compressed datastream. There is no required correlation between the structure of the
      <a>image data</a> (for example, scanline boundaries) and <a>deflate</a> block boundaries or <a class="chunk" href=
      "#11IDAT">IDAT</a> chunk boundaries. The complete <a>image data</a> is represented by a single <a>zlib</a> datastream that is
      stored in some number of <a class="chunk" href="#11IDAT">IDAT</a> chunks; a decoder that assumes any more than this is
      incorrect. Some encoder implementations may emit datastreams in which some of these structures are indeed related, but
      decoders cannot rely on this.</p>
    </section>
    <!-- Maintain a fragment named "13Filtering" to preserve incoming links to it -->

    <section id="13Filtering">
      <h2>Filtering</h2>

      <p>To reverse the effect of a filter, the decoder may need to use the decoded values of the prior pixel on the same line, the
      pixel immediately above the current pixel on the prior line, and the pixel just to the left of the pixel above. This implies
      that at least one scanline's worth of <a>image data</a> needs to be stored by the decoder at all times. Even though some
      filter types do not refer to the prior scanline, the decoder will always need to store each scanline as it is decoded, since
      the next scanline might use a filter type that refers to it. See <a href="#7Filtering"></a>.</p>
    </section>
    <!-- Maintain a fragment named "13Progressive-display" to preserve incoming links to it -->

    <section id="13Progressive-display">
      <h2>Interlacing and progressive display</h2>

      <p>Decoders are required to be able to read interlaced images. If the reference image contains fewer than five columns or
      fewer than five rows, some passes will be empty. Encoders and decoders shall handle this case correctly. In particular,
      filter type bytes are associated only with nonempty scanlines; no filter type bytes are present in an empty reduced
      image.</p>

      <p>When receiving images over slow transmission links, viewers can improve perceived performance by displaying interlaced
      images progressively. This means that as each reduced image is received, an approximation to the complete image is displayed
      based on the data received so far. One simple yet pleasing effect can be obtained by expanding each received pixel to fill a
      rectangle covering the yet-to-be-transmitted pixel positions below and to the right of the received pixel. This process can
      be described by the following ISO C code [[ISO_9899]]:</p>

      <pre>
/*
    variables declared and initialized elsewhere in the code:
        height, width
    functions or macros defined elsewhere in the code:
        visit(), min()
 */

int starting_row[7]  = { 0, 0, 4, 0, 2, 0, 1 };
int starting_col[7]  = { 0, 4, 0, 2, 0, 1, 0 };
int row_increment[7] = { 8, 8, 8, 4, 4, 2, 2 };
int col_increment[7] = { 8, 8, 4, 4, 2, 2, 1 };
int block_height[7]  = { 8, 8, 4, 4, 2, 2, 1 };
int block_width[7]   = { 8, 4, 4, 2, 2, 1, 1 };

int pass;
long row, col;

pass = 0;
while (pass &lt; 7)
{
    row = starting_row[pass];
    while (row &lt; height)
    {
        col = starting_col[pass];
        while (col &lt; width)
        {
            visit(row, col,
                  min(block_height[pass], height - row),
                  min(block_width[pass], width - col));
            col = col + col_increment[pass];
        }
        row = row + row_increment[pass];
    }
    pass = pass + 1;
}
</pre>
      <p>The function <code>visit(row,column,height,width)</code> obtains the next transmitted pixel and paints a rectangle of the
      specified height and width, whose upper-left corner is at the specified row and column, using the color indicated by the
      pixel. Note that row and column are measured from 0,0 at the upper left corner.</p>

      <p>If the viewer is merging the received image with a background image, it may be more convenient just to paint the received
      pixel positions (the <code>visit()</code> function sets only the pixel at the specified row and column, not the whole
      rectangle). This produces a "fade-in" effect as the new image gradually replaces the old. An advantage of this approach is
      that proper alpha or transparency processing can be done as each pixel is replaced. Painting a rectangle as described above
      will overwrite background-image pixels that may be needed later, if the pixels eventually received for those positions turn
      out to be wholly or partially transparent. This is a problem only if the background image is not stored anywhere
      offscreen.</p>
    </section>
    <!-- Maintain a fragment named "13Truecolour-image-handling" to preserve incoming links to it -->

    <section id="13Truecolour-image-handling">
      <h2>Truecolor image handling</h2>

      <p>To achieve PNG's goal of universal interchangeability, decoders shall accept all types of PNG image: <a>indexed-color</a>,
      <a>truecolor</a>, and <a>greyscale</a>. Viewers running on indexed-color display hardware need to be able to reduce
      <a>truecolor</a> images to indexed-color for viewing. This process is called "color quantization".</p>

      <p>A simple, fast method for color quantization is to reduce the image to a fixed palette. Palettes with uniform color
      spacing ("color cubes") are usually used to minimize the per-pixel computation. For photograph-like images, dithering is
      recommended to avoid ugly contours in what should be smooth gradients; however, dithering introduces graininess that can be
      objectionable.</p>

      <p>The quality of rendering can be improved substantially by using a palette chosen specifically for the image, since a
      color cube usually has numerous entries that are unused in any particular image. This approach requires more work, first in
      choosing the palette, and second in mapping individual pixels to the closest available color. PNG allows the encoder to
      supply suggested palettes, but not all encoders will do so, and the suggested palettes may be unsuitable in any case (they
      may have too many or too few colors). Therefore, high-quality viewers will need to have a palette selection routine at hand.
      A large lookup table is usually the most feasible way of mapping individual pixels to palette entries with adequate
      speed.</p>

      <p>Numerous implementations of color quantization are available. The PNG sample implementation, libpng (<a href=
      "http://www.libpng.org/pub/png/libpng.html"><code>http://www.libpng.org/pub/png/libpng.html</code></a>), includes code for
      the purpose.</p>
    </section>
    <!-- Maintain a fragment named "13Sample-depth-rescaling" to preserve incoming links to it -->

    <section id="13Sample-depth-rescaling">
      <h2>Sample depth rescaling</h2>

      <p>Decoders may wish to scale PNG data to a lesser sample depth (data precision) for display. For example, 16-bit data will
      need to be reduced to 8-bit depth for use on most present-day display hardware. Reduction of 8-bit data to 5-bit depth is
      also common.</p>

      <p>The most accurate scaling is achieved by the linear equation</p>

      <p><code>output = floor((input * MAXOUTSAMPLE / MAXINSAMPLE) + 0.5)</code>
      </p>

      <p>where</p>

      <p><code>MAXINSAMPLE = (2<sup>sampledepth</sup>)-1</code><br>
      <code>MAXOUTSAMPLE = (2<sup>desired_sampledepth</sup>)-1</code>
      </p>

      <p>A slightly less accurate conversion is achieved by simply shifting right by <code>(sampledepth -
      desired_sampledepth)</code> places. For example, to reduce 16-bit samples to 8-bit, the low-order byte can be discarded. In
      many situations the shift method is sufficiently accurate for display purposes, and it is certainly much faster. (But if
      <a>gamma</a> correction is being done, sample rescaling can be merged into the <a>gamma</a> correction lookup table, as is
      illustrated in <a href="#13Decoder-gamma-handling"></a>.)</p>

      <p>If the decoder needs to scale samples up (for example, if the <a>frame buffer</a> has a greater sample depth than the PNG
      image), it should use linear scaling or left-bit-replication as described in <a href="#12Sample-depth-scaling"></a>.</p>

      <p>When an <a class="chunk" href="#11sBIT">sBIT</a> chunk is present, the reference <a>image data</a> can be recovered by
      shifting right to the sample depth specified by <a class="chunk" href="#11sBIT">sBIT</a>. Note that linear scaling will not
      necessarily reproduce the original data, because the encoder is not required to have used linear scaling to scale the data
      up. However, the encoder is required to have used a method that preserves the high-order bits, so shifting always works. This
      is the only case in which shifting might be said to be more accurate than linear scaling. A decoder need not pay attention to
      the <a class="chunk" href="#11sBIT">sBIT</a> chunk; the stored image is a valid PNG datastream of the sample depth indicated
      by the <a class="chunk" href="#11IHDR">IHDR</a> chunk; however, using <a class="chunk" href="#11sBIT">sBIT</a> to recover the
      original samples before scaling them to suit the display often yields a more accurate display than ignoring <a class="chunk"
      href="#11sBIT">sBIT</a>.</p>

      <p id="tRNS-compare-exactly">When comparing pixel values to <a class="chunk" href="#11tRNS">tRNS</a> chunk values to detect transparent pixels, the
      comparison shall be done exactly. Therefore, transparent pixel detection shall be done before reducing sample precision.</p>
    </section>
    <!-- Maintain a fragment named "13Decoder-gamma-handling" to preserve incoming links to it -->

    <section id="13Decoder-gamma-handling">
      <h2>Decoder gamma handling</h2>

      <p>See <a href="#C-GammaAppendix"></a> for a brief introduction to <a>gamma</a> issues.</p>

      <p>Viewers capable of full color management will perform more sophisticated calculations than those described here.</p>

      <p>For an image display program to produce correct tone reproduction, it is necessary to take into account the relationship
      between samples and display output, and the <a>transfer function</a> of the display system. This can be done by
      calculating:</p>

      <p><code>sample = integer_sample / (2<sup>sampledepth</sup> - 1.0)<br>
      display_output = sample<sup>1.0/gamma</sup><br>
      display_input = inverse_display_transfer(display_output)<br>
      framebuf_sample = floor((display_input * MAX_FRAMEBUF_SAMPLE)+0.5)</code>
      </p>

      <p>where <var>integer_sample</var> is the sample value from the datastream, <var>framebuf_sample</var> is the value to write
      into the <a>frame buffer</a>, and <var>MAX_FRAMEBUF_SAMPLE</var> is the maximum value of a <a>frame buffer</a> sample (255
      for 8-bit, 31 for 5-bit, etc). The first line converts an integer sample into a normalized floating point value (in the range
      0.0 to 1.0), the second converts to a value proportional to the desired display output intensity, the third accounts for the
      display system's <a>transfer function</a>, and the fourth converts to an integer <a>frame buffer</a> sample. Zero raised to
      any positive power is zero.</p>

      <p>A step could be inserted between the second and third to adjust <var>display_output</var> to account for the difference
      between the actual viewing conditions and the reference viewing conditions. However, this adjustment requires accounting for
      veiling glare, black mapping, and color appearance models, none of which can be well approximated by power functions. Such
      calculations are not described here. If viewing conditions are ignored, the error will usually be small.</p>

      <p>The display <a>transfer function</a> can typically be approximated by a power function with exponent
      <var>display_exponent</var>, in which case the second and third lines can be merged into:</p>

      <p><code>display_input = sample<sup>1.0/(gamma * display_exponent)</sup> = sample<sup>decoding_exponent</sup></code>
      </p>

      <p>so as to perform only one power calculation. For color images, the entire calculation is performed separately for R, G,
      and B values.</p>

      <p>The <a>gamma value</a> can be taken directly from the <a class="chunk" href="#11gAMA">gAMA</a> chunk. Alternatively, an
      application may wish to allow the user to adjust the appearance of the displayed image by influencing the <a>gamma value</a>.
      For example, the user could manually set a parameter <var>user_exponent</var> which defaults to 1.0, and the application
      could set:</p>

      <pre>
<code>gamma = gamma_from_file / user_exponent
decoding_exponent = 1.0 / (gamma * display_exponent)
   = user_exponent / (gamma_from_file * display_exponent)</code>
</pre>
      <p>The user would set <var>user_exponent</var> greater than 1 to darken the mid-level tones, or less than 1 to lighten
      them.</p>

      <p>A <a class="chunk" href="#11gAMA">gAMA</a> chunk containing zero is meaningless but could appear by mistake. Decoders
      should ignore it, and editors may discard it and issue a warning to the user.</p>

      <p>It is <strong>not</strong> necessary to perform a transcendental mathematical computation for every pixel. Instead, a
      lookup table can be computed that gives the correct output value for every possible sample value. This requires only 256
      calculations per image (for 8-bit accuracy), not one or three calculations per pixel. For an indexed-color image, a one-time
      correction of the palette is sufficient, unless the image uses transparency and is being displayed against a nonuniform
      background.</p>

      <p>If floating-point calculations are not possible, <a>gamma</a> correction tables can be computed using integer arithmetic
      and a precomputed table of logarithms. Example code appears in [[PNG-EXTENSIONS]].</p>

      <p>When the incoming image has unknown <a>gamma value</a> (<a class="chunk" href="#11gAMA">gAMA</a>, <a class="chunk" href=
      "#srgb-standard-colour-space">sRGB</a>, and <a class="chunk" href="#11iCCP">iCCP</a> all absent), standalone image viewers
      should choose a likely default <a>gamma value</a>, but allow the user to select a new one if the result proves too dark or
      too light. The default <a>gamma value</a> may depend on other knowledge about the image, for example whether it came from the
      Internet or from the local system. For consistency, viewers for document formats such as HTML, or vector graphics such as
      SVG, should treat embedded or linked PNG images with unknown <a>gamma value</a> in the same way that they treat other
      untagged images.</p>

      <p>In practice, it is often difficult to determine what value of display exponent should be used. In systems with no built-in
      <a>gamma</a> correction, the display exponent is determined entirely by the CRT. A display exponent of 2.2 should be
      used unless detailed calibration measurements are available for the particular CRT used.</p>

      <p>Many modern <a>frame buffers</a> have lookup tables that are used to perform <a>gamma</a> correction, and on these systems
      the display exponent value should be the exponent of the lookup table and CRT combined. It may not be possible to find
      out what the lookup table contains from within the viewer application, in which case it may be necessary to ask the user to
      supply the display system's exponent value. Unfortunately, different manufacturers use different ways of specifying what
      should go into the lookup table, so interpretation of the system <a>gamma value</a> is system-dependent.</p>

      <p>The response of real displays is actually more complex than can be described by a single number (the display exponent). If
      actual measurements of the monitor's light output as a function of voltage input are available, the third and fourth lines of
      the computation above can be replaced by a lookup in these measurements, to find the actual <a>frame buffer</a> value that
      most nearly gives the desired brightness.</p>
    </section>
    <!-- Maintain a fragment named "13Decoder-colour-handling" to preserve incoming links to it -->

    <section id="13Decoder-colour-handling">
      <h2>Decoder color handling</h2>

      <p>See <a href="#C-GammaAppendix"></a> for references to color issues.</p>

      <p>In many cases, the <a>image data</a> in PNG datastreams will be treated as device-dependent RGB values and displayed
      without modification (except for appropriate <a>gamma</a> correction). This provides the fastest display of PNG images. But
      unless the viewer uses exactly the same display hardware as that used by the author of the original image, the colors will
      not be exactly the same as those seen by the original author, particularly for darker or near-neutral colors. The <a class=
      "chunk" href="#11cHRM">cHRM</a> chunk provides information that allows closer color matching than that provided by
      <a>gamma</a> correction alone.</p>

      <p>The <a class="chunk" href="#11cHRM">cHRM</a> data can be used to transform the <a>image data</a> from RGB to XYZ and
      thence into a perceptually linear color space such as CIE LAB. The colors can be partitioned to generate an optimal
      palette, because the geometric distance between two colors in CIE LAB is strongly related to how different those colors
      appear (unlike, for example, RGB or XYZ spaces). The resulting palette of colors, once transformed back into RGB color
      space, could be used for display or written into a <a class="chunk" href="#11PLTE">PLTE</a> chunk.</p>

      <p>Decoders that are part of image processing applications might also transform <a>image data</a> into CIE LAB space for
      analysis.</p>

      <p>In applications where color fidelity is critical, such as product design, scientific visualization, medicine,
      architecture, or advertising, PNG decoders can transform the <a>image data</a> from source RGB to the display RGB space of
      the monitor used to view the image. This involves calculating the matrix to go from source RGB to XYZ and the matrix to go
      from XYZ to display RGB, then combining them to produce the overall transformation. The PNG decoder is responsible for
      implementing gamut mapping.</p>

      <p>Decoders running on platforms that have a Color Management System (CMS) can pass the <a>image data</a>, <a class="chunk"
      href="#11gAMA">gAMA</a>, and <a class="chunk" href="#11cHRM">cHRM</a> values to the CMS for display or further
      processing.</p>

      <p>PNG decoders that provide color printing facilities can use the facilities in Level 2 PostScript to specify <a>image
      data</a> in calibrated RGB space or in a device-independent color space such as XYZ. This will provide better color
      fidelity than a simple RGB to CMYK conversion. The PostScript Language Reference manual [[?PostScript]] gives examples. Such
      decoders are responsible for implementing gamut mapping between source RGB (specified in the <a class="chunk" href=
      "#11cHRM">cHRM</a> chunk) and the target printer. The PostScript interpreter is then responsible for producing the required
      colors.</p>

      <p>PNG decoders can use the <a class="chunk" href="#11cHRM">cHRM</a> data to calculate an accurate greyscale representation
      of a color image. Conversion from RGB to grey is simply a case of calculating the Y (luminance) component of XYZ, which is a
      weighted sum of R, G, and B values. The weights depend upon the monitor type, i.e. the values in the <a class="chunk" href=
      "#11cHRM">cHRM</a> chunk. PNG decoders may wish to do this for PNG datastreams with no <a class="chunk" href=
      "#11cHRM">cHRM</a> chunk. In this case, a reasonable default would be the CCIR 709 primaries [[ITU-R-BT.709]]. The original
      NTSC primaries should <strong>not</strong> be used unless the PNG image really was color-balanced for such a monitor.</p>
    </section>
    <!-- Maintain a fragment named "13Background-colour" to preserve incoming links to it -->

    <section id="13Background-colour">
      <h2>Background color</h2>

      <p>The background color given by the <a class="chunk" href="#11bKGD">bKGD</a> chunk will typically be used to fill unused
      screen space around the image, as well as any transparent pixels within the image. (Thus, <a class="chunk" href=
      "#11bKGD">bKGD</a> is valid and useful even when the image does not use transparency.) If no <a class="chunk" href=
      "#11bKGD">bKGD</a> chunk is present, the viewer will need to decide upon a suitable background color. When no other
      information is available, a medium grey such as 153 in the 8-bit sRGB color space would be a reasonable choice. Transparent
      black or white text and dark drop shadows, which are common, would all be legible against this background.</p>

      <p>Viewers that have a specific background against which to present the image (such as web browsers) should ignore the
      <a class="chunk" href="#11bKGD">bKGD</a> chunk, in effect overriding <a class="chunk" href="#11bKGD">bKGD</a> with their
      preferred background color or background image.</p>

      <p>The background color given by the <a class="chunk" href="#11bKGD">bKGD</a> chunk is not to be considered transparent,
      even if it happens to match the color given by the <a class="chunk" href="#11tRNS">tRNS</a> chunk (or, in the case of an
      <a>indexed-color</a> image, refers to a palette index that is marked as transparent by the <a class="chunk" href="#11tRNS">tRNS</a>
      chunk). Otherwise one would have to imagine something "behind the background" to <a>composite</a> against. The background
      color is either used as background or ignored; it is not an intermediate layer between the PNG image and some other
      background.</p>

      <p>Indeed, it will be common that the <a class="chunk" href="#11bKGD">bKGD</a> and <a class="chunk" href="#11tRNS">tRNS</a>
      chunks specify the same color, since then a decoder that does not implement transparency processing will give the intended
      display, at least when no partially-transparent pixels are present.</p>
    </section>
    <!-- Maintain a fragment named "13Alpha-channel-processing" to preserve incoming links to it -->

    <section id="13Alpha-channel-processing">
      <h2>Alpha channel processing</h2>

      <p>The alpha channel can be used to <a>composite</a> a foreground image against a background image. The PNG datastream
      defines the foreground image and the transparency mask, but not the background image. PNG decoders are <strong>not</strong>
      required to support this most general case. It is expected that most will be able to support compositing against a single
      background color.</p>

      <p>The equation for computing a <a>composited</a> sample value is:</p>

      <pre>
output = alpha * foreground + (1-alpha) * background
</pre>
      <p>where alpha and the input and output sample values are expressed as fractions in the range 0 to 1. This computation should
      be performed with intensity samples (not <a>gamma</a>-encoded samples). For color images, the computation is done separately
      for R, G, and B samples.</p>

      <p>The following code illustrates the general case of compositing a foreground image against a background image. It assumes
      that the original pixel data are available for the background image, and that output is to a <a>frame buffer</a> for display.
      Other variants are possible; see the comments below the code. The code allows the sample depths and <a>gamma values</a> of
      foreground image and background image all to be different and not necessarily suited to the display system. In practice no
      assumptions about equality should be made without first checking.</p>
      
      

      <p>This code is ISO C [[ISO_9899]], with line numbers added for reference in the comments below.</p>

      <pre>
   01  int foreground[4];  /* image pixel: R, G, B, A */
   02  int background[3];  /* background pixel: R, G, B */
   03  int fbpix[3];       /* frame buffer pixel */
   04  int fg_maxsample;   /* foreground max sample */
   05  int bg_maxsample;   /* background max sample */
   06  int fb_maxsample;   /* frame buffer max sample */
   07  int ialpha;
   08  float alpha, compalpha;
   09  float gamfg, linfg, gambg, linbg, comppix, gcvideo;

       /* Get max sample values in data and frame buffer */
   10  fg_maxsample = (1 &lt;&lt; fg_sample_depth) - 1;
   11  bg_maxsample = (1 &lt;&lt; bg_sample_depth) - 1;
   12  fb_maxsample = (1 &lt;&lt; frame_buffer_sample_depth) - 1;
       /*
        * Get integer version of alpha.
        * Check for opaque and transparent special cases;
        * no compositing needed if so.
        *
        * We show the whole gamma decode/correct process in
        * floating point, but it would more likely be done
        * with lookup tables.
        */
   13  ialpha = foreground[3];

   14  if (ialpha == 0) {
           /*
            * Foreground image is transparent here.
            * If the background image is already in the frame
            * buffer, there is nothing to do.
            */
   15      ;
   16  } else if (ialpha == fg_maxsample) {
           /*
            * Copy foreground pixel to frame buffer.
            */
   17      for (i = 0; i &lt; 3; i++) {
   18          gamfg = (float) foreground[i] / fg_maxsample;
   19          linfg = pow(gamfg, 1.0 / fg_gamma);
   20          comppix = linfg;
   21          gcvideo = pow(comppix, 1.0 / display_exponent);
   22          fbpix[i] = (int) (gcvideo * fb_maxsample + 0.5);
   23      }
   24  } else {
           /*
            * Compositing is necessary.
            * Get floating-point alpha and its complement.
            * Note: alpha is always linear; gamma does not
            * affect it.
            */
   25      alpha = (float) ialpha / fg_maxsample;
   26      compalpha = 1.0 - alpha;

   27      for (i = 0; i &lt; 3; i++) {
               /*
                * Convert foreground and background to floating
                * point, then undo gamma encoding.
                */
   28          gamfg = (float) foreground[i] / fg_maxsample;
   29          linfg = pow(gamfg, 1.0 / fg_gamma);
   30          gambg = (float) background[i] / bg_maxsample;
</pre>
      

      <pre>
   31          linbg = pow(gambg, 1.0 / bg_gamma);
               /*
                * Composite.
                */
   32          comppix = linfg * alpha + linbg * compalpha;
               /*
                * Gamma correct for display.
                * Convert to integer frame buffer pixel.
                */
   33          gcvideo = pow(comppix, 1.0 / display_exponent);
   34          fbpix[i] = (int) (gcvideo * fb_maxsample + 0.5);
   35      }
   36  }
</pre>
      <p>Variations:</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>If output is to another PNG datastream instead of a <a>frame buffer</a>, lines 21, 22, 33, and 34 should be changed
        along the following lines

          <pre>
   /*
    * Gamma encode for storage in output datastream.
    * Convert to integer sample value.
    */
   gamout = pow(comppix, outfile_gamma);
   outpix[i] = (int) (gamout * out_maxsample + 0.5);
</pre>Also, it becomes necessary to process background pixels when alpha is zero, rather than just skipping pixels. Thus, line 15
will need to be replaced by copies of lines 17-23, but processing background instead of foreground pixel values.
        </li>

        <li>If the sample depths of the output file, foreground file, and background file are all the same, and the three <a>gamma
        values</a> also match, then the no-compositing code in lines 14-23 reduces to copying pixel values from the input file to
        the output file if alpha is one, or copying pixel values from background to output file if alpha is zero. Since alpha is
        typically either zero or one for the vast majority of pixels in an image, this is a significant saving. No <a>gamma</a>
        computations are needed for most pixels.
        </li>

        <li>When the sample depths and <a>gamma values</a> all match, it may appear attractive to skip the <a>gamma</a> decoding
        and encoding (lines 28-31, 33-34) and just perform line 32 using <a>gamma</a>-encoded sample values. Although this does not
        have too bad an effect on image quality, the time savings are small if alpha values of zero and one are treated as special
        cases as recommended here.
        </li>

        <li>If the original pixel values of the background image are no longer available, only processed <a>frame buffer</a> pixels
        left by display of the background image, then lines 30 and 31 need to extract intensity from the <a>frame buffer</a> pixel
        values using code such as

          <pre>
   /*
    * Convert frame buffer value into intensity sample.
    */
   gcvideo = (float) fbpix[i] / fb_maxsample;
   linbg = pow(gcvideo, display_exponent);
</pre>However, some roundoff error can result, so it is better to have the original background pixels available if at all possible.
        </li>

        <li>Note that lines 18-22 are performing exactly the same <a>gamma</a> computation that is done when no alpha channel is
        present. If the no-alpha case is handled with a lookup table, the same lookup table can be used here. Lines 28-31 and 33-34
        can also be done with (different) lookup tables.
        </li>

        <li>Integer arithmetic can be used instead of floating point, providing care is taken to maintain sufficient precision
        throughout.</li>
      </ol>

      <p class="note">NOTE In floating point, no overflow or underflow checks are needed, because the input sample values are
      guaranteed to be between 0 and 1, and compositing always yields a result that is in between the input values (inclusive).
      With integer arithmetic, some roundoff-error analysis might be needed to guarantee no overflow or underflow.</p>
      
      

      <p>When displaying a PNG image with full alpha channel, it is important to be able to <a>composite</a> the image against some
      background, even if it is only black. Ignoring the alpha channel will cause PNG images that have been converted from an
      associated-alpha representation to look wrong. (Of course, if the alpha channel is a separate transparency mask, then
      ignoring alpha is a useful option: it allows the hidden parts of the image to be recovered.)</p>

      <p>Even if the decoder does not implement true compositing logic, it is simple to deal with images that contain only zero and
      one alpha values. (This is implicitly true for <a>greyscale</a> and <a>truecolor</a> PNG datastreams that use a <a class="chunk"
      href="#11tRNS">tRNS</a> chunk; for <a>indexed-color</a> PNG datastreams it is easy to check whether the <a class="chunk" href=
      "#11tRNS">tRNS</a> chunk contains any values other than 0 and 255.) In this simple case, transparent pixels are replaced by
      the background color, while others are unchanged.</p>

      <p>If a decoder contains only this much transparency capability, it should deal with a full alpha channel by treating all
      nonzero alpha values as fully opaque or by dithering. Neither approach will yield very good results for images converted from
      associated-alpha formats, but this is preferable to doing nothing. Dithering full alpha to binary alpha is very much like
      dithering greyscale to black-and-white, except that all fully transparent and fully opaque pixels should be left unchanged by
      the dither.</p>
    </section>
    <!-- Maintain a fragment named "13Histogram-and-suggested-palette-usage" to preserve incoming links to it -->

    <section id="13Histogram-and-suggested-palette-usage">
      <h2>Histogram and suggested palette usage</h2>

      <p>For viewers running on indexed-color hardware attempting to display a <a>truecolor</a> image, or an indexed-color image
      whose palette is too large for the <a>frame buffer</a>, the encoder may have provided one or more suggested palettes in
      <a class="chunk" href="#11sPLT">sPLT</a> chunks. If one of these is found to be suitable, based on size and perhaps name, the
      PNG decoder can use that palette. Suggested palettes with a sample depth different from what the decoder needs can be
      converted using sample depth rescaling (see <a href="#13Sample-depth-rescaling"></a>).</p>

      <p>When the background is a solid color, the viewer should <a>composite</a> the image and the suggested palette against that
      color, then quantize the resulting image to the resulting RGB palette. When the image uses transparency and the background
      is not a solid color, no suggested palette is likely to be useful.</p>

      <p>For <a>truecolor</a> images, a suggested palette might also be provided in a <a class="chunk" href="#11PLTE">PLTE</a>
      chunk. If the image has a <a class="chunk" href="#11tRNS">tRNS</a> chunk and the background is a solid color, the viewer
      will need to adapt the suggested palette for use with its desired background color. To do this, the palette entry closest to
      the <a class="chunk" href="#11tRNS">tRNS</a> color should be replaced with the desired background color; or alternatively a
      palette entry for the background color can be added, if the viewer can handle more colors than there are <a class="chunk"
      href="#11PLTE">PLTE</a> entries.</p>

      <p>For images of <a>color type</a> 6 (<a>truecolor with alpha</a>), any <a class="chunk" href="#11PLTE">PLTE</a> chunk
      should have been designed for display of the image against a uniform background of the color specified by the <a class=
      "chunk" href="#11bKGD">bKGD</a> chunk. Viewers should probably ignore the palette if they intend to use a different
      background, or if the <a class="chunk" href="#11bKGD">bKGD</a> chunk is missing. Viewers can use a suggested palette for
      display against a different background than it was intended for, but the results may not be very good.</p>

      <p>If the viewer presents a transparent <a>truecolor</a> image against a background that is more complex than a uniform
      color, it is unlikely that the suggested palette will be optimal for the <a>composite</a> image. In this case it is best to
      perform a <a>truecolor</a> compositing step on the <a>truecolor</a> PNG image and background image, then color-quantize
      the resulting image.</p>

      <p>In <a>truecolor</a> PNG datastreams, if both <a class="chunk" href="#11PLTE">PLTE</a> and <a class="chunk" href=
      "#11sPLT">sPLT</a> chunks appear, the PNG decoder may choose from among the palettes suggested by both, bearing in mind the
      different transparency semantics described above.</p>

      <p>The frequencies in the <a class="chunk" href="#11sPLT">sPLT</a> and <a class="chunk" href="#11hIST">hIST</a> chunks are
      useful when the viewer cannot provide as many colors as are used in the palette in the PNG datastream. If the viewer has a
      shortfall of only a few colors, it is usually adequate to drop the least-used colors from the palette. To reduce the number
      of colors substantially, it is best to choose entirely new representative colors, rather than trying to use a subset of the
      existing palette. This amounts to performing a new color quantization step; however, the existing palette and histogram can
      be used as the input data, thus avoiding a scan of the <a>image data</a> in the <a class="chunk" href="#11IDAT">IDAT</a>
      chunks.</p>

      <p>If no suggested palette is provided, a decoder can develop its own, at the cost of an extra pass over the <a>image
      data</a> in the <a class="chunk" href="#11IDAT">IDAT</a> chunks. Alternatively, a default palette (probably a color cube)
      can be used.</p>

      <p>See also <a href="#12Suggested-palettes"></a>.</p>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "14EditorsExt" to preserve incoming links to it -->

  <section id="14EditorsExt">
    <h2>Editors</h2>
    <!-- Maintain a fragment named "14Additional-chunk-types" to preserve incoming links to it -->

    <section id="14Additional-chunk-types">
      <h2>Additional chunk types</h2>

      <p>Authors are encouraged to look existing chunk types in both this specification and [[PNG-EXTENSIONS]] before considering
      introducing a new chunk types. The chunk types at [[PNG-EXTENSIONS]] are expected to be less widely supported than those
      defined in this specification.</p>
    </section>
    <!-- Maintain a fragment named "14Ordering" to preserve incoming links to it -->

    <section id="14Ordering">
      <h2>Behavior of PNG editors</h2>

      <p>Two examples of <a>PNG editors</a> are a program that adds or modifies text chunks, and a program that adds a suggested
      palette to a <a>truecolor</a> PNG datastream. Ordinary image editors are not <a>PNG editors</a> because they usually discard
      all unrecognized information while reading in an image.</p>

      <p>To allow new chunk types to be added to PNG, it is necessary to establish rules about the ordering requirements for all
      chunk types. Otherwise a <a>PNG editor</a> does not know what to do when it encounters an unknown chunk.</p>

      <p>EXAMPLE Consider a hypothetical new ancillary chunk type that is safe-to-copy and is required to appear after <a class=
      "chunk" href="#11PLTE">PLTE</a> if <a class="chunk" href="#11PLTE">PLTE</a> is present. If a program attempts to add a
      <a class="chunk" href="#11PLTE">PLTE</a> chunk and does not recognize the new chunk, it may insert the <a class="chunk" href=
      "#11PLTE">PLTE</a> chunk in the wrong place, namely after the new chunk. Such problems could be prevented by requiring <a>PNG
      editors</a> to discard all unknown chunks, but that is a very unattractive solution. Instead, PNG requires ancillary chunks
      not to have ordering restrictions like this.</p>

      <p>To prevent this type of problem while allowing for future extension, constraints are placed on both the behavior of
      <a>PNG editors</a> and the allowed ordering requirements for chunks. The safe-to-copy bit defines the proper handling of
      unrecognized chunks in a datastream that is being modified.</p>
      <!-- <ol start="1"> -->

      <ol>
        <li>If a chunk's safe-to-copy bit is 1, the chunk may be copied to a modified PNG datastream whether or not the <a>PNG
        editor</a> recognizes the chunk type, and regardless of the extent of the datastream modifications.
        </li>

        <li>If a chunk's safe-to-copy bit is 0, it indicates that the chunk depends on the <a>image data</a>. If the program has
        made <strong>any</strong> changes to <strong>critical</strong> chunks, including addition, modification, deletion, or
        reordering of critical chunks, then unrecognized unsafe chunks shall <strong>not</strong> be copied to the output PNG
        datastream. (Of course, if the program <strong>does</strong> recognize the chunk, it can choose to output an appropriately
        modified version.)
        </li>

        <li>A <a>PNG editor</a> is always allowed to copy all unrecognized ancillary chunks if it has only added, deleted,
        modified, or reordered <strong>ancillary</strong> chunks. This implies that it is not permissible for ancillary chunks to
        depend on other ancillary chunks.
        </li>

        <li>
          <a>PNG editors</a> shall terminate on encountering an unrecognized critical chunk type, because there is no way to be
          certain that a valid datastream will result from modifying a datastream containing such a chunk. (Simply discarding the
          chunk is not good enough, because it might have unknown implications for the interpretation of other chunks.) The
          safe/unsafe mechanism is intended for use with ancillary chunks. The safe-to-copy bit will always be 0 for critical
          chunks.
        </li>
      </ol>

      <p>The rules governing ordering of chunks are as follows.</p>
      <!-- <ol start="5"> -->

      <ol>
        <li>When copying an unknown <strong>unsafe-to-copy</strong> ancillary chunk, a <a>PNG editor</a> shall not move the chunk
        relative to any critical chunk. It may relocate the chunk freely relative to other ancillary chunks that occur between the
        same pair of critical chunks. (This is well defined since the editor shall not add, delete, modify, or reorder critical
        chunks if it is preserving unknown unsafe-to-copy chunks.)
        </li>

        <li>When copying an unknown <strong>safe-to-copy</strong> ancillary chunk, a <a>PNG editor</a> shall not move the chunk
        from before <a class="chunk" href="#11IDAT">IDAT</a> to after <a class="chunk" href="#11IDAT">IDAT</a> or vice versa. (This
        is well defined because <a class="chunk" href="#11IDAT">IDAT</a> is always present.) Any other reordering is permitted.
        </li>

        <li>When copying a <strong>known</strong> ancillary chunk type, an editor need only honour the specific chunk ordering
        rules that exist for that chunk type. However, it may always choose to apply the above general rules instead.</li>
      </ol>

      <p>These rules are expressed in terms of copying chunks from an input datastream to an output datastream, but they apply in
      the obvious way if a PNG datastream is modified in place.</p>

      <p>See also <a href="#5Chunk-naming-conventions"></a>.</p>

      <p><a>PNG editors</a> that do not change the <a>image data</a> should not change the <a class="chunk" href="#11tIME">tIME</a>
      chunk. The Creation Time keyword in the <a class="chunk" href="#11tEXt">tEXt</a>, <a class="chunk" href="#11zTXt">zTXt</a>,
      and <a class="chunk" href="#11iTXt">iTXt</a> chunks may be used for a user-supplied time.</p>
    </section>
    <!-- Maintain a fragment named "14Ordering-of-chunks" to preserve incoming links to it -->

    <section id="14Ordering-of-chunks">
      <h2>Ordering of chunks</h2>
      <!-- Maintain a fragment named "14Ordering-of-critical-chunks" to preserve incoming links to it -->

      <section id="14Ordering-of-critical-chunks">
        <h2>Ordering of critical chunks</h2>

        <p>Critical chunks may have arbitrary ordering requirements, because <a>PNG editors</a> are required to terminate if they
        encounter unknown critical chunks. For example <a class="chunk" href="#11IHDR">IHDR</a> has the specific ordering rule that
        it shall always appear first. A PNG editor, or indeed any PNG-writing program, shall know and follow the ordering rules for
        any critical chunk type that it can generate.</p>
      </section>
      <!-- Maintain a fragment named "14Ordering-of-ancillary-chunks" to preserve incoming links to it -->

      <section id="14Ordering-of-ancillary-chunks">
        <h2>Ordering of ancillary chunks</h2>

        <p>The strictest ordering rules for an ancillary chunk type are:</p>
        <!-- <ol start="1"> -->

        <ol>
          <li>Unsafe-to-copy chunks may have ordering requirements relative to critical chunks.</li>

          <li>Safe-to-copy chunks may have ordering requirements relative to <a class="chunk" href="#11IDAT">IDAT</a>.
          </li>
        </ol>

        <p>The actual ordering rules for any particular ancillary chunk type may be weaker. See for example the ordering rules for
        the standard ancillary chunk types in <a href="#5ChunkOrdering"></a>.</p>

        <p>Decoders shall not assume more about the positioning of any ancillary chunk than is specified by the chunk ordering
        rules. In particular, it is never valid to assume that a specific ancillary chunk type occurs with any particular
        positioning relative to other ancillary chunks.</p>

        <p>EXAMPLE It is unsafe to assume that a particular private ancillary chunk occurs immediately before <a class="chunk"
        href="#11IEND">IEND</a>. Even if it is always written in that position by a particular application, a <a>PNG editor</a>
        might have inserted some other ancillary chunk after it. But it is safe to assume that the chunk will remain somewhere
        between <a class="chunk" href="#11IDAT">IDAT</a> and <a class="chunk" href="#11IEND">IEND</a>.</p>
      </section>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "15Conformance" to preserve incoming links to it -->

  <div id="15Conformance">
  </div>

  <section id="conformance">
    <h2>Conformance</h2>
    <!-- Maintain a fragment named "15ConfIntro" to preserve incoming links to it -->

    <section id="15ConfIntro">
      <h2>Introduction</h2>
      <!-- Maintain a fragment named "15ConfObjectives" to preserve incoming links to it -->

      <section id="15ConfObjectives">
        <h2>Objectives</h2>

        <p>This clause addresses conformance of PNG datastreams, PNG encoders, PNG decoders, and <a>PNG editors</a>.</p>

        <p>The primary objectives of the specifications in this clause are:</p>
        <!-- <ol start="1"> -->

        <ol>
          <li>to promote interoperability by eliminating arbitrary subsets of, or extensions to, this specification;</li>

          <li>to promote uniformity in the development of conformance tests;</li>

          <li>to promote consistent results across PNG encoders, decoders, and editors;</li>

          <li>to facilitate automated test generation.</li>
        </ol>
      </section>
      <!-- Maintain a fragment named "15ConfScope" to preserve incoming links to it -->

      <section id="15ConfScope">
        <h2>Scope</h2>

        <p>Conformance is defined for PNG datastreams and for PNG encoders, decoders, and editors.</p>

        <p>This clause addresses the PNG datastream and implementation requirements including the range of allowable differences
        for PNG encoders, PNG decoders, and <a>PNG editors</a>. This clause does not directly address the environmental,
        performance, or resource requirements of the encoder, decoder, or editor.</p>

        <p>The scope of this clause is limited to rules for the open interchange of PNG datastreams.</p>
      </section>
    </section>
    <!-- Maintain a fragment named "15ConformanceConf" to preserve incoming links to it -->

    <section id="15ConformanceConf">
      <h2>Conformance conditions</h2>
      <!-- Maintain a fragment named "15FileConformance" to preserve incoming links to it -->

      <section id="15FileConformance">
        <h2>Conformance of PNG datastreams</h2>

        <p>A PNG datastream conforms to this specification if the following conditions are met.</p>

        <ol>
          <li>The PNG datastream contains a PNG signature as the first content (see <a href="#5PNG-file-signature"></a>).
          </li>

          <li>With respect to the chunk types defined in this International Standard:
            <ul>
              <li>the PNG datastream contains as its first chunk, an <a class="chunk" href="#11IHDR">IHDR</a> chunk, immediately
              following the PNG signature;
              </li>

              <li>the PNG datastream contains as its last chunk, an <a class="chunk" href="#11IEND">IEND</a> chunk.
              </li>
            </ul>
          </li>

          <li>No chunks or other content follow the <a class="chunk" href="#11IEND">IEND</a> chunk.
          </li>

          <li>All chunks contained therein match the specification of the corresponding chunk types of this specification. The PNG
          datastream shall obey the relationships among chunk types defined in this specification.</li>

          <li>The sequence of chunks in the PNG datastream obeys the ordering relationship specified in this International
          Standard.</li>

          <li>All field values in the PNG datastream obey the relationships specified in this specification producing the structure
          specified in this specification.</li>

          <li>No chunks appear in the PNG datastream other than those specified in this specification or those defined according to
          the rules for creating new chunk types as defined in this specification.</li>

          <li>The PNG datastream is encoded according to the rules of this International Standard.</li>
        </ol>
      </section>
      
      
      <!-- Maintain a fragment named "15ConformanceEncoder" to preserve incoming links to it -->

      <section id="15ConformanceEncoder">
        <h2>Conformance of PNG encoders</h2>

        <p>A PNG encoder conforms to this specification if it satisfies the following conditions.</p>
        <!-- <ol start="1"> -->

        <ol>
          <li>All PNG datastreams that are generated by the PNG encoder are conforming PNG datastreams.</li>

          <li>When encoding input samples that have a sample depth that cannot be directly represented in PNG, the encoder scales
          the samples up to the next higher sample depth that is allowed by PNG. The data are scaled in such a way that the
          high-order bits match the original data.</li>

          <li>
            <a>Private field values</a> are used when encoding experimental or private definitions of values for any of the method
            or type fields.
          </li>
        </ol>
      </section>
      <!-- Maintain a fragment named "15ConformanceDecoder" to preserve incoming links to it -->

      <section id="15ConformanceDecoder">
        <h2>Conformance of PNG decoders</h2>

        <p>A PNG decoder conforms to this specification if it satisfies the following conditions.</p>
        <!-- <ol start="1"> -->

        <ol>
          <li>It is able to read any PNG datastream that conforms to this International Standard, including both public and private
          chunks whose types may not be recognized.</li>

          <li>It supports all the standardized critical chunks, and all the standardized compression, filter, and interlace methods
          and types in any PNG datastream that conforms to this International Standard.</li>

          <li>Unknown chunk types are handled as described in <a href="#5Chunk-naming-conventions"></a>. An unknown chunk type is
          <strong>not</strong> treated as an error unless it is a critical chunk.
          </li>

          <li>Unexpected values in fields of known chunks (for example, an unexpected compression method in the <a class="chunk"
          href="#11IHDR">IHDR</a> chunk) are treated as errors.
          </li>

          <li>All types of PNG images (indexed-color, <a>truecolor</a>, <a>greyscale</a>, <a>truecolor with alpha</a>, and <a>greyscale
          with alpha</a>) are processed. For example, decoders which are part of viewers running on indexed-color display hardware
          shall reduce <a>truecolor</a> images to indexed format for viewing.
          </li>

          <li>Encountering an unknown chunk in which the ancillary bit is 0 generates an error if the decoder is attempting to
          extract the image.</li>

          <li>A chunk type in which the reserved bit is set is treated as an unknown chunk type.</li>

          <li>All valid combinations of bit depth and <a>color type</a> as defined in <a class="chunk" href="#11IHDR"></a> are
          supported.
          </li>

          <li>An error is reported if an unrecognized value is encountered in the bit depth, <a>color type</a>, compression
          method, <a>filter method</a>, or interlace method bytes of the <a class="chunk" href="#11IHDR">IHDR</a> chunk.
          </li>

          <li>When processing 16-bit <a>greyscale</a> or <a>truecolor</a> data in the <a class="chunk" href="#11tRNS">tRNS</a> chunk,
          both bytes of the sample values are evaluated to determine whether a pixel is transparent.
          </li>

          <li>When processing an image compressed by compression method 0, the decoder assumes no more than that the complete
          <a>image data</a> is represented by a single compressed datastream that is stored in some number of <a class="chunk"
            href="#11IDAT">IDAT</a> chunks.
          </li>

          <li>No assumptions are made concerning the positioning of any ancillary chunk other than those that are specified by the
          chunk ordering rules.</li>
        </ol>
      </section>
      <!-- Maintain a fragment named "15ConformanceEditor" to preserve incoming links to it -->

      <section id="15ConformanceEditor">
        <h2>Conformance of PNG editors</h2>

        <p>A <a>PNG editor</a> conforms to this specification if it satisfies the following conditions.</p>

        <ol>
          <li>It conforms to the requirements for PNG encoders.</li>

          <li>It conforms to the requirements for PNG decoders.</li>

          <li>It is able to encode all chunks that it decodes.</li>

          <li>It preserves the ordering of the chunks presented within the rules in <a href="#5ChunkOrdering"></a>.
          </li>

          <li>It properly processes the safe-to-copy bit information and preserves unknown chunks when the safe-to-copy rules
          permit it.</li>

          <li>Unless the user specifically permits lossy operations or the editor issues a warning, it preserves all information
          required to reconstruct the reference image exactly, except that the sample depth of the alpha channel need not be
          preserved if it contains only zero and maximum values. Operations such as changing the <a>color type</a> or rearranging
          the palette in an <a>indexed-color</a> datastream are permitted provided that the new datastream losslessly represents the same
          reference image.
          </li>
        </ol>
      </section>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "A-Conventions" to preserve incoming links to it -->

  <section class="appendix" id="A-Conventions">
    <!-- Maintain a fragment named "IANA-registrations" to preserve incoming links to it -->

    <h2 id="IANA-registrations">Internet Media Types</h2>
    <!-- Maintain a fragment named "A-Media-type" to preserve incoming links to image/png registration -->

    <section>
      <h3 id="A-Media-type">image/png</h3>

      <p>This updates the existing <span class="tt">image/png</span> Internet Media type, under the <span class="tt">image</span>
      top level type. This appendix is in conformance with <a href="https://www.rfc-editor.org/info/bcp13">BCP 13</a> and <a href=
      "https://www.w3.org/2020/01/registering-mediatypes.html">W3CRegMedia</a>.</p>

      <dl>
        <dt>Media type name:</dt>

        <dd>image</dd>

        <dt>Media subtype name:</dt>

        <dd>png</dd>

        <dt>Required parameters:</dt>

        <dd>None</dd>

        <dt>Optional parameters:</dt>

        <dd>None</dd>

        <dt>Encoding considerations:</dt>

        <dd>binary</dd>

        <dt>Security considerations:</dt>

        <dd>
          <p>A PNG document is composed of a collection of explicitly typed "chunks". For each of the chunk types defined in the
          PNG specification (except for <span class="chunk">gIFx</span>), the only effect associated with those chunks is to cause
          an image to be rendered on the recipient's display or printer.</p>

          <p>The <span class="chunk">gIFx</span> chunk type is used to encapsulate Application Extension data, and some use of that
          data might present security risks, though no risks are known. Likewise, the security risks associated with future chunk
          types cannot be evaluated, particularly unregistered chunks. However, it is the intention of the PNG Working Group to
          disallow chunks containing "executable" data to become registered chunks.</p>

          <p>The text chunks, <a class="chunk" href="#11tEXt">tEXt</a>, <a class="chunk" href="#11iTXt">iTXT</a> and <a class=
          "chunk" href="#11zTXt">zTXt</a>, contain data that can be displayed in the form of comments, etc. Some operating systems
          or terminals might allow the display of textual data with embedded control characters to perform operations such as
          re-mapping of keys, creation of files, etc. For this reason, the specification recommends that the text chunks be
          filtered for control characters before direct display.</p>

          <p>The PNG format is specifically designed to facilitate early detection of file transmission errors, and makes use of
          cyclical redundancy checks to ensure the integrity of the data contained in its chunks.</p>
        </dd>

        <dt>Interoperability considerations:</dt>

        <dd>Network byte order used throughout.</dd>

        <dt>Published specification:</dt>

        <dd>
          <a href="https://www.w3.org/TR/PNG/">Portable Network Graphics (PNG) Specification</a>, <a href=
          "https://www.w3.org/TR/PNG/">https://www.w3.org/TR/PNG/</a>
        </dd>

        <dt>Applications which use this media:</dt>

        <dd>PNG is widely implemented in all Web browsers, image viewers, and image creation tools</dd>

        <dt>Fragment identifier considerations:</dt>

        <dd>N/A</dd>

        <dt>Restrictions on usage:</dt>

        <dd>N/A</dd>

        <dt>Provisional registration? (standards tree only):</dt>

        <dd>No</dd>

        <dt>Additional information:</dt>

        <dd>
          <dl>
            <dt>Deprecated alias names for this type:</dt>

            <dd>N/A</dd>

            <dt>Magic number(s):</dt>

            <dd>89 50 4E 47 0D 0A 1A 0A</dd>

            <dt>File extension(s):</dt>

            <dd>.png</dd>

            <dt>Macintosh file type code:</dt>

            <dd>PNGf</dd>

            <dt>Object Identifiers:</dt>

            <dd>N/A</dd>
          </dl>
        </dd>

        <dt>General Comments:</dt>

        <dd>
          <p>This registration updates the earlier one:</p>

          <ol>
            <li>The old one points to an expired Internet Draft. This updated registration points to a W3C Recommendation.</li>

            <li>The old contact person is sadly deceased. The new contact email is a publicly archived W3C mailing list for the PNG
            Working Group.</li>

            <li>Change controller is W3C</li>
          </ol>
        </dd>

        <dt>Person to contact for further information:</dt>

        <dd>
          <dl>
            <dt>Name:</dt>

            <dd>PNG Working Group</dd>

            <dt>Email:</dt>

            <dd>
              <a href="mailto:public-png@w3.org">public-png@w3.org</a>
            </dd>
          </dl>
        </dd>

        <dt>Intended usage:</dt>

        <dd>Common</dd>

        <dt>Author/Change controller:</dt>

        <dd>W3C</dd>
      </dl>
    </section>

    <section>
      <h3>image/apng</h3>

      <p>This appendix is in conformance with <a href="https://www.rfc-editor.org/info/bcp13">BCP 13</a> and <a href=
      "https://www.w3.org/2020/01/registering-mediatypes.html">W3CRegMedia</a>.</p>

      <dl>
        <dt>Media type name:</dt>

        <dd>image</dd>

        <dt>Media subtype name:</dt>

        <dd>apng</dd>

        <dt>Required parameters:</dt>

        <dd>N/A</dd>

        <dt>Optional parameters:</dt>

        <dd>N/A</dd>

        <dt>Encoding considerations:</dt>

        <dd>binary</dd>

        <dt>Security considerations:</dt>

        <dd>
          <p>An APNG document is composed of a collection of explicitly typed "chunks". For each of the chunk types defined in the
          PNG specification (except for <span class="chunk">gIFx</span>), the only effect associated with those chunks is to cause
          an animated image to be rendered on the recipient's display.</p>

          <p>The <span class="chunk">gIFx</span> chunk type is used to encapsulate Application Extension data, and some use of that
          data might present security risks, though no risks are known. Likewise, the security risks associated with future chunk
          types cannot be evaluated, particularly unregistered chunks. However, it is the intention of the PNG Working Group to
          disallow chunks containing "executable" data to become registered chunks.</p>

          <p>The text chunks, <a class="chunk" href="#11tEXt">tEXt</a>, <a class="chunk" href="#11iTXt">iTXt</a> and <a class=
          "chunk" href="#11zTXt">zTXt</a>, contain data that can be displayed in the form of comments, etc. Some operating systems
          or terminals might allow the display of textual data with embedded control characters to perform operations such as
          re-mapping of keys, creation of files, etc. For this reason, the specification recommends that the text chunks be
          filtered for control characters before direct display.</p>

          <p>The PNG format is specifically designed to facilitate early detection of file transmission errors, and makes use of
          cyclical redundancy checks to ensure the integrity of the data contained in its chunks.</p>

          <p>If one creates an APNG file with unrelated static image and animated image chunks, somebody using a tool not
          supporting the APNG format would only see the static image and be unaware of the additional content. This could be used
          e.g. to bypass moderation.</p>
        </dd>

        <dt>Interoperability considerations:</dt>

        <dd>None</dd>

        <dt>Published specification:</dt>

        <dd>
          <a href="https://www.w3.org/TR/png/">Portable Network Graphics (PNG) Specification</a>, <a href=
          "https://www.w3.org/TR/png/">https://www.w3.org/TR/png/</a>
        </dd>

        <dt>Applications which use this media:</dt>

        <dd>Animated PNG (APNG) is widely implemented in all Web browsers, and is increasingly available in image viewers, and
        animation and image creation tools</dd>

        <dt>Fragment identifier considerations:</dt>

        <dd>N/A</dd>

        <dt>Restrictions on usage:</dt>

        <dd>N/A</dd>

        <dt>Provisional registration? (standards tree only):</dt>

        <dd>No</dd>

        <dt>Additional information:</dt>

        <dd>
          <dl>
            <dt>Deprecated alias names for this type:</dt>

            <dd>image/vnd.mozilla.apng</dd>

            <dt>Magic number(s):</dt>

            <dd>89 50 4E 47 0D 0A 1A 0A</dd>

            <dt>File extension(s):</dt>

            <dd>.apng</dd>

            <dt>Object Identifiers:</dt>

            <dd>N/A</dd>
          </dl>
        </dd>

        <dt>General Comments:</dt>

        <dd>
          <p>image/apng has been in widespread, unregistered use since 2015. Animated PNG was not part of the official PNG
          specification until 2022. This registration, plus the PNG specification (3rd Edition) brings official documentation into
          alignment with already widely-deployed reality.</p>
        </dd>

        <dt>Person to contact for further information:</dt>

        <dd>
          <dl>
            <dt>Name:</dt>

            <dd>PNG Working Group</dd>

            <dt>Email:</dt>

            <dd>
              <a href="mailto:public-png@w3.org">public-png@w3.org</a>
            </dd>
          </dl>
        </dd>

        <dt>Intended usage:</dt>

        <dd>Common</dd>

        <dt>Author/Change controller:</dt>

        <dd>W3C</dd>
      </dl>
    </section>
  </section>
  
  
  <!-- Maintain a fragment named "B-NewChunksAppendix" to preserve incoming links to it -->

  <section class="appendix informative" id="B-NewChunksAppendix">
    <!-- Maintain a fragment named "newchunks" to preserve incoming links to it -->

    <h2 class="Annex" id="newchunks">Guidelines for private chunk types</h2>

    <p>The following specifies guidelines for the definition of private chunks:</p>
    <!-- <ol start="1"> -->

    <ol>
      <li>Do not define new chunks that redefine the meaning of existing chunks or change the interpretation of an existing
      standardized chunk, e.g., do not add a new chunk to say that RGB and alpha values actually mean CMYK.</li>

      <li>Minimize the use of private chunks to aid portability.</li>

      <li>Avoid defining chunks that depend on total datastream contents. If such chunks have to be defined, make them critical
      chunks.</li>

      <li>For textual information that is representable in Latin-1 avoid defining a new chunk type. Use a <a class="chunk" href=
      "#11tEXt">tEXt</a> or <a class="chunk" href="#11zTXt">zTXt</a> chunk with a suitable keyword to identify the type of
      information. For textual information that is not representable in Latin-1 but which can be represented in UTF-8, use an
      <a class="chunk" href="#11iTXt">iTXt</a> chunk with a suitable keyword.
      </li>

      <li>Group mutually dependent ancillary information into a single chunk. This avoids the need to introduce chunk ordering
      relationships.</li>

      <li>Avoid defining private critical chunks.</li>
    </ol>
  </section>
  
  
  <!-- Maintain a fragment named "C-GammaAppendix" to preserve incoming links to it -->

  <section class="appendix informative" id="C-GammaAppendix">
    <!-- Maintain a fragment named "gammachromaticity" to preserve incoming links to it -->

    <h2 class="Annex" id="gammachromaticity">Gamma and chromaticity</h2>

    <p>A <a>gamma value</a> is a numerical parameter used to describe approximations to certain non-linear <a>transfer
    functions</a> encountered in image capture and reproduction. The <a>gamma value</a> is the exponent in a power law function.
    For example the function:</p>

    <p><code>intensity = (voltage + constant)<sup>exponent</sup></code>
    </p>

    <p>which is used to model the non-linearity of CRT displays. It is often assumed, as in this International Standard,
    that the constant is zero.</p>

    <p>For the purposes of this specification, it is convenient to consider five places in a general image pipeline at which
    non-linear <a>transfer functions</a> may occur and which may be modelled by power laws. The characteristic exponent associated
    with each is given a specific name.</p>

    <table id="gamma-pipeline"  class="simple numbered">
      <tr>
        <td><var>input_exponent</var>
        </td>
        <td>the exponent of the image sensor.</td>
      </tr>

      <tr>
        <td><var>encoding_exponent</var>
        </td>
        <td>
          the exponent of any <a>transfer function</a> performed by the process or device writing the datastream.
        </td>
      </tr>

      <tr>
        <td><var>decoding_exponent</var>
        </td>
        <td>
          the exponent of any <a>transfer function</a> performed by the software reading the <a>image data</a>stream.
        </td>
      </tr>

      <tr>
        <td><var>LUT_exponent</var>
        </td>
        <td>
          the exponent of the <a>transfer function</a> applied between the <a>frame buffer</a> and the display device (typically
          this is applied by a Look Up Table).
        </td>
      </tr>

      <tr>
        <td><var>output_exponent</var>
        </td>
        <td>
          the exponent of the display device. For a CRT, this is typically a value close to 2.2.
        </td>
      </tr>
    </table>

    <p>It is convenient to define some additional entities that describe some composite <a>transfer functions</a>, or combinations
    of stages.</p>

    <table id="gamma-composite" class="simple numbered">
      <tr>
        <td><var>display_exponent</var>
        </td>
        <td>
          exponent of the <a>transfer function</a> applied between the <a>frame buffer</a> and the display surface of the display
          device.<br>
          <code>display_exponent = LUT_exponent * output_exponent</code>
        </td>
      </tr>

      <tr>
        <td><var>gamma</var>
        </td>
        <td>exponent of the function mapping display output intensity to samples in the PNG datastream.<br>
        <code>gamma = 1.0 / (decoding_exponent * display_exponent)</code></td>
      </tr>

      <tr>
        <td><var>end_to_end_exponent</var>
        </td>
        <td>the exponent of the function mapping image sensor input intensity to display output intensity. This is generally a
        value in the range 1.0 to 1.5.</td>
      </tr>
    </table>

    <p>The PNG <a class="chunk" href="#11gAMA">gAMA</a> chunk is used to record the <a>gamma value</a>. This information may be
    used by decoders together with additional information about the display environment in order to achieve, or approximate, the
    desired display output.</p>

    <p>Additional information about this subject may be found [[?GAMMA-FAQ]].</p>

    <p>Additional information on the impact of color space on image encoding may be found in [[?Kasson]] and [[?Hill]].</p>

    <p>Background information about <a>chromaticity</a> and color spaces may be found in [[?Luminance-Chromaticity]] and [[?COLOR-FAQ]].</p>
  </section>
  
  
  <!-- Maintain a fragment named "D-CRCAppendix" to preserve incoming links to it -->

  <section class="appendix" id="D-CRCAppendix">
    <!-- Maintain a fragment named "samplecrc" to preserve incoming links to it -->

    <h2 class="Annex" id="samplecrc">Sample CRC implementation</h2>

    <p>The following sample code — which is informative — represents a practical implementation of the CRC (Cyclic
    Redundancy Check) employed in PNG chunks. (See also ISO 3309 [[ISO-3309]] or ITU-T V.42 [[ITU-T-V.42]] for a formal
    specification.)</p>

    <p>The sample code is in the ISO C [[ISO_9899]] programming language. The hints in <a href="#D-tabled1"></a> may help non-C
    users to read the code more easily.</p>
    <!-- Maintain a fragment named "D-tabled1" to preserve incoming links to it -->

    <table id="D-tabled1" class="numbered simple">
      <caption>
        Hints for reading ISO C code
      </caption>

      <tr>
        <th>Operator</th>
        <th>Description</th>
      </tr>

      <tr>
        <td><code>&amp;</code>
        </td>
        <td>Bitwise AND operator.</td>
      </tr>

      <tr>
        <td><code>^</code>
        </td>
        <td>Bitwise exclusive-OR operator.</td>
      </tr>

      <tr>
        <td><code>&gt;&gt;</code>
        </td>
        <td>Bitwise right shift operator. When applied to an unsigned quantity, as here, right shift inserts zeroes at the
        left.</td>
      </tr>

      <tr>
        <td><code>!</code>
        </td>
        <td>Logical NOT operator.</td>
      </tr>

      <tr>
        <td><code>++</code>
        </td>
        <td>"<code>n++</code>" increments the variable <var>n</var>. In "for" loops, it is applied after the variable is
        tested.</td>
      </tr>

      <tr>
        <td><code>0xNNN</code>
        </td>
        <td><code>0x</code> introduces a hexadecimal (base 16) constant. Suffix <code>L</code> indicates a long value (at least 32
        bits).</td>
      </tr>
    </table>

    <hr>

    <pre>
   /* Table of CRCs of all 8-bit messages. */
   unsigned long crc_table[256];

   /* Flag: has the table been computed? Initially false. */
   int crc_table_computed = 0;

   /* Make the table for a fast CRC. */
   void make_crc_table(void)
   {
     unsigned long c;
     int n, k;

     for (n = 0; n &lt; 256; n++) {
       c = (unsigned long) n;
       for (k = 0; k &lt; 8; k++) {
         if (c &amp; 1)
           c = 0xedb88320L ^ (c &gt;&gt; 1);
         else
           c = c &gt;&gt; 1;
       }
       crc_table[n] = c;
     }
     crc_table_computed = 1;
   }

</pre>
    

    <pre>
   /* Update a running CRC with the bytes buf[0..len-1]--the CRC
      should be initialized to all 1's, and the transmitted value
      is the 1's complement of the final running CRC (see the
      crc() routine below). */

   unsigned long update_crc(unsigned long crc, unsigned char *buf,
                            int len)
   {
     unsigned long c = crc;
     int n;

     if (!crc_table_computed)
       make_crc_table();
     for (n = 0; n &lt; len; n++) {
       c = crc_table[(c ^ buf[n]) &amp; 0xff] ^ (c &gt;&gt; 8);
     }
     return c;
   }

   /* Return the CRC of the bytes buf[0..len-1]. */
   unsigned long crc(unsigned char *buf, int len)
   {
     return update_crc(0xffffffffL, buf, len) ^ 0xffffffffL;
   }
</pre>
  </section>
  
  
  <!-- Maintain a fragment named "E-Resources" to preserve incoming links to it -->

  <section class="appendix informative" id="E-Resources">
    <!-- Maintain a fragment named "onlineresources" to preserve incoming links to it -->

    <h2 class="Annex" id="onlineresources">Online resources</h2>
    <!-- Maintain a fragment named "E-Intro" to preserve incoming links to it -->

    <section class="introductory" id="E-Intro">
      <h3>Introduction</h3>

      <p>This annex gives the locations of some Internet resources for PNG software developers. By the nature of the Internet, the
      list is incomplete and subject to change.</p>
    </section>

    <!-- Maintain a fragment named "E-icc-profile-specs" to preserve incoming links to it -->

    <section id="E-icc-profile-specs">
      <h2>ICC profile specifications</h2>

      <p>ICC profile specifications are available at: <a href="https://www.color.org/"><code>https://www.color.org/</code></a></p>
    </section>
    <!-- Maintain a fragment named "E-PNG-home-page" to preserve incoming links to it -->

    <section id="E-PNG-home-page">
      <h2>PNG web site</h2>

      <p>There is a World Wide Web site for PNG at <a href=
      "http://www.libpng.org/pub/png/"><code>http://www.libpng.org/pub/png/</code></a>. This page is a central location for current
      information about PNG and PNG-related tools.</p>

      <p>Additional documentation and portable C code for <a>deflate</a>, and an optimized implementation of the CRC
      algorithm are available from the zlib web site, <a href="https://www.zlib.net/"><code>https://www.zlib.net/</code></a>.</p>
    </section>
    <!-- Maintain a fragment named "E-Sample-implementation" to preserve incoming links to it -->

    <section id="E-Sample-implementation">
      <h2>Sample implementation and test images</h2>

      <p>A sample implementation in portable C, <strong>libpng</strong>, is available at <a href=
      "http://www.libpng.org/pub/png/libpng.html"><code>http://www.libpng.org/pub/png/libpng.html</code></a>. Sample viewer and
      encoder applications of libpng are available at <a href=
      "http://www.libpng.org/pub/png/book/sources.html"><code>http://www.libpng.org/pub/png/book/sources.html</code></a> and are
      described in detail in <i>PNG: The Definitive Guide</i> [[?ROELOFS]]. Test images can also be accessed from the PNG web
      site.</p>
    </section>
  </section>
  <!-- Maintain a fragment named "F-ChangeList" to preserve incoming links to it -->

  <section id="F-ChangeList" class="appendix informative">
    <h2 class="Annex">Changes</h2>

    <h3 id="changes-20230921">Changes since the <a href="https://www.w3.org/TR/2023/CR-png-3-20230921/">Candidate Recommendation Snapshot of 21 September 2023 (Third Edition)</a></h3>

    <ul>
      <!-- to 10 Jun 2024 -->
      <li>Clarified that bit depth and color type fields can take private values</li>
      <li>Listed both decimal and hexadecimal values in MaxCLL and MaxFALL examples</li>
      <li>Corrected terminology in mDCv section</li>
      <li>Corrected "PNG image" in cHRM section</li>
      <li>Consolidated color chunk precedence information</li>
      <li>Added order of precedence for color space chunks</li>
      <li>Clarified color chunk priorities description</li>
      <li>Mark SMPTE RP 2077 as informative, since it is not freely available</li>
      <li>Added color chunk priority table</li>
      <li>Clarified alpha channels are always full-range</li>
      <li>Added EOTF and OETF definitions</li>
      <li>Added recommendation for handling negative values resulting from narrow-range images using an extended range transfer function</li>
      <li>Clarified "video" from "video full range flag) is used to match H.273 wording but still applies to still images</li>
      <li>Added link to IANA subtag registry</li>
      <li>Fixed links to alhpa compaction and alpha separation sections</li>
      <li>Fixed broken tRNS link</li>
      <li>Added Display P3 cICP example</li>
      <li>Changed "perceived" wording to "measured", as luminance and chromaticity don't define a perceived color</li>
      <li>Clarified which metadata forms part of HDR10</li>
      <li>Updated link to latest version of ITU-R BT.2390</li>
      <li>Noted that currently there is no published standard to adapt an SDR image from default viewing conditions (display luminance and ambient illumination) to those given in <span class="chunk">mDCV</span></li>
      <li>Noted that the adaptation of BT.2100 HLG images to differing viewing conditions, given in BT.2390, may also be used with SDR images.</li>
      <li>Noted that tone mapping, to adjust the luminance levels given in <span class="chunk">cLLi</span> to those of a target display to prevent clipping, is particularly important for formats such as BT.2100 PQ which use absolute luminance.</li>
      <li>Noted that use of full-range BT.709 values, while common, is not part of the BT.709 standard</li>
      <li>Added mention of protected code values for Serial Digital Interface (baseband video) in description of narrow-range and full-range video</li>
      <li>Added reference to ITU-R-BT.2390</li>
      <li>Changed description of <span class="chunk">mDCv</span> to focus on BT.2100 PQ, as use with other formats is currently rare</li>
      <li>Clarified matching requirements for 16-bit <span class="chunk">tRNS</span> matching</li>
      <li>Used more precise "primary chromaticities" rather than just "primaries"</li>
      <li>Added requirement that <span class="chunk">mDCv</span> requires an accompanying <span class="chunk">cICP</span> to fit with expectations of existing HDR10 workflows</li>
      <li>Better explanation of <code>Video Full Range Flag</code></li>
      <li>Clarified ordering and encoding of sequence numbers, clarified <span class="chunk">fdAT</span> concatenation is in order of sequence number</li>
      <li>Added missing mentions of <span class="chunk">cICP</span> in descriptions of related chunks</li>
      <li>Fully specified the ordering and byte-order of fields in <span class="chunk">mDCv</span></li>
      <li>Added missing definition of PNG two-byte unsigned integer</li>
      <li>Used Display P3, rather than sRGB, in SDR <span class="chunk">mDCv</span> examples</li>
      <li>Added Chris Needham as co-author</li>
      <li>Updated examples for <span class="chunk">mDCv</span>, added reference to SMPTE-ST-2086.</li>
      <li>Added reference to Display P3</li>
      <li>Explicitly mentioned that the concatenated data from <span class="chunk">IDAT</span> and <span class="chunk">fdAT</span> may include chunks with zero-length data</li>
      <li>Assorted non-substantive improvements to markup, styling, internal cross-linking, correction of typos, punctuation, grammar, consistent use of US English, etc</li>
    </ul>

    <h3 id="changes-20230720">Changes since the <a href="https://www.w3.org/TR/2023/WD-png-3-20230720/">
      Working Draft of 20 July 2023 (Third Edition)</a></h3>

    <ul>
      <!-- to 21 Sept 2023 -->
      <li>Clarified descriptions of <span class="chunk">mDCv</span> and <span class="chunk">cLLi</span></li>
      <li>Added note to Security Considerations about potentially malicious data after <span class="chunk">IEND</span>.</li>
      <li>Clarified that <a href="#cLLi-chunk" class="chunk">cLLi</a> is for HDR content</li>
      <li>Added an informative reference to Smith &amp; Zink "On the Calculation and Usage of HDR Static Content Metadata"</li>
      <li>Added an informative reference to CTA-861.3-A for static HDR metadata</li>
      <li>Fixed broken reference to ITU-R BT.2100 </li>
      <li>Updated reference to SMPTE-ST-2067-21</li>
      <!-- to 26 Aug 2023 -->
      <li>Added guidance on calculating MaxCLL and MaxFALL values</li>
      <li>Added example (live streaming) where <a href="#cLLi-chunk" class="chunk">cLLi</a> could not be pre-calculated</li>
      <li>Added definitions for stop, SDR, HDR, HLG and PQ</li>
      <li>Clarified definition of narrow-range</li>
      <li>Updated ITU-T H Suppl. 19 reference to latest version</li>
      <li>Added Simon Thompson as an author</li>
      <li>Mandated current browser handling of out-of-range palette indices</li>
      <li>Updated "Additional Information" table to add <a href="#mDCv-chunk" class="chunk">mDCv</a> and <a href="#cLLi-chunk" class="chunk">cLLi</a>.</li>
    </ul>

    <h3 id="changes-20221025">Changes since the <a href="https://www.w3.org/TR/2022/WD-png-3-20221025/">
      First Public Working Draft of 25 October 2022 (Third Edition)</a></h3>

    <ul>
      <!-- to 18 July 2023 -->
      <li>Explained preferable handling of trailing bytes in the final <a href="#11IDAT" class="chunk">IDAT</a> chunk for encoders and decoders.</li>
      <li>Linked to open issue on tone-mapping <a>HDR</a> [[ITU-R-BT.2100]] images in the presence of <a href="#mDCv-chunk" class="chunk">mDCv</a>.</li>

      <li>Follow the Encoding Standard on UTF-8 encode and decode.</li>
      <li>Added definition of a frame.</li>
      <li>Required the Matrix Coefficients in <a href="#cICP-chunk" class="chunk">cICP</a> to be zero (RGB data).</li>
      <li>Added known Privacy issue with recoverable data that only appears to have been redacted.</li>
      <li>Improved advice on choosing filters.</li>
      <li>Added links to color image type definitions.</li>
      <li>Clarified that MaxFALL uses the values of the frame with highest mean luminance.</li>
      <li>Clarified luminance units.</li>
      <li>Prefer RFC 3339 format for Creation Time.</li>
      <li>Improved the definition of <a href="#mDCv-chunk" class="chunk">mDCv</a>, with better descriptions, default values, and reference to SMPTE standards.</li>
      <li>Refactored the terms and definitions, for clarity.</li>
      <li>Improved definitions of source, reference, and PNG images.</li>
      <li>Moved concepts from the terms and definitions section to the main prose.</li>
      <!-- to 6 March 2023 -->
      <li>Corrected error in <a href="#eXIf" class="chunk">eXIf</a> chunk,
        which conflicted with the <a href="#5ChunkOrdering">chunk ordering</a> section.</li>
      <li>Simplified <a href="#1Scope">Scope</a> section to remove redundant detail described elsewhere.</li>
      <li>Redrew chunk-ordering lattice diagrams to be clearer and more consistent.</li>
      <li>Added a new chunk, <a href="#cLLi-chunk" class="chunk">cLLi</a>,
      to describe the Maximum Single-Pixel and Frame-Average Luminance Levels
      for both static and animated <a>HDR</a> [[ITU-R-BT.2100]] PNG images.

      </li>
      <li>Updated external links to latest versions, preferring https over http.</li>
      <li>Specified interoperable handling of extra sample bits, beyond the specified bit depth,
        in <a href="#11tRNS" class="chunk">tRNS</a> and <a href="#11bKGD" class="chunk">bKGD</a> chunks.
      </li>
      <li>Added a new chunk, <a href="#mDCv-chunk" class="chunk">mDCv</a>
        to describe the color volume of the mastering display used to grade <a>HDR</a> [[ITU-R-BT.2100]] content.</li>

      <li>Used correct Unicode character names.</li>
      <li>Changed chunk type codes to use hexadecimal, rather than decimal.</li>
      <li>Described textual chunk processing more clearly.</li>
      <li>Recommended <a href="#11iTXt" class="chunk">iTXt</a> for new content.</li>
      <li>Clarifications on the language tag field of the <a href="#11iTXt" class="chunk">iTXt</a> chunk,
        corrected examples to conform to BCP47.</li>
      <li>Updated image/apng registration appendix. APNG MIME type registered with IANA.</li>
      <li>Converted ACII-art figures to more accessible diagrams.</li>
    </ul>

    <h3 id="changes-20031110">Changes since the <a href="https://www.w3.org/TR/2003/REC-PNG-20031110/">W3C Recommendation of 10 November 2003</a> (PNG
    Second Edition)</h3>

    <ul>
      <!-- to 22 March 2024 -->

      <li>
        <p>The three previously defined, but unofficial, chunks for Animated PNG (APNG) have been added:</p>

        <ul>
          <li><a href="#acTL-chunk" class="chunk">acTL</a> Animation Control Chunk</li>
          <li><a href="#fcTL-chunk" class="chunk">fcTL</a> Frame Control Chunk</li>
          <li><a href="#fdAT-chunk" class="chunk">fdAT</a> Frame Data Chunk</li>
        </ul>
        
        <p>This brings the PNG specification into alignment with widely deployed industry practice.</p>
      </li>

      <li>
        <p>Added the <a class="chunk" href="#cICP-chunk">cICP</a> chunk, Coding-independent code points for video signal type
          identification, to contain image format metadata defined in [[ITU-T-H.273]] which enables PNG to contain [[ITU-R-BT.2100]] High Dynamic Range
          (<a>HDR</a>) and Wide Color Gamut (WCG) images.</p>
      </li>

      <li>
        <p>For chunks which define the image color space,
          the order of precedence is clearly defined,
          if more than one is present.</p>
      </li>

      <li>
        <p>The previously defined <a class="chunk" href="#eXIf">eXIf</a> chunk has been moved from the PNG-Extensions document
        [[PNG-EXTENSIONS]] into the main body of this specification, to reflect its increasing use.</p>
      </li>

      <li>
        <p>To help with tonemapping HDR content, added the <a class="chunk" href="#mDCv-chunk">mDCv</a> chunk, which contains metadata about the display used in
          mastering, and <a href="#cLLi-chunk" class="chunk">cLLi</a>, which contains metadata about peak and average light levels. This enabled more accurate color matching on heterogeneous platforms</p>
      </li>

      <li>
        <p>Clarified that the <a href="#11iCCP" class="chunk">iCCP</a> chunk, which contains an ICC profile, can contain profiles conforming to any version of the ICC.1 specification. PNG Second Edition only referenced the then-current v2 of ICC.1, although it has since become industry practice to also used higher versions.</p>
      </li>

      <li>
        <p>Clarified handling of out-of-range indexes, for indexed-color PNG</p>
      </li>

      <li>
        <p>Clarified error recovery for unknown and invalid ancillary chunks</p>
      </li>

      <li>
        <p>Incorporation of all <a href="https://www.w3.org/2003/11/REC-PNG-20031110-errata">PNG Second Edition Errata</a>. Notably, clarified that PNG images with unknown gamma value, when embedded in formats such as HTML or SVG, must be treated as <a href="https://drafts.csswg.org/css-color-4/#untagged">untagged images</a></p>
      </li>

      <li>
        <p>Various editorial clarifications in response to community feedback</p>
      </li>

      <li>
        <p>References updated to latest versions</p>
      </li>

      <li>
        <p>Markup corrections and link fixes</p>
      </li>

      <li>
        <p>Document source reformatted to use ReSpec</p>
      </li>
    </ul>

    <h3>Changes between First and Second Editions</h3>

    <p>For the list of changes between W3C Recommendation <a href="https://www.w3.org/TR/REC-png-961001">PNG Specification Version
    1.0</a> and <a href="https://www.w3.org/TR/2003/REC-PNG-20031110/">PNG Second Edition</a>, see <a href=
    "https://www.w3.org/TR/2003/REC-PNG-20031110/#F-ChangeList">PNG Second Edition changelist</a></p>
  </section>
  <script type="application/javascript" src="https://www.w3.org/scripts/TR/fixup.js"></script>
</body>
</html>
